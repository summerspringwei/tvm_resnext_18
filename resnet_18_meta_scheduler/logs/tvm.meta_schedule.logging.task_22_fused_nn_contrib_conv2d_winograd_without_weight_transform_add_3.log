2023-11-10 23:34:19 [INFO] [task_scheduler.cc:160] Initializing Task #22: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3"
2023-11-10 23:34:19 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(9), T.int64(9)))
        input_tile = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)))
        B = T.alloc_buffer((T.int64(4), T.int64(4)))
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        A = T.alloc_buffer((T.int64(4), T.int64(2)))
        inverse = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)))
        conv2d_winograd = T.alloc_buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(512), T.int64(9), T.int64(9)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3])
                data_pad[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(8) and T.int64(1) <= v_i3 and v_i3 < T.int64(8), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for ci, p, eps, nu in T.grid(T.int64(512), T.int64(16), T.int64(4), T.int64(4)):
            with T.block("input_tile"):
                v_ci, v_p, v_eps, v_nu = T.axis.remap("SSSS", [ci, p, eps, nu])
                T.reads(data_pad[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps, v_p % T.int64(4) * T.int64(2) + v_nu])
                T.writes(input_tile[v_ci, v_p, v_eps, v_nu])
                T.block_attr({"schedule_rule": "None"})
                input_tile[v_ci, v_p, v_eps, v_nu] = data_pad[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps, v_p % T.int64(4) * T.int64(2) + v_nu]
        for i, j in T.grid(T.int64(4), T.int64(4)):
            with T.block("B"):
                v_i, v_j = T.axis.remap("SS", [i, j])
                T.reads()
                T.writes(B[v_i, v_j])
                T.block_attr({"schedule_rule": "None"})
                B[v_i, v_j] = T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
        for eps, nu, ci, p, r_a, r_b in T.grid(T.int64(4), T.int64(4), T.int64(512), T.int64(16), T.int64(4), T.int64(4)):
            with T.block("data_pack"):
                v_eps, v_nu, v_ci, v_p, v_r_a, v_r_b = T.axis.remap("SSSSRR", [eps, nu, ci, p, r_a, r_b])
                T.reads(input_tile[v_ci, v_p, v_r_a, v_r_b], B[T.min(v_r_a, v_r_b):T.min(v_r_a, v_r_b) + (T.max(v_r_a, v_r_b) + T.int64(1) - T.min(v_r_a, v_r_b)), T.min(v_eps, v_nu):T.min(v_eps, v_nu) + (T.max(v_eps, v_nu) + T.int64(1) - T.min(v_eps, v_nu))])
                T.writes(data_pack[v_eps, v_nu, v_ci, v_p])
                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                with T.init():
                    data_pack[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                data_pack[v_eps, v_nu, v_ci, v_p] = data_pack[v_eps, v_nu, v_ci, v_p] + input_tile[v_ci, v_p, v_r_a, v_r_b] * B[v_r_a, v_eps] * B[v_r_b, v_nu]
        for eps, nu, co, p, ci in T.grid(T.int64(4), T.int64(4), T.int64(512), T.int64(16), T.int64(512)):
            with T.block("bgemm"):
                v_eps, v_nu, v_co, v_p, v_ci = T.axis.remap("SSSSR", [eps, nu, co, p, ci])
                T.reads(data_pack[v_eps, v_nu, v_ci, v_p], p1[v_eps, v_nu, v_ci, v_co])
                T.writes(bgemm[v_eps, v_nu, v_co, v_p])
                with T.init():
                    bgemm[v_eps, v_nu, v_co, v_p] = T.float32(0)
                bgemm[v_eps, v_nu, v_co, v_p] = bgemm[v_eps, v_nu, v_co, v_p] + data_pack[v_eps, v_nu, v_ci, v_p] * p1[v_eps, v_nu, v_ci, v_co]
        for i, j in T.grid(T.int64(4), T.int64(2)):
            with T.block("A"):
                v_i, v_j = T.axis.remap("SS", [i, j])
                T.reads()
                T.writes(A[v_i, v_j])
                T.block_attr({"schedule_rule": "None"})
                A[v_i, v_j] = T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
        for co, p, vh, vw, r_a, r_b in T.grid(T.int64(512), T.int64(16), T.int64(2), T.int64(2), T.int64(4), T.int64(4)):
            with T.block("inverse"):
                v_co, v_p, v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSSSRR", [co, p, vh, vw, r_a, r_b])
                T.reads(bgemm[v_r_a, v_r_b, v_co, v_p], A[T.min(v_r_a, v_r_b):T.min(v_r_a, v_r_b) + (T.max(v_r_a, v_r_b) + T.int64(1) - T.min(v_r_a, v_r_b)), T.min(v_vh, v_vw):T.min(v_vh, v_vw) + (T.max(v_vh, v_vw) + T.int64(1) - T.min(v_vh, v_vw))])
                T.writes(inverse[v_co, v_p, v_vh, v_vw])
                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                with T.init():
                    inverse[v_co, v_p, v_vh, v_vw] = T.float32(0)
                inverse[v_co, v_p, v_vh, v_vw] = inverse[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * A[v_r_a, v_vh] * A[v_r_b, v_vw]
        for n, co, h, w in T.grid(T.int64(1), T.int64(512), T.int64(7), T.int64(7)):
            with T.block("conv2d_winograd"):
                v_n, v_co, v_h, v_w = T.axis.remap("SSSS", [n, co, h, w])
                T.reads(inverse[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)])
                T.writes(conv2d_winograd[v_n, v_co, v_h, v_w])
                conv2d_winograd[v_n, v_co, v_h, v_w] = inverse[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(512), T.int64(7), T.int64(7)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(conv2d_winograd[v_ax0, v_ax1, v_ax2, v_ax3], p2[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3] = conv2d_winograd[v_ax0, v_ax1, v_ax2, v_ax3] + p2[v_ax0, v_ax1, v_ax2, v_ax3]
2023-11-10 23:34:19 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2023-11-10 23:34:19 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 512})
            input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
            data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
            bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
            inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
            data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
            bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
            data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
            for ci_p_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
                for ci_p_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("input_tile"):
                            v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(64) + ci_p_fused_1 // T.int64(16) + ax0)
                            v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                            v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                            T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                            T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                            T.block_attr({"schedule_rule": "None"})
                            input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                    for eps in T.unroll(T.int64(4)):
                        for nu in T.unroll(T.int64(4)):
                            for r_a in T.unroll(T.int64(4)):
                                for r_b in T.unroll(T.int64(4)):
                                    with T.block("data_pack"):
                                        v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(16))
                                        v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(16))
                                        v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                        T.reads(input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                        T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                        with T.init():
                                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                                        data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("data_pack_local"):
                            v0, v1 = T.axis.remap("SS", [ax0, ax1])
                            v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(64) + ci_p_fused_1 // T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                            T.reads(data_pack_local[v0, v1, v2, v3])
                            T.writes(data_pack[v0, v1, v2, v3])
                            data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
            for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(4), thread="blockIdx.x"):
                for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(32), thread="vthread.x"):
                    for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                        for ci_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(1024)):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(256))
                                    v1 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused % T.int64(256) // T.int64(64))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(64) // T.int64(4))
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused * T.int64(4) + ax0_ax1_ax2_ax3_fused % T.int64(4))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(131072)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(32768))
                                    v1 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused % T.int64(32768) // T.int64(8192))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(8192) // T.int64(512))
                                    v3 = T.axis.spatial(T.int64(512), ax0_ax1_ax2_ax3_fused % T.int64(512))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(2), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(2)):
                                with T.block("bgemm"):
                                    v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(16) * T.int64(2) + eps_3 + eps_4)
                                    v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(16) // T.int64(4) + nu_3 + nu_4)
                                    v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused % T.int64(4) // T.int64(2) * T.int64(256) + co_3 * T.int64(8) + co_4)
                                    v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused * T.int64(4) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(2) + p_3 * T.int64(2) + p_4)
                                    v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(16) + ci_1 + ci_2)
                                    T.reads(data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                    T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                                    bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(256), T.int64(2)):
                            with T.block("bgemm_local"):
                                v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(16) * T.int64(2) + ax0)
                                v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(16) // T.int64(4) + ax1)
                                v2 = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused % T.int64(4) // T.int64(2) * T.int64(256) + ax2)
                                v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused * T.int64(4) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(2) + ax3)
                                T.reads(bgemm_local[v0, v1, v2, v3])
                                T.writes(bgemm[v0, v1, v2, v3])
                                bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
            for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
                for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                        for ax2 in T.unroll(T.int64(2)):
                            for ax3 in T.unroll(T.int64(2)):
                                for ax4 in T.unroll(T.int64(4)):
                                    for ax5 in T.unroll(T.int64(4)):
                                        with T.block("inverse"):
                                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                            v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                            v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                            T.reads(bgemm[v_r_a, v_r_b, v_co, v_p])
                                            T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                            with T.init():
                                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                                            inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                    for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                        with T.block("conv2d_winograd"):
                            v_n = T.axis.spatial(T.int64(1), T.int64(0))
                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16))
                            v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                            v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                            T.where((n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                            T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                            T.writes(T_add[v_n, v_co, v_h, v_w])
                            T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[1, 2, 1, 2, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 4, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 1, 32, 8])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 2, 1, 1, 2])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[32, 16, 1])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
2023-11-10 23:34:19 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 512})
            input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
            data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
            bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
            inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
            data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
            bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
            data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
            for ci_p_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
                for ci_p_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("input_tile"):
                            v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(64) + ci_p_fused_1 // T.int64(16) + ax0)
                            v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                            v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                            T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                            T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                            T.block_attr({"schedule_rule": "None"})
                            input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                    for eps in T.unroll(T.int64(4)):
                        for nu in T.unroll(T.int64(4)):
                            for r_a in T.unroll(T.int64(4)):
                                for r_b in T.unroll(T.int64(4)):
                                    with T.block("data_pack"):
                                        v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(16))
                                        v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(16))
                                        v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                        T.reads(input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                        T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                        with T.init():
                                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                                        data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("data_pack_local"):
                            v0, v1 = T.axis.remap("SS", [ax0, ax1])
                            v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(64) + ci_p_fused_1 // T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                            T.reads(data_pack_local[v0, v1, v2, v3])
                            T.writes(data_pack[v0, v1, v2, v3])
                            data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
            for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(4), thread="blockIdx.x"):
                for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(32), thread="vthread.x"):
                    for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                        for ci_0_fused in T.serial(T.int64(32), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(1024)):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(256))
                                    v1 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused % T.int64(256) // T.int64(64))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(64) // T.int64(4))
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused * T.int64(4) + ax0_ax1_ax2_ax3_fused % T.int64(4))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(131072)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(32768))
                                    v1 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused % T.int64(32768) // T.int64(8192))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(8192) // T.int64(512))
                                    v3 = T.axis.spatial(T.int64(512), ax0_ax1_ax2_ax3_fused % T.int64(512))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(2), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(2)):
                                with T.block("bgemm"):
                                    v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(16) * T.int64(2) + eps_3 + eps_4)
                                    v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(16) // T.int64(4) + nu_3 + nu_4)
                                    v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused % T.int64(4) // T.int64(2) * T.int64(256) + co_3 * T.int64(8) + co_4)
                                    v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused * T.int64(4) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(2) + p_3 * T.int64(2) + p_4)
                                    v_ci = T.axis.reduce(T.int64(512), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                    T.reads(data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                    T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                                    bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(256), T.int64(2)):
                            with T.block("bgemm_local"):
                                v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(16) * T.int64(2) + ax0)
                                v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(16) // T.int64(4) + ax1)
                                v2 = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused % T.int64(4) // T.int64(2) * T.int64(256) + ax2)
                                v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused * T.int64(4) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(2) + ax3)
                                T.reads(bgemm_local[v0, v1, v2, v3])
                                T.writes(bgemm[v0, v1, v2, v3])
                                bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
            for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
                for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                        for ax2 in T.unroll(T.int64(2)):
                            for ax3 in T.unroll(T.int64(2)):
                                for ax4 in T.unroll(T.int64(4)):
                                    for ax5 in T.unroll(T.int64(4)):
                                        with T.block("inverse"):
                                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                            v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                            v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                            T.reads(bgemm[v_r_a, v_r_b, v_co, v_p])
                                            T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                            with T.init():
                                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                                            inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                    for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                        with T.block("conv2d_winograd"):
                            v_n = T.axis.spatial(T.int64(1), T.int64(0))
                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16))
                            v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                            v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                            T.where((n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                            T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                            T.writes(T_add[v_n, v_co, v_h, v_w])
                            T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[1, 2, 1, 2, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 4, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 1, 32, 8])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 2, 1, 1, 2])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[32, 16, 1])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
l118 = sch.fuse(l89, preserve_unit_iters=True)
sch.annotate(block_or_loop=l118, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l118, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l118, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
2023-11-10 23:34:19 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 512})
            input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
            data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
            bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
            inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
            data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
            bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
            data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
            for ci_p_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x"):
                for ci_p_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("input_tile"):
                            v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(64) + ci_p_fused_1 // T.int64(16) + ax0)
                            v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                            v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                            T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                            T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                            T.block_attr({"schedule_rule": "None"})
                            input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                    for eps in T.unroll(T.int64(4)):
                        for nu in T.unroll(T.int64(4)):
                            for r_a in T.unroll(T.int64(4)):
                                for r_b in T.unroll(T.int64(4)):
                                    with T.block("data_pack"):
                                        v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                        v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) // T.int64(16))
                                        v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(1024) + ci_p_fused_1) % T.int64(16))
                                        v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                        T.reads(input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                        T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                        with T.init():
                                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                                        data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("data_pack_local"):
                            v0, v1 = T.axis.remap("SS", [ax0, ax1])
                            v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(64) + ci_p_fused_1 // T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                            T.reads(data_pack_local[v0, v1, v2, v3])
                            T.writes(data_pack[v0, v1, v2, v3])
                            data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
            for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(4), thread="blockIdx.x"):
                for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(32), thread="vthread.x"):
                    for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                        for ci_0_fused in T.serial(T.int64(32), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(1024)):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(256))
                                    v1 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused % T.int64(256) // T.int64(64))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(64) // T.int64(4))
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused * T.int64(4) + ax0_ax1_ax2_ax3_fused % T.int64(4))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(131072)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(32768))
                                    v1 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused % T.int64(32768) // T.int64(8192))
                                    v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(8192) // T.int64(512))
                                    v3 = T.axis.spatial(T.int64(512), ax0_ax1_ax2_ax3_fused % T.int64(512))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(2), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(2)):
                                with T.block("bgemm"):
                                    v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(16) * T.int64(2) + eps_3 + eps_4)
                                    v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(16) // T.int64(4) + nu_3 + nu_4)
                                    v_co = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused % T.int64(4) // T.int64(2) * T.int64(256) + co_3 * T.int64(8) + co_4)
                                    v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused * T.int64(4) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(2) + p_3 * T.int64(2) + p_4)
                                    v_ci = T.axis.reduce(T.int64(512), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                    T.reads(data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                    T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                                    bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(256), T.int64(2)):
                            with T.block("bgemm_local"):
                                v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(16) * T.int64(2) + ax0)
                                v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused % T.int64(16) // T.int64(4) + ax1)
                                v2 = T.axis.spatial(T.int64(512), eps_1_nu_1_co_1_p_1_fused % T.int64(4) // T.int64(2) * T.int64(256) + ax2)
                                v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused * T.int64(4) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(2) + ax3)
                                T.reads(bgemm_local[v0, v1, v2, v3])
                                T.writes(bgemm[v0, v1, v2, v3])
                                bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
            for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
                for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                        for ax2 in T.unroll(T.int64(2)):
                            for ax3 in T.unroll(T.int64(2)):
                                for ax4 in T.unroll(T.int64(4)):
                                    for ax5 in T.unroll(T.int64(4)):
                                        with T.block("inverse"):
                                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                            v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                            v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                            T.reads(bgemm[v_r_a, v_r_b, v_co, v_p])
                                            T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                            with T.init():
                                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                                            inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                    for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                        with T.block("conv2d_winograd"):
                            v_n = T.axis.spatial(T.int64(1), T.int64(0))
                            v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16))
                            v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                            v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                            T.where((n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                            T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                            T.writes(T_add[v_n, v_co, v_h, v_w])
                            T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[1, 2, 1, 2, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 4, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 1, 32, 8])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 2, 1, 1, 2])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[32, 16, 1])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
l118 = sch.fuse(l89, preserve_unit_iters=True)
sch.annotate(block_or_loop=l118, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l118, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l118, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
2023-11-11 00:07:43 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 00:07:43 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2023-11-11 00:07:50 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 501 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 00:07:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1003 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 00:08:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1500 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 00:08:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2001 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 00:08:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2503 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 00:08:21 [INFO] [evolutionary_search.cc:723] Sampled 57 candidate(s)
2023-11-11 00:08:38 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 158 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 00:08:52 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 114 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 00:09:07 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 123 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 00:09:22 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 126 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 00:09:23 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9998  0.9997  0.9982  0.9975  0.9973  0.9968  0.9962  0.9954  0.9952  0.9949  0.9947  0.9941  0.9937  0.9911  0.9893  0.9890
[17 : 32]:	0.9888  0.9886  0.9875  0.9873  0.9842  0.9841  0.9835  0.9834  0.9823  0.9811  0.9807  0.9801  0.9787  0.9774  0.9770  0.9763
[33 : 48]:	0.9760  0.9746  0.9744  0.9740  0.9734  0.9732  0.9732  0.9722  0.9702  0.9698  0.9693  0.9689  0.9671  0.9662  0.9662  0.9649
[49 : 64]:	0.9640  0.9639  0.9639  0.9632  0.9629  0.9620  0.9615  0.9588  0.9588  0.9587  0.9572  0.9567  0.9548  0.9547  0.9545  0.9533
2023-11-11 00:09:23 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 00:09:24 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #1: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(8), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(4)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_3_init * T.int64(4) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + p_3_init * T.int64(4) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(256), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(2))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(128))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(2))
                                        v2 = T.axis.spatial(T.int64(512), ci_0_fused * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(256))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(256) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(4), T.int64(1), T.int64(1), T.int64(4)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_3 * T.int64(4) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + p_3 * T.int64(4) + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0_fused * T.int64(2) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(8)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(256) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(128) + eps_2_nu_2_co_2_p_2_fused + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 4])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 2, 128, 1, 1])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 2, 1, 2, 4])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[256, 1, 2])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
l118 = sch.fuse(l89, preserve_unit_iters=True)
sch.annotate(block_or_loop=l118, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l118, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l118, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b4)
v119 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v119)
l120, l121, l122, l123, l124, l125 = sch.get_loops(block=b3)
l126 = sch.fuse(l120, l121, l122, l123, preserve_unit_iters=True)
v127 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l128, l129 = sch.split(loop=l126, factors=[None, v127], preserve_unit_iters=True)
sch.bind(loop=l128, thread_axis="blockIdx.x")
sch.bind(loop=l129, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l130, l131, l132, l133, l134 = sch.get_loops(block=b96)
l135, l136, l137 = sch.split(loop=l134, factors=[None, 128, 4], preserve_unit_iters=True)
sch.vectorize(loop=l137)
sch.bind(loop=l136, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l138, l139, l140, l141, l142 = sch.get_loops(block=b107)
l143, l144, l145 = sch.split(loop=l142, factors=[None, 128, 4], preserve_unit_iters=True)
sch.vectorize(loop=l145)
sch.bind(loop=l144, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b151)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b152)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b153)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b154)
l217, l218, l219, l220 = sch.get_loops(block=b155)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #2: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(16), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(512), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(512) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(32) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(16), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) // T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(8) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(16)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(2048))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(2048) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(1024))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(1024) // T.int64(256))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(256) // T.int64(8))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(8))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) // T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(8) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(32) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(8) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(64) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(8) // T.int64(2) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(8), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=4)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 2, 2, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[64, 4, 2, 1, 1])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 2, 8, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[16, 4, 8])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #3: Error in running:
LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(16) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(4) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) // T.int64(2) * T.int64(2) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(2) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(256)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(64))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64) // T.int64(16))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16) // T.int64(8))
                                    v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(8))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(64))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64) // T.int64(16))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16) // T.int64(8))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(8))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(16) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(4) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) // T.int64(2) * T.int64(2) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(2) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(2) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(16) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused % T.int64(16) // T.int64(4) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused // T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(4) // T.int64(2) * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_0_nu_0_co_0_p_0_fused % T.int64(2) * T.int64(8) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(4) + eps_2_nu_2_co_2_p_2_fused % T.int64(2) * T.int64(2) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[64, 2, 2, 1, 2])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 2, 2, 2, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[256, 2, 1])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135 = sch.split(loop=l133, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l136, l137, l138, l139, l140 = sch.get_loops(block=b107)
l141, l142 = sch.split(loop=l140, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l142, thread_axis="threadIdx.x")
b143 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b143, ann_key="meta_schedule.unroll_explicit")
b144, b145, b146, b147, b148, b149, b150, b151, b152 = sch.get_child_blocks(b143)
l153, l154, l155, l156, l157, l158 = sch.get_loops(block=b144)
l159, l160, l161, l162, l163, l164 = sch.get_loops(block=b145)
sch.annotate(block_or_loop=l159, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l159, ann_key="pragma_unroll_explicit", ann_val=1)
l165, l166, l167, l168, l169, l170 = sch.get_loops(block=b146)
l171, l172, l173, l174, l175, l176 = sch.get_loops(block=b147)
l177, l178, l179, l180, l181, l182 = sch.get_loops(block=b148)
l183, l184, l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l183, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l183, ann_key="pragma_unroll_explicit", ann_val=1)
l197, l198, l199, l200, l201, l202, l203 = sch.get_loops(block=b150)
l204, l205, l206, l207, l208, l209, l210, l211 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l204, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l204, ann_key="pragma_unroll_explicit", ann_val=1)
l212, l213, l214, l215 = sch.get_loops(block=b152)
b216 = sch.get_block(name="data_pack", func_name="main")
l217, l218, l219, l220, l221, l222 = sch.get_loops(block=b216)
b223 = sch.decompose_reduction(block=b216, loop=l221)
b224 = sch.get_block(name="bgemm", func_name="main")
l225, l226, l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238 = sch.get_loops(block=b224)
b239 = sch.decompose_reduction(block=b224, loop=l228)
b240 = sch.get_block(name="inverse", func_name="main")
l241, l242, l243, l244, l245, l246, l247, l248 = sch.get_loops(block=b240)
b249 = sch.decompose_reduction(block=b240, loop=l247)
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #4: GFLOPs: 2188.0504. Time: 64.9469 us. Best GFLOPs: 2188.0504
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #5: GFLOPs: 1840.0522. Time: 77.2299 us. Best GFLOPs: 2188.0504
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #6: GFLOPs: 132.7005. Time: 1070.8862 us. Best GFLOPs: 2188.0504
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #7: GFLOPs: 974.2369. Time: 145.8651 us. Best GFLOPs: 2188.0504
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #8: GFLOPs: 1441.7273. Time: 98.5673 us. Best GFLOPs: 2188.0504
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #9: GFLOPs: 488.9610. Time: 290.6308 us. Best GFLOPs: 2188.0504
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #10: GFLOPs: 1075.0568. Time: 132.1857 us. Best GFLOPs: 2188.0504
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #11: GFLOPs: 1869.7674. Time: 76.0026 us. Best GFLOPs: 2188.0504
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #12: GFLOPs: 686.2395. Time: 207.0810 us. Best GFLOPs: 2188.0504
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #13: GFLOPs: 666.0663. Time: 213.3529 us. Best GFLOPs: 2188.0504
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #14: GFLOPs: 1686.7882. Time: 84.2472 us. Best GFLOPs: 2188.0504
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #15: GFLOPs: 2512.7039. Time: 56.5555 us. Best GFLOPs: 2512.7039
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #16: GFLOPs: 1986.0775. Time: 71.5517 us. Best GFLOPs: 2512.7039
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #17: GFLOPs: 185.6134. Time: 765.6080 us. Best GFLOPs: 2512.7039
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #18: GFLOPs: 849.5132. Time: 167.2807 us. Best GFLOPs: 2512.7039
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #19: GFLOPs: 502.1675. Time: 282.9875 us. Best GFLOPs: 2512.7039
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #20: GFLOPs: 4345.8234. Time: 32.6997 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #21: GFLOPs: 962.6229. Time: 147.6249 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #22: GFLOPs: 931.7131. Time: 152.5224 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #23: GFLOPs: 1146.0189. Time: 124.0007 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #24: GFLOPs: 1279.5658. Time: 111.0589 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #25: GFLOPs: 2763.2448. Time: 51.4276 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #26: GFLOPs: 948.4697. Time: 149.8278 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #27: GFLOPs: 1099.4040. Time: 129.2583 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #28: GFLOPs: 188.6717. Time: 753.1979 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #29: GFLOPs: 420.4868. Time: 337.9586 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #30: GFLOPs: 38.2415. Time: 3716.0419 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #31: GFLOPs: 809.6470. Time: 175.5174 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #32: GFLOPs: 2950.2750. Time: 48.1674 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #33: GFLOPs: 1614.5618. Time: 88.0159 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #34: GFLOPs: 153.4826. Time: 925.8843 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #35: GFLOPs: 63.2700. Time: 2246.0415 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #36: GFLOPs: 472.0589. Time: 301.0369 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #37: GFLOPs: 976.1411. Time: 145.5805 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #38: GFLOPs: 1264.2214. Time: 112.4068 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #39: GFLOPs: 1169.9665. Time: 121.4626 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #40: GFLOPs: 126.1875. Time: 1126.1584 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #41: GFLOPs: 1081.6271. Time: 131.3827 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #42: GFLOPs: 2182.2021. Time: 65.1210 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #43: GFLOPs: 1504.8237. Time: 94.4344 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #44: GFLOPs: 3433.8696. Time: 41.3840 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #45: GFLOPs: 670.7377. Time: 211.8669 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #46: GFLOPs: 2022.4039. Time: 70.2664 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #47: GFLOPs: 938.5697. Time: 151.4082 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #48: GFLOPs: 721.5446. Time: 196.9485 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #49: GFLOPs: 2533.7093. Time: 56.0866 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #50: GFLOPs: 1230.2944. Time: 115.5066 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #51: GFLOPs: 125.3487. Time: 1133.6946 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #52: GFLOPs: 1613.8151. Time: 88.0566 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #53: GFLOPs: 2659.9945. Time: 53.4238 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #54: GFLOPs: 1690.9064. Time: 84.0420 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #55: GFLOPs: 81.1417. Time: 1751.3459 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #56: GFLOPs: 993.4192. Time: 143.0485 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #57: GFLOPs: 2317.6934. Time: 61.3140 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #58: GFLOPs: 187.8242. Time: 756.5966 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #59: GFLOPs: 609.7308. Time: 233.0654 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #60: GFLOPs: 178.0345. Time: 798.1998 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #61: GFLOPs: 2347.6469. Time: 60.5317 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #62: GFLOPs: 160.2893. Time: 886.5665 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #63: GFLOPs: 491.6965. Time: 289.0139 us. Best GFLOPs: 4345.8234
2023-11-11 00:28:52 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #64: GFLOPs: 2276.6938. Time: 62.4182 us. Best GFLOPs: 4345.8234
2023-11-11 01:04:22 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 01:04:24 [INFO] [evolutionary_search.cc:715] Picked top 61 candidate(s) from database
2023-11-11 01:04:30 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 443 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:04:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 883 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:04:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1321 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:04:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1764 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:04:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2203 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:04:57 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2023-11-11 01:05:14 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 103 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:05:32 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 111 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:05:51 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 104 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:06:10 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 88 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:06:15 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0467  1.0389  1.0382  1.0321  1.0148  1.0091  0.9960  0.9933  0.9853  0.9787  0.9781  0.9769  0.9737  0.9725  0.9712  0.9686
[17 : 32]:	0.9685  0.9615  0.9613  0.9576  0.9545  0.9489  0.9483  0.9419  0.9401  0.9366  0.9344  0.9324  0.9311  0.9287  0.9285  0.9285
[33 : 48]:	0.9270  0.9265  0.9211  0.9185  0.9180  0.9178  0.9177  0.9153  0.9153  0.9036  0.9023  0.9007  0.8989  0.8974  0.8962  0.8959
[49 : 64]:	0.8947  0.8841  0.8830  0.8816  0.8816  0.8802  0.8785  0.8739  0.8705  0.8705  0.8694  0.8686  0.8674  0.8670  0.8659  0.8646
2023-11-11 01:06:15 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 01:06:15 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #65: GFLOPs: 4420.4721. Time: 32.1475 us. Best GFLOPs: 4420.4721
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #66: GFLOPs: 4335.0508. Time: 32.7810 us. Best GFLOPs: 4420.4721
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #67: GFLOPs: 4366.5122. Time: 32.5448 us. Best GFLOPs: 4420.4721
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #68: GFLOPs: 1510.2761. Time: 94.0935 us. Best GFLOPs: 4420.4721
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #69: GFLOPs: 4420.7051. Time: 32.1458 us. Best GFLOPs: 4420.7051
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #70: GFLOPs: 4364.1901. Time: 32.5621 us. Best GFLOPs: 4420.7051
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #71: GFLOPs: 2016.5863. Time: 70.4692 us. Best GFLOPs: 4420.7051
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #72: GFLOPs: 1497.8158. Time: 94.8762 us. Best GFLOPs: 4420.7051
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #73: GFLOPs: 4374.7506. Time: 32.4835 us. Best GFLOPs: 4420.7051
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #74: GFLOPs: 4445.4401. Time: 31.9669 us. Best GFLOPs: 4445.4401
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #75: GFLOPs: 4444.5658. Time: 31.9732 us. Best GFLOPs: 4445.4401
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #76: GFLOPs: 4865.5362. Time: 29.2069 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #77: GFLOPs: 1499.4073. Time: 94.7755 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #78: GFLOPs: 1507.7408. Time: 94.2517 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #79: GFLOPs: 4401.1540. Time: 32.2886 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #80: GFLOPs: 4443.8836. Time: 31.9781 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #81: GFLOPs: 1493.6674. Time: 95.1397 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #82: GFLOPs: 1538.3148. Time: 92.3784 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #83: GFLOPs: 1634.5867. Time: 86.9377 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #84: GFLOPs: 3666.3522. Time: 38.7598 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #85: GFLOPs: 1478.7769. Time: 96.0978 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #86: GFLOPs: 1489.6114. Time: 95.3988 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #87: GFLOPs: 4430.0995. Time: 32.0776 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #88: GFLOPs: 1568.2423. Time: 90.6155 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #89: GFLOPs: 4330.3136. Time: 32.8168 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #90: GFLOPs: 4328.8032. Time: 32.8283 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #91: GFLOPs: 1475.2572. Time: 96.3270 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #92: GFLOPs: 1475.8439. Time: 96.2887 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #93: GFLOPs: 3578.4418. Time: 39.7120 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #94: GFLOPs: 1568.5349. Time: 90.5986 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #95: GFLOPs: 1557.3020. Time: 91.2521 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #96: GFLOPs: 4254.0785. Time: 33.4049 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #97: GFLOPs: 1558.2124. Time: 91.1988 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #98: GFLOPs: 3621.7855. Time: 39.2368 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #99: GFLOPs: 1576.3985. Time: 90.1467 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #100: GFLOPs: 4364.6201. Time: 32.5589 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #101: GFLOPs: 4368.5333. Time: 32.5297 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #102: GFLOPs: 3839.5298. Time: 37.0116 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #103: GFLOPs: 1648.8579. Time: 86.1852 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #104: GFLOPs: 4433.8149. Time: 32.0508 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #105: GFLOPs: 4268.0118. Time: 33.2959 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #106: GFLOPs: 3392.3308. Time: 41.8907 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #107: GFLOPs: 3383.1990. Time: 42.0038 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #108: GFLOPs: 1542.0502. Time: 92.1547 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #109: GFLOPs: 3812.4707. Time: 37.2743 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #110: GFLOPs: 1506.7897. Time: 94.3112 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #111: GFLOPs: 31.2365. Time: 4549.3993 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #112: GFLOPs: 4424.4639. Time: 32.1185 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #113: GFLOPs: 3833.8152. Time: 37.0668 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #114: GFLOPs: 1542.0601. Time: 92.1541 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #115: GFLOPs: 4205.1548. Time: 33.7936 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #116: GFLOPs: 4378.5652. Time: 32.4552 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #117: GFLOPs: 3234.8538. Time: 43.9300 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #118: GFLOPs: 4406.5723. Time: 32.2489 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #119: GFLOPs: 4311.4960. Time: 32.9601 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #120: GFLOPs: 1559.2865. Time: 91.1360 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #121: GFLOPs: 4483.5866. Time: 31.6950 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #122: GFLOPs: 4470.2289. Time: 31.7897 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #123: GFLOPs: 3513.2589. Time: 40.4488 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #124: GFLOPs: 1514.6602. Time: 93.8211 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #125: GFLOPs: 4011.9223. Time: 35.4212 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #126: GFLOPs: 1417.0586. Time: 100.2832 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #127: GFLOPs: 303.7741. Time: 467.8053 us. Best GFLOPs: 4865.5362
2023-11-11 01:06:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #128: GFLOPs: 1482.7483. Time: 95.8404 us. Best GFLOPs: 4865.5362
2023-11-11 01:50:06 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 01:50:09 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 01:50:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:50:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 806 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:50:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1208 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:50:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1609 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:50:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2008 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:50:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2405 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:50:45 [INFO] [evolutionary_search.cc:723] Sampled 55 candidate(s)
2023-11-11 01:51:01 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 106 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:51:20 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 118 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:51:39 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 93 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:51:58 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 125 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 01:52:03 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.1638  1.0748  1.0612  1.0572  1.0468  1.0441  1.0419  1.0216  1.0071  1.0039  0.9884  0.9865  0.9810  0.9779  0.9778  0.9722
[17 : 32]:	0.9618  0.9607  0.9606  0.9602  0.9598  0.9556  0.9526  0.9503  0.9495  0.9489  0.9488  0.9484  0.9479  0.9465  0.9461  0.9449
[33 : 48]:	0.9440  0.9429  0.9425  0.9417  0.9403  0.9398  0.9393  0.9393  0.9383  0.9379  0.9368  0.9358  0.9354  0.9349  0.9311  0.9292
[49 : 64]:	0.9292  0.9288  0.9278  0.9278  0.9277  0.9268  0.9265  0.9264  0.9260  0.9259  0.9248  0.9247  0.9241  0.9238  0.9235  0.9228
2023-11-11 01:52:03 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 01:52:03 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #129: GFLOPs: 2450.0288. Time: 58.0022 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #130: GFLOPs: 1320.3905. Time: 107.6251 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #131: GFLOPs: 4781.4714. Time: 29.7204 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #132: GFLOPs: 4741.3895. Time: 29.9716 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #133: GFLOPs: 3151.8331. Time: 45.0871 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #134: GFLOPs: 4377.0664. Time: 32.4663 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #135: GFLOPs: 4734.3429. Time: 30.0162 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #136: GFLOPs: 2496.5824. Time: 56.9207 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #137: GFLOPs: 3077.1140. Time: 46.1820 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #138: GFLOPs: 4251.4989. Time: 33.4252 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #139: GFLOPs: 4734.9221. Time: 30.0126 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #140: GFLOPs: 4844.4889. Time: 29.3338 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #141: GFLOPs: 4734.4522. Time: 30.0155 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #142: GFLOPs: 2415.8680. Time: 58.8224 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #143: GFLOPs: 2797.5457. Time: 50.7971 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #144: GFLOPs: 2659.2892. Time: 53.4380 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #145: GFLOPs: 4858.4458. Time: 29.2495 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #146: GFLOPs: 4768.3892. Time: 29.8019 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #147: GFLOPs: 2681.7589. Time: 52.9903 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #148: GFLOPs: 4771.1207. Time: 29.7849 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #149: GFLOPs: 3061.9978. Time: 46.4099 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #150: GFLOPs: 4813.7577. Time: 29.5210 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #151: GFLOPs: 3176.8148. Time: 44.7326 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #152: GFLOPs: 4155.9496. Time: 34.1937 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #153: GFLOPs: 4576.4404. Time: 31.0519 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #154: GFLOPs: 3061.3195. Time: 46.4202 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #155: GFLOPs: 3075.6262. Time: 46.2043 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #156: GFLOPs: 4048.5274. Time: 35.1009 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #157: GFLOPs: 4769.8205. Time: 29.7930 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #158: GFLOPs: 4278.7849. Time: 33.2120 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #159: GFLOPs: 4074.8662. Time: 34.8741 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #160: GFLOPs: 2975.5440. Time: 47.7584 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #161: GFLOPs: 3578.1797. Time: 39.7149 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #162: GFLOPs: 4084.8318. Time: 34.7890 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #163: GFLOPs: 3997.3359. Time: 35.5505 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #164: GFLOPs: 1901.6239. Time: 74.7294 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #165: GFLOPs: 3556.0487. Time: 39.9621 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #166: GFLOPs: 4276.1038. Time: 33.2329 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #167: GFLOPs: 4740.1953. Time: 29.9792 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #168: GFLOPs: 4355.7472. Time: 32.6252 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #169: GFLOPs: 3557.0216. Time: 39.9512 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #170: GFLOPs: 4727.3787. Time: 30.0605 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #171: GFLOPs: 4828.7623. Time: 29.4293 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #172: GFLOPs: 3553.9992. Time: 39.9851 us. Best GFLOPs: 4865.5362
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #173: GFLOPs: 4877.0819. Time: 29.1377 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #174: GFLOPs: 3523.5671. Time: 40.3305 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #175: GFLOPs: 2677.2244. Time: 53.0800 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #176: GFLOPs: 4771.5299. Time: 29.7823 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #177: GFLOPs: 4842.1306. Time: 29.3481 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #178: GFLOPs: 3555.9748. Time: 39.9629 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #179: GFLOPs: 4467.3520. Time: 31.8102 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #180: GFLOPs: 4358.6045. Time: 32.6038 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #181: GFLOPs: 4801.4566. Time: 29.5967 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #182: GFLOPs: 4757.3365. Time: 29.8712 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #183: GFLOPs: 4843.7901. Time: 29.3380 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #184: GFLOPs: 3603.7500. Time: 39.4331 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #185: GFLOPs: 2372.3857. Time: 59.9005 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #186: GFLOPs: 4099.5919. Time: 34.6637 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #187: GFLOPs: 3959.0346. Time: 35.8944 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #188: GFLOPs: 3874.9704. Time: 36.6731 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #189: GFLOPs: 3604.9723. Time: 39.4198 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #190: GFLOPs: 39.8532. Time: 3565.7632 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #191: GFLOPs: 1113.7178. Time: 127.5971 us. Best GFLOPs: 4877.0819
2023-11-11 01:52:42 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #192: GFLOPs: 790.1015. Time: 179.8593 us. Best GFLOPs: 4877.0819
2023-11-11 02:43:22 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 02:43:25 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 02:43:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 400 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 02:43:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 800 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 02:43:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1196 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 02:43:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1595 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 02:43:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2000 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 02:43:55 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2023-11-11 02:44:10 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 95 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 02:44:29 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 99 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 02:44:47 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 107 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 02:45:05 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 102 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 02:45:10 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0554  1.0516  1.0460  1.0351  1.0186  1.0186  1.0143  1.0135  1.0110  1.0097  1.0047  1.0044  1.0041  1.0020  0.9987  0.9987
[17 : 32]:	0.9976  0.9964  0.9955  0.9949  0.9945  0.9926  0.9916  0.9915  0.9896  0.9895  0.9885  0.9883  0.9875  0.9870  0.9867  0.9866
[33 : 48]:	0.9861  0.9851  0.9850  0.9849  0.9848  0.9842  0.9832  0.9821  0.9817  0.9816  0.9806  0.9801  0.9798  0.9783  0.9778  0.9775
[49 : 64]:	0.9774  0.9760  0.9751  0.9750  0.9741  0.9740  0.9735  0.9731  0.9731  0.9730  0.9728  0.9726  0.9719  0.9719  0.9718  0.9714
2023-11-11 02:45:11 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 02:45:11 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #193: GFLOPs: 4816.5644. Time: 29.5038 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #194: GFLOPs: 4788.7888. Time: 29.6750 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #195: GFLOPs: 4792.6621. Time: 29.6510 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #196: GFLOPs: 4808.1196. Time: 29.5557 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #197: GFLOPs: 4552.2183. Time: 31.2171 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #198: GFLOPs: 4555.6450. Time: 31.1936 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #199: GFLOPs: 4552.4578. Time: 31.2155 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #200: GFLOPs: 4639.6562. Time: 30.6288 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #201: GFLOPs: 4846.1430. Time: 29.3238 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #202: GFLOPs: 4803.7282. Time: 29.5827 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #203: GFLOPs: 4830.2617. Time: 29.4202 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #204: GFLOPs: 4746.1409. Time: 29.9416 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #205: GFLOPs: 4758.1093. Time: 29.8663 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #206: GFLOPs: 4791.3911. Time: 29.6588 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #207: GFLOPs: 4540.9326. Time: 31.2947 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #208: GFLOPs: 4843.7991. Time: 29.3380 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #209: GFLOPs: 4554.8274. Time: 31.1992 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #210: GFLOPs: 4557.1922. Time: 31.1830 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #211: GFLOPs: 4740.5095. Time: 29.9772 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #212: GFLOPs: 4821.6884. Time: 29.4725 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #213: GFLOPs: 4545.7333. Time: 31.2617 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #214: GFLOPs: 4755.8629. Time: 29.8804 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #215: GFLOPs: 4756.7487. Time: 29.8748 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #216: GFLOPs: 4714.3194. Time: 30.1437 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #217: GFLOPs: 4837.7667. Time: 29.3745 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #218: GFLOPs: 4763.1170. Time: 29.8349 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #219: GFLOPs: 4800.7785. Time: 29.6009 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #220: GFLOPs: 4791.3923. Time: 29.6588 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #221: GFLOPs: 4760.2812. Time: 29.8527 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #222: GFLOPs: 4794.1241. Time: 29.6419 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #223: GFLOPs: 4825.7438. Time: 29.4477 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #224: GFLOPs: 4797.4482. Time: 29.6214 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #225: GFLOPs: 4760.8142. Time: 29.8493 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #226: GFLOPs: 4843.0409. Time: 29.3425 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #227: GFLOPs: 4793.3293. Time: 29.6469 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #228: GFLOPs: 4794.5373. Time: 29.6394 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #229: GFLOPs: 4744.7867. Time: 29.9502 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #230: GFLOPs: 4829.9426. Time: 29.4221 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #231: GFLOPs: 4833.9667. Time: 29.3976 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #232: GFLOPs: 4743.5908. Time: 29.9577 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #233: GFLOPs: 4792.8003. Time: 29.6501 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #234: GFLOPs: 4755.9280. Time: 29.8800 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #235: GFLOPs: 4554.8274. Time: 31.1992 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #236: GFLOPs: 4831.6664. Time: 29.4116 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #237: GFLOPs: 4745.3711. Time: 29.9465 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #238: GFLOPs: 4646.6344. Time: 30.5828 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #239: GFLOPs: 4754.3642. Time: 29.8898 us. Best GFLOPs: 4877.0819
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #240: GFLOPs: 4996.8160. Time: 28.4395 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #241: GFLOPs: 4702.9762. Time: 30.2164 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #242: GFLOPs: 4711.8049. Time: 30.1598 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #243: GFLOPs: 4718.8470. Time: 30.1148 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #244: GFLOPs: 4733.7624. Time: 30.0199 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #245: GFLOPs: 4780.3275. Time: 29.7275 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #246: GFLOPs: 4777.2447. Time: 29.7467 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #247: GFLOPs: 4757.4303. Time: 29.8706 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #248: GFLOPs: 4624.5383. Time: 30.7289 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #249: GFLOPs: 4799.6310. Time: 29.6079 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #250: GFLOPs: 4749.1351. Time: 29.9227 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #251: GFLOPs: 4709.2043. Time: 30.1765 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #252: GFLOPs: 4710.2392. Time: 30.1698 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #253: GFLOPs: 4726.3791. Time: 30.0668 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #254: GFLOPs: 1481.5397. Time: 95.9185 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #255: GFLOPs: 161.9594. Time: 877.4243 us. Best GFLOPs: 4996.8160
2023-11-11 02:45:48 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #256: GFLOPs: 187.9732. Time: 755.9969 us. Best GFLOPs: 4996.8160
2023-11-11 03:22:51 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 03:22:54 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 03:22:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 03:23:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 804 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 03:23:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1207 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 03:23:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1609 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 03:23:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2009 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 03:23:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2407 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 03:23:29 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2023-11-11 03:23:44 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 112 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 03:24:02 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 95 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 03:24:20 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 109 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 03:24:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 117 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 03:24:44 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.2869  1.2836  1.0483  0.9842  0.9839  0.9816  0.9806  0.9793  0.9776  0.9775  0.9774  0.9770  0.9764  0.9754  0.9753  0.9733
[17 : 32]:	0.9733  0.9722  0.9712  0.9710  0.9710  0.9703  0.9702  0.9695  0.9680  0.9679  0.9668  0.9666  0.9666  0.9666  0.9664  0.9663
[33 : 48]:	0.9660  0.9659  0.9658  0.9656  0.9656  0.9654  0.9646  0.9642  0.9641  0.9639  0.9639  0.9639  0.9639  0.9637  0.9635  0.9632
[49 : 64]:	0.9626  0.9621  0.9621  0.9620  0.9617  0.9617  0.9615  0.9615  0.9614  0.9612  0.9612  0.9611  0.9608  0.9608  0.9608  0.9607
2023-11-11 03:24:45 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 03:24:45 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #257: GFLOPs: 1112.3158. Time: 127.7579 us. Best GFLOPs: 4996.8160
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #258: GFLOPs: 394.4891. Time: 360.2309 us. Best GFLOPs: 4996.8160
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #259: GFLOPs: 3202.0611. Time: 44.3799 us. Best GFLOPs: 4996.8160
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #260: GFLOPs: 5100.3086. Time: 27.8625 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #261: GFLOPs: 5054.4967. Time: 28.1150 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #262: GFLOPs: 4948.3729. Time: 28.7180 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #263: GFLOPs: 4964.4058. Time: 28.6252 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #264: GFLOPs: 3983.9662. Time: 35.6698 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #265: GFLOPs: 5007.6365. Time: 28.3781 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #266: GFLOPs: 4980.8532. Time: 28.5307 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #267: GFLOPs: 5047.6275. Time: 28.1533 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #268: GFLOPs: 4982.1989. Time: 28.5230 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #269: GFLOPs: 4935.9477. Time: 28.7902 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #270: GFLOPs: 5019.4362. Time: 28.3114 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #271: GFLOPs: 4909.7703. Time: 28.9437 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #272: GFLOPs: 4874.5782. Time: 29.1527 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #273: GFLOPs: 4808.1546. Time: 29.5554 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #274: GFLOPs: 4983.3482. Time: 28.5164 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #275: GFLOPs: 4921.1916. Time: 28.8766 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #276: GFLOPs: 1144.2501. Time: 124.1924 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #277: GFLOPs: 1084.3025. Time: 131.0586 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #278: GFLOPs: 4871.0837. Time: 29.1736 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #279: GFLOPs: 4847.8463. Time: 29.3135 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #280: GFLOPs: 4873.9426. Time: 29.1565 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #281: GFLOPs: 4494.9169. Time: 31.6151 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #282: GFLOPs: 4981.1372. Time: 28.5291 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #283: GFLOPs: 4877.7060. Time: 29.1340 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #284: GFLOPs: 4984.8570. Time: 28.5078 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #285: GFLOPs: 4932.0282. Time: 28.8131 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #286: GFLOPs: 4901.3436. Time: 28.9935 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #287: GFLOPs: 5003.6078. Time: 28.4009 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #288: GFLOPs: 4910.5658. Time: 28.9391 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #289: GFLOPs: 4869.6719. Time: 29.1821 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #290: GFLOPs: 4830.1661. Time: 29.4208 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #291: GFLOPs: 4892.2667. Time: 29.0473 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #292: GFLOPs: 4924.0892. Time: 28.8596 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #293: GFLOPs: 4964.7858. Time: 28.6230 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #294: GFLOPs: 4918.4781. Time: 28.8925 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #295: GFLOPs: 4947.5783. Time: 28.7226 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #296: GFLOPs: 4427.3234. Time: 32.0978 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #297: GFLOPs: 4908.0877. Time: 28.9537 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #298: GFLOPs: 4591.3114. Time: 30.9513 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #299: GFLOPs: 4902.4612. Time: 28.9869 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #300: GFLOPs: 4903.1187. Time: 28.9830 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #301: GFLOPs: 4895.4356. Time: 29.0285 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #302: GFLOPs: 4829.4638. Time: 29.4250 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #303: GFLOPs: 4904.1053. Time: 28.9772 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #304: GFLOPs: 4863.1353. Time: 29.2213 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #305: GFLOPs: 4946.8256. Time: 28.7269 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #306: GFLOPs: 4923.1258. Time: 28.8652 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #307: GFLOPs: 4901.2204. Time: 28.9942 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #308: GFLOPs: 4814.3668. Time: 29.5173 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #309: GFLOPs: 4839.2799. Time: 29.3653 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #310: GFLOPs: 4838.5095. Time: 29.3700 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #311: GFLOPs: 4873.9932. Time: 29.1562 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #312: GFLOPs: 4857.1221. Time: 29.2575 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #313: GFLOPs: 4965.1257. Time: 28.6211 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #314: GFLOPs: 4821.1199. Time: 29.4760 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #315: GFLOPs: 4886.8327. Time: 29.0796 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #316: GFLOPs: 4899.8980. Time: 29.0021 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #317: GFLOPs: 4872.9533. Time: 29.1624 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #318: GFLOPs: 1202.5539. Time: 118.1711 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #319: GFLOPs: 109.3757. Time: 1299.2566 us. Best GFLOPs: 5100.3086
2023-11-11 03:25:22 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #320: GFLOPs: 706.2755. Time: 201.2064 us. Best GFLOPs: 5100.3086
2023-11-11 04:07:33 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 04:07:35 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 04:07:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 400 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:07:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 803 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:07:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1204 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:07:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1604 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:08:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2004 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:08:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2404 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:08:11 [INFO] [evolutionary_search.cc:723] Sampled 56 candidate(s)
2023-11-11 04:08:26 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 98 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:08:44 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 112 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:09:02 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 133 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:09:21 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 113 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:09:26 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9952  0.9806  0.9736  0.9713  0.9689  0.9678  0.9671  0.9658  0.9654  0.9645  0.9642  0.9641  0.9637  0.9634  0.9629  0.9626
[17 : 32]:	0.9624  0.9621  0.9621  0.9620  0.9615  0.9613  0.9612  0.9609  0.9606  0.9605  0.9604  0.9603  0.9593  0.9592  0.9592  0.9590
[33 : 48]:	0.9589  0.9587  0.9585  0.9583  0.9580  0.9579  0.9574  0.9574  0.9569  0.9569  0.9568  0.9567  0.9567  0.9560  0.9558  0.9556
[49 : 64]:	0.9555  0.9555  0.9554  0.9552  0.9552  0.9549  0.9549  0.9547  0.9545  0.9545  0.9543  0.9542  0.9539  0.9538  0.9537  0.9536
2023-11-11 04:09:26 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 04:09:26 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #321: GFLOPs: 4815.4573. Time: 29.5106 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #322: GFLOPs: 4725.6240. Time: 30.0716 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #323: GFLOPs: 4756.9698. Time: 29.8735 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #324: GFLOPs: 4879.2193. Time: 29.1250 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #325: GFLOPs: 4968.8648. Time: 28.5995 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #326: GFLOPs: 4827.0330. Time: 29.4399 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #327: GFLOPs: 4968.9205. Time: 28.5992 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #328: GFLOPs: 4857.1304. Time: 29.2574 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #329: GFLOPs: 5029.4183. Time: 28.2552 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #330: GFLOPs: 4922.3060. Time: 28.8700 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #331: GFLOPs: 5065.1951. Time: 28.0556 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #332: GFLOPs: 4901.0902. Time: 28.9950 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #333: GFLOPs: 4840.8803. Time: 29.3556 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #334: GFLOPs: 4856.5413. Time: 29.2610 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #335: GFLOPs: 4875.6729. Time: 29.1462 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #336: GFLOPs: 4831.3880. Time: 29.4133 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #337: GFLOPs: 4917.4266. Time: 28.8987 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #338: GFLOPs: 4922.8293. Time: 28.8670 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #339: GFLOPs: 4844.2166. Time: 29.3354 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #340: GFLOPs: 5069.5762. Time: 28.0314 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #341: GFLOPs: 4850.9380. Time: 29.2948 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #342: GFLOPs: 4844.2486. Time: 29.3352 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #343: GFLOPs: 4969.0195. Time: 28.5986 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #344: GFLOPs: 4924.9910. Time: 28.8543 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #345: GFLOPs: 4997.2527. Time: 28.4371 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #346: GFLOPs: 5027.5125. Time: 28.2659 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #347: GFLOPs: 4862.4525. Time: 29.2254 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #348: GFLOPs: 4923.5254. Time: 28.8629 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #349: GFLOPs: 4806.8435. Time: 29.5635 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #350: GFLOPs: 4962.0275. Time: 28.6389 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #351: GFLOPs: 4879.4449. Time: 29.1236 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #352: GFLOPs: 4909.9500. Time: 28.9427 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #353: GFLOPs: 4927.5896. Time: 28.8391 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #354: GFLOPs: 4920.9953. Time: 28.8777 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #355: GFLOPs: 4821.2059. Time: 29.4754 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #356: GFLOPs: 4844.2093. Time: 29.3355 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #357: GFLOPs: 4914.8566. Time: 28.9138 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #358: GFLOPs: 4967.5341. Time: 28.6072 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #359: GFLOPs: 4939.4713. Time: 28.7697 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #360: GFLOPs: 4903.6267. Time: 28.9800 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #361: GFLOPs: 4909.3265. Time: 28.9464 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #362: GFLOPs: 4624.7906. Time: 30.7273 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #363: GFLOPs: 4894.0807. Time: 29.0365 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #364: GFLOPs: 4968.7648. Time: 28.6001 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #365: GFLOPs: 4794.6330. Time: 29.6388 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #366: GFLOPs: 4751.8411. Time: 29.9057 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #367: GFLOPs: 4939.2462. Time: 28.7710 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #368: GFLOPs: 4745.0846. Time: 29.9483 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #369: GFLOPs: 4838.0713. Time: 29.3727 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #370: GFLOPs: 4650.1037. Time: 30.5600 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #371: GFLOPs: 4893.5622. Time: 29.0396 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #372: GFLOPs: 4791.1034. Time: 29.6606 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #373: GFLOPs: 5007.1264. Time: 28.3810 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #374: GFLOPs: 4882.9581. Time: 29.1027 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #375: GFLOPs: 4747.0231. Time: 29.9361 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #376: GFLOPs: 5068.1489. Time: 28.0393 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #377: GFLOPs: 4833.6890. Time: 29.3993 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #378: GFLOPs: 4865.8186. Time: 29.2052 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #379: GFLOPs: 4901.2779. Time: 28.9939 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #380: GFLOPs: 5040.1119. Time: 28.1952 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #381: GFLOPs: 5006.1206. Time: 28.3867 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #382: GFLOPs: 473.0560. Time: 300.4024 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #383: GFLOPs: 227.6415. Time: 624.2584 us. Best GFLOPs: 5100.3086
2023-11-11 04:10:06 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #384: GFLOPs: 777.4792. Time: 182.7793 us. Best GFLOPs: 5100.3086
2023-11-11 04:50:27 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 04:50:30 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 04:50:36 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:50:42 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 799 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:50:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1200 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:50:54 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1598 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:51:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1999 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:51:00 [INFO] [evolutionary_search.cc:723] Sampled 51 candidate(s)
2023-11-11 04:51:15 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 94 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:51:33 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 107 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:51:51 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 91 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:52:09 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 111 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 04:52:14 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.4768  1.0166  0.9974  0.9946  0.9940  0.9917  0.9900  0.9872  0.9864  0.9863  0.9854  0.9854  0.9849  0.9835  0.9833  0.9830
[17 : 32]:	0.9812  0.9811  0.9809  0.9807  0.9803  0.9792  0.9790  0.9784  0.9773  0.9767  0.9761  0.9754  0.9754  0.9751  0.9749  0.9749
[33 : 48]:	0.9745  0.9741  0.9735  0.9716  0.9713  0.9710  0.9707  0.9707  0.9705  0.9705  0.9694  0.9693  0.9691  0.9691  0.9686  0.9686
[49 : 64]:	0.9679  0.9677  0.9677  0.9675  0.9673  0.9672  0.9657  0.9657  0.9654  0.9654  0.9653  0.9651  0.9648  0.9644  0.9643  0.9640
2023-11-11 04:52:14 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 04:52:14 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #385: GFLOPs: 1398.4559. Time: 101.6172 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #386: GFLOPs: 898.8712. Time: 158.0951 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #387: GFLOPs: 4952.2190. Time: 28.6956 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #388: GFLOPs: 5022.7696. Time: 28.2926 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #389: GFLOPs: 4961.3763. Time: 28.6427 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #390: GFLOPs: 4955.9711. Time: 28.6739 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #391: GFLOPs: 4973.1556. Time: 28.5748 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #392: GFLOPs: 5017.5047. Time: 28.3223 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #393: GFLOPs: 4916.9684. Time: 28.9014 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #394: GFLOPs: 4997.8875. Time: 28.4334 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #395: GFLOPs: 5010.8181. Time: 28.3601 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #396: GFLOPs: 4917.9829. Time: 28.8954 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #397: GFLOPs: 4776.4150. Time: 29.7518 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #398: GFLOPs: 5026.1088. Time: 28.2738 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #399: GFLOPs: 4907.3315. Time: 28.9581 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #400: GFLOPs: 4848.9262. Time: 29.3069 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #401: GFLOPs: 4635.9650. Time: 30.6532 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #402: GFLOPs: 4661.1603. Time: 30.4875 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #403: GFLOPs: 4782.4225. Time: 29.7145 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #404: GFLOPs: 5027.5458. Time: 28.2657 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #405: GFLOPs: 4791.7529. Time: 29.6566 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #406: GFLOPs: 5048.5913. Time: 28.1479 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #407: GFLOPs: 5016.2651. Time: 28.3293 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #408: GFLOPs: 4870.4538. Time: 29.1774 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #409: GFLOPs: 4357.9514. Time: 32.6087 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #410: GFLOPs: 4931.2933. Time: 28.8174 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #411: GFLOPs: 4969.2178. Time: 28.5975 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #412: GFLOPs: 4995.2829. Time: 28.4483 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #413: GFLOPs: 4945.6392. Time: 28.7338 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #414: GFLOPs: 3320.2887. Time: 42.7996 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #415: GFLOPs: 5025.9420. Time: 28.2747 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #416: GFLOPs: 4930.2521. Time: 28.8235 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #417: GFLOPs: 4632.8960. Time: 30.6735 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #418: GFLOPs: 4819.9523. Time: 29.4831 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #419: GFLOPs: 4929.1150. Time: 28.8302 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #420: GFLOPs: 4927.9837. Time: 28.8368 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #421: GFLOPs: 5058.5879. Time: 28.0923 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #422: GFLOPs: 5024.3054. Time: 28.2839 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #423: GFLOPs: 4887.1290. Time: 29.0778 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #424: GFLOPs: 4883.7432. Time: 29.0980 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #425: GFLOPs: 4857.5097. Time: 29.2551 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #426: GFLOPs: 4946.3018. Time: 28.7300 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #427: GFLOPs: 4944.6323. Time: 28.7397 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #428: GFLOPs: 5058.5541. Time: 28.0924 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #429: GFLOPs: 4785.3967. Time: 29.6960 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #430: GFLOPs: 4910.7617. Time: 28.9379 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #431: GFLOPs: 4951.1172. Time: 28.7020 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #432: GFLOPs: 5023.5177. Time: 28.2884 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #433: GFLOPs: 5043.1030. Time: 28.1785 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #434: GFLOPs: 4923.7261. Time: 28.8617 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #435: GFLOPs: 4865.0412. Time: 29.2099 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #436: GFLOPs: 4906.9030. Time: 28.9607 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #437: GFLOPs: 4938.8833. Time: 28.7731 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #438: GFLOPs: 4868.2162. Time: 29.1908 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #439: GFLOPs: 4901.8039. Time: 28.9908 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #440: GFLOPs: 4852.7699. Time: 29.2837 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #441: GFLOPs: 4901.2529. Time: 28.9940 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #442: GFLOPs: 4877.8631. Time: 29.1331 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #443: GFLOPs: 4820.0390. Time: 29.4826 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #444: GFLOPs: 5006.8737. Time: 28.3824 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #445: GFLOPs: 5058.7574. Time: 28.0913 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #446: GFLOPs: 1182.7869. Time: 120.1460 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #447: GFLOPs: 1014.1209. Time: 140.1284 us. Best GFLOPs: 5100.3086
2023-11-11 04:52:49 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #448: GFLOPs: 33.0089. Time: 4305.1093 us. Best GFLOPs: 5100.3086
2023-11-11 05:25:47 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 05:25:50 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 05:25:56 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 05:26:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 803 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 05:26:08 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1204 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 05:26:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1599 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 05:26:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2006 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 05:26:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2412 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 05:26:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2811 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 05:26:31 [INFO] [evolutionary_search.cc:723] Sampled 59 candidate(s)
2023-11-11 05:26:46 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 104 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 05:27:05 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 109 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 05:27:23 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 120 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 05:27:42 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 120 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 05:27:47 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0059  1.0034  1.0031  0.9988  0.9981  0.9962  0.9956  0.9952  0.9943  0.9912  0.9912  0.9894  0.9894  0.9892  0.9880  0.9878
[17 : 32]:	0.9877  0.9875  0.9866  0.9866  0.9841  0.9840  0.9834  0.9832  0.9829  0.9824  0.9824  0.9823  0.9823  0.9822  0.9818  0.9816
[33 : 48]:	0.9815  0.9813  0.9810  0.9797  0.9791  0.9789  0.9789  0.9787  0.9784  0.9776  0.9771  0.9770  0.9770  0.9765  0.9760  0.9756
[49 : 64]:	0.9756  0.9755  0.9754  0.9753  0.9751  0.9748  0.9746  0.9746  0.9742  0.9742  0.9740  0.9734  0.9730  0.9727  0.9727  0.9727
2023-11-11 05:27:47 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 05:27:47 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #449: GFLOPs: 4883.3368. Time: 29.1004 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #450: GFLOPs: 5011.3533. Time: 28.3570 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #451: GFLOPs: 4967.5959. Time: 28.6068 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #452: GFLOPs: 5028.7829. Time: 28.2588 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #453: GFLOPs: 5012.1953. Time: 28.3523 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #454: GFLOPs: 4456.6883. Time: 31.8863 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #455: GFLOPs: 5015.1751. Time: 28.3354 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #456: GFLOPs: 4975.2698. Time: 28.5627 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #457: GFLOPs: 4988.4766. Time: 28.4871 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #458: GFLOPs: 4970.6057. Time: 28.5895 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #459: GFLOPs: 5043.4239. Time: 28.1767 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #460: GFLOPs: 4967.0059. Time: 28.6102 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #461: GFLOPs: 4986.5129. Time: 28.4983 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #462: GFLOPs: 4960.1510. Time: 28.6498 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #463: GFLOPs: 4871.6616. Time: 29.1702 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #464: GFLOPs: 4957.3553. Time: 28.6659 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #465: GFLOPs: 4588.9983. Time: 30.9669 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #466: GFLOPs: 4995.2491. Time: 28.4485 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #467: GFLOPs: 4921.6515. Time: 28.8739 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #468: GFLOPs: 5042.7332. Time: 28.1806 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #469: GFLOPs: 4824.0373. Time: 29.4581 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #470: GFLOPs: 4974.2437. Time: 28.5686 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #471: GFLOPs: 4959.4567. Time: 28.6538 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #472: GFLOPs: 4932.4564. Time: 28.8106 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #473: GFLOPs: 4821.7240. Time: 29.4723 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #474: GFLOPs: 4972.4240. Time: 28.5790 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #475: GFLOPs: 4964.4000. Time: 28.6252 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #476: GFLOPs: 4959.1275. Time: 28.6557 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #477: GFLOPs: 4968.6893. Time: 28.6005 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #478: GFLOPs: 4930.6466. Time: 28.8212 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #479: GFLOPs: 5068.9644. Time: 28.0347 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #480: GFLOPs: 5015.9737. Time: 28.3309 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #481: GFLOPs: 4588.9375. Time: 30.9673 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #482: GFLOPs: 4872.1114. Time: 29.1675 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #483: GFLOPs: 5013.0473. Time: 28.3475 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #484: GFLOPs: 4943.4417. Time: 28.7466 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #485: GFLOPs: 4748.5994. Time: 29.9261 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #486: GFLOPs: 4955.1207. Time: 28.6788 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #487: GFLOPs: 4849.1483. Time: 29.3056 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #488: GFLOPs: 4951.6093. Time: 28.6992 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #489: GFLOPs: 4978.0195. Time: 28.5469 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #490: GFLOPs: 5022.0664. Time: 28.2965 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #491: GFLOPs: 4839.2152. Time: 29.3657 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #492: GFLOPs: 4480.8318. Time: 31.7145 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #493: GFLOPs: 4936.6012. Time: 28.7864 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #494: GFLOPs: 4968.7887. Time: 28.6000 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #495: GFLOPs: 4842.6513. Time: 29.3449 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #496: GFLOPs: 4969.2838. Time: 28.5971 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #497: GFLOPs: 5013.9099. Time: 28.3426 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #498: GFLOPs: 4799.6599. Time: 29.6078 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #499: GFLOPs: 4891.6516. Time: 29.0510 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #500: GFLOPs: 4942.8028. Time: 28.7503 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #501: GFLOPs: 4940.7122. Time: 28.7625 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #502: GFLOPs: 4891.6192. Time: 29.0511 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #503: GFLOPs: 4974.1695. Time: 28.5690 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #504: GFLOPs: 4498.6436. Time: 31.5889 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #505: GFLOPs: 4929.1997. Time: 28.8297 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #506: GFLOPs: 4965.7097. Time: 28.6177 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #507: GFLOPs: 4908.0483. Time: 28.9539 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #508: GFLOPs: 4966.7089. Time: 28.6119 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #509: GFLOPs: 4913.0464. Time: 28.9244 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #510: GFLOPs: 416.8492. Time: 340.9077 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #511: GFLOPs: 932.9362. Time: 152.3225 us. Best GFLOPs: 5100.3086
2023-11-11 05:28:23 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #512: GFLOPs: 504.3303. Time: 281.7740 us. Best GFLOPs: 5100.3086
2023-11-11 06:11:25 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 06:11:28 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 06:11:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 394 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:11:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 793 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:11:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1197 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:11:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1597 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:11:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2003 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:12:03 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2400 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:12:03 [INFO] [evolutionary_search.cc:723] Sampled 60 candidate(s)
2023-11-11 06:12:18 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 108 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:12:37 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 108 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:12:55 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 130 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:13:13 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 126 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:13:18 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.3756  1.3608  1.2522  1.2512  1.2447  1.2154  1.2134  1.2125  1.2117  1.2096  1.1909  1.1894  1.1872  1.1835  1.1823  1.1809
[17 : 32]:	1.1807  1.1804  1.1777  1.1733  1.1731  1.1611  1.1587  1.1524  1.1475  1.1422  1.1404  1.1379  1.1369  1.1327  1.1244  1.1182
[33 : 48]:	1.1034  1.0917  1.0855  1.0418  1.0057  0.9979  0.9972  0.9970  0.9960  0.9934  0.9905  0.9897  0.9884  0.9876  0.9862  0.9862
[49 : 64]:	0.9851  0.9848  0.9846  0.9836  0.9829  0.9812  0.9812  0.9809  0.9806  0.9802  0.9802  0.9801  0.9800  0.9799  0.9794  0.9791
2023-11-11 06:13:18 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 06:13:18 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #513: GFLOPs: 1907.5899. Time: 74.4956 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #514: GFLOPs: 1880.9213. Time: 75.5519 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #515: GFLOPs: 4409.9153. Time: 32.2245 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #516: GFLOPs: 4413.7810. Time: 32.1962 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #517: GFLOPs: 4399.2314. Time: 32.3027 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #518: GFLOPs: 4364.0699. Time: 32.5630 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #519: GFLOPs: 4390.8894. Time: 32.3641 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #520: GFLOPs: 4391.0926. Time: 32.3626 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #521: GFLOPs: 4498.4859. Time: 31.5900 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #522: GFLOPs: 1789.9432. Time: 79.3920 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #523: GFLOPs: 4361.8996. Time: 32.5792 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #524: GFLOPs: 4518.6068. Time: 31.4493 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #525: GFLOPs: 3223.8808. Time: 44.0795 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #526: GFLOPs: 3972.6377. Time: 35.7715 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #527: GFLOPs: 4623.6219. Time: 30.7350 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #528: GFLOPs: 4614.1414. Time: 30.7982 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #529: GFLOPs: 4615.1456. Time: 30.7915 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #530: GFLOPs: 3976.0399. Time: 35.7409 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #531: GFLOPs: 4587.3921. Time: 30.9778 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #532: GFLOPs: 4648.1271. Time: 30.5730 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #533: GFLOPs: 4622.5834. Time: 30.7419 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #534: GFLOPs: 4682.3353. Time: 30.3496 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #535: GFLOPs: 4455.8304. Time: 31.8924 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #536: GFLOPs: 4408.3951. Time: 32.2356 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #537: GFLOPs: 4019.1496. Time: 35.3575 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #538: GFLOPs: 4618.0386. Time: 30.7722 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #539: GFLOPs: 4505.8382. Time: 31.5384 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #540: GFLOPs: 1340.6000. Time: 106.0026 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #541: GFLOPs: 4381.3943. Time: 32.4342 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #542: GFLOPs: 1082.2764. Time: 131.3039 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #543: GFLOPs: 1145.9822. Time: 124.0047 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #544: GFLOPs: 4383.4758. Time: 32.4188 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #545: GFLOPs: 1788.0978. Time: 79.4739 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #546: GFLOPs: 1791.7734. Time: 79.3109 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #547: GFLOPs: 3910.6028. Time: 36.3389 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #548: GFLOPs: 4595.5132. Time: 30.9230 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #549: GFLOPs: 4713.7853. Time: 30.1471 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #550: GFLOPs: 5057.2011. Time: 28.1000 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #551: GFLOPs: 4720.3901. Time: 30.1050 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #552: GFLOPs: 5047.9166. Time: 28.1516 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #553: GFLOPs: 362.8121. Time: 391.6825 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #554: GFLOPs: 5033.0671. Time: 28.2347 us. Best GFLOPs: 5100.3086
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #555: GFLOPs: 5106.9051. Time: 27.8265 us. Best GFLOPs: 5106.9051
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #556: GFLOPs: 5032.5979. Time: 28.2373 us. Best GFLOPs: 5106.9051
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #557: GFLOPs: 5060.1788. Time: 28.0834 us. Best GFLOPs: 5106.9051
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #558: GFLOPs: 5060.1112. Time: 28.0838 us. Best GFLOPs: 5106.9051
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #559: GFLOPs: 5128.2237. Time: 27.7108 us. Best GFLOPs: 5128.2237
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #560: GFLOPs: 4971.5721. Time: 28.5839 us. Best GFLOPs: 5128.2237
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #561: GFLOPs: 5030.0539. Time: 28.2516 us. Best GFLOPs: 5128.2237
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #562: GFLOPs: 5147.0484. Time: 27.6094 us. Best GFLOPs: 5147.0484
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #563: GFLOPs: 5089.2932. Time: 27.9228 us. Best GFLOPs: 5147.0484
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #564: GFLOPs: 4679.5200. Time: 30.3679 us. Best GFLOPs: 5147.0484
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #565: GFLOPs: 5148.9275. Time: 27.5994 us. Best GFLOPs: 5148.9275
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #566: GFLOPs: 3301.8779. Time: 43.0383 us. Best GFLOPs: 5148.9275
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #567: GFLOPs: 5022.0033. Time: 28.2969 us. Best GFLOPs: 5148.9275
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #568: GFLOPs: 5057.5055. Time: 28.0983 us. Best GFLOPs: 5148.9275
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #569: GFLOPs: 5085.7744. Time: 27.9421 us. Best GFLOPs: 5148.9275
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #570: GFLOPs: 4930.2849. Time: 28.8233 us. Best GFLOPs: 5148.9275
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #571: GFLOPs: 5088.4810. Time: 27.9272 us. Best GFLOPs: 5148.9275
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #572: GFLOPs: 5043.7421. Time: 28.1749 us. Best GFLOPs: 5148.9275
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #573: GFLOPs: 5078.7690. Time: 27.9806 us. Best GFLOPs: 5148.9275
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #574: GFLOPs: 798.5033. Time: 177.9669 us. Best GFLOPs: 5148.9275
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #575: GFLOPs: 722.8725. Time: 196.5867 us. Best GFLOPs: 5148.9275
2023-11-11 06:13:54 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #576: GFLOPs: 363.7631. Time: 390.6585 us. Best GFLOPs: 5148.9275
2023-11-11 06:51:44 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 06:51:47 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 06:51:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:51:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 803 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:52:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1203 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:52:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1610 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:52:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2014 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:52:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2416 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:52:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2815 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:52:29 [INFO] [evolutionary_search.cc:723] Sampled 55 candidate(s)
2023-11-11 06:52:44 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 124 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:53:02 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 92 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:53:20 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 106 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:53:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 126 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 06:53:43 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0466  0.9997  0.9997  0.9995  0.9994  0.9981  0.9979  0.9965  0.9958  0.9956  0.9951  0.9945  0.9943  0.9941  0.9935  0.9935
[17 : 32]:	0.9919  0.9901  0.9897  0.9878  0.9862  0.9849  0.9847  0.9840  0.9835  0.9825  0.9817  0.9816  0.9814  0.9799  0.9799  0.9799
[33 : 48]:	0.9797  0.9793  0.9793  0.9792  0.9787  0.9784  0.9782  0.9776  0.9775  0.9771  0.9762  0.9761  0.9754  0.9752  0.9751  0.9749
[49 : 64]:	0.9748  0.9742  0.9741  0.9740  0.9740  0.9737  0.9735  0.9732  0.9729  0.9728  0.9727  0.9722  0.9721  0.9721  0.9716  0.9708
2023-11-11 06:53:44 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 06:53:44 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #577: GFLOPs: 5036.5757. Time: 28.2150 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #578: GFLOPs: 5041.9765. Time: 28.1848 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #579: GFLOPs: 5041.1533. Time: 28.1894 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #580: GFLOPs: 4915.5953. Time: 28.9094 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #581: GFLOPs: 5023.2208. Time: 28.2900 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #582: GFLOPs: 5010.1248. Time: 28.3640 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #583: GFLOPs: 4916.1838. Time: 28.9060 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #584: GFLOPs: 4866.5309. Time: 29.2009 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #585: GFLOPs: 4931.9764. Time: 28.8134 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #586: GFLOPs: 4863.5524. Time: 29.2188 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #587: GFLOPs: 4907.9571. Time: 28.9544 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #588: GFLOPs: 4948.6711. Time: 28.7162 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #589: GFLOPs: 4878.3185. Time: 29.1304 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #590: GFLOPs: 4864.5437. Time: 29.2128 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #591: GFLOPs: 4871.9468. Time: 29.1684 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #592: GFLOPs: 4920.5177. Time: 28.8805 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #593: GFLOPs: 4920.8640. Time: 28.8785 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #594: GFLOPs: 4968.2602. Time: 28.6030 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #595: GFLOPs: 4955.2524. Time: 28.6781 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #596: GFLOPs: 4859.8664. Time: 29.2410 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #597: GFLOPs: 4914.6801. Time: 28.9148 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #598: GFLOPs: 4913.5983. Time: 28.9212 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #599: GFLOPs: 4936.3436. Time: 28.7879 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #600: GFLOPs: 4917.3613. Time: 28.8991 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #601: GFLOPs: 4978.5934. Time: 28.5436 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #602: GFLOPs: 4985.8547. Time: 28.5021 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #603: GFLOPs: 4999.6591. Time: 28.4234 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #604: GFLOPs: 4880.2821. Time: 29.1186 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #605: GFLOPs: 5046.2328. Time: 28.1610 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #606: GFLOPs: 4962.2267. Time: 28.6378 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #607: GFLOPs: 4975.4020. Time: 28.5619 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #608: GFLOPs: 5001.6083. Time: 28.4123 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #609: GFLOPs: 4940.9730. Time: 28.7610 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #610: GFLOPs: 4951.4124. Time: 28.7003 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #611: GFLOPs: 4839.7266. Time: 29.3626 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #612: GFLOPs: 4986.2204. Time: 28.5000 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #613: GFLOPs: 4949.0691. Time: 28.7139 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #614: GFLOPs: 4818.3136. Time: 29.4931 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #615: GFLOPs: 4940.6661. Time: 28.7627 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #616: GFLOPs: 3919.3433. Time: 36.2579 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #617: GFLOPs: 4907.9245. Time: 28.9546 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #618: GFLOPs: 4937.2339. Time: 28.7827 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #619: GFLOPs: 4980.1477. Time: 28.5347 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #620: GFLOPs: 4862.9142. Time: 29.2226 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #621: GFLOPs: 4911.4192. Time: 28.9340 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #622: GFLOPs: 4935.0046. Time: 28.7957 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #623: GFLOPs: 4925.3565. Time: 28.8522 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #624: GFLOPs: 4992.4286. Time: 28.4645 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #625: GFLOPs: 4794.5373. Time: 29.6394 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #626: GFLOPs: 5012.2502. Time: 28.3520 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #627: GFLOPs: 4877.2194. Time: 29.1369 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #628: GFLOPs: 4911.6429. Time: 28.9327 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #629: GFLOPs: 4886.5358. Time: 29.0814 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #630: GFLOPs: 4620.9239. Time: 30.7530 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #631: GFLOPs: 4982.1280. Time: 28.5234 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #632: GFLOPs: 4807.1312. Time: 29.5617 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #633: GFLOPs: 4795.0547. Time: 29.6362 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #634: GFLOPs: 4964.0929. Time: 28.6270 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #635: GFLOPs: 4504.5516. Time: 31.5475 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #636: GFLOPs: 5017.0384. Time: 28.3249 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #637: GFLOPs: 4866.8820. Time: 29.1988 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #638: GFLOPs: 1998.0816. Time: 71.1218 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #639: GFLOPs: 1342.3944. Time: 105.8609 us. Best GFLOPs: 5148.9275
2023-11-11 06:54:21 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #640: GFLOPs: 480.6899. Time: 295.6316 us. Best GFLOPs: 5148.9275
2023-11-11 07:36:25 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 07:36:28 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 07:36:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 07:36:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 803 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 07:36:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1202 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 07:36:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1602 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 07:36:58 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2003 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 07:37:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 07:37:04 [INFO] [evolutionary_search.cc:723] Sampled 57 candidate(s)
2023-11-11 07:37:20 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 101 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 07:37:38 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 125 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 07:37:57 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 107 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 07:38:16 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 141 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 07:38:21 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.3197  1.1583  1.1372  1.0469  1.0430  1.0427  1.0060  1.0006  0.9996  0.9993  0.9992  0.9975  0.9967  0.9967  0.9955  0.9938
[17 : 32]:	0.9936  0.9935  0.9921  0.9917  0.9916  0.9902  0.9900  0.9883  0.9870  0.9860  0.9849  0.9843  0.9839  0.9835  0.9827  0.9826
[33 : 48]:	0.9822  0.9822  0.9820  0.9809  0.9808  0.9806  0.9806  0.9801  0.9801  0.9799  0.9795  0.9793  0.9783  0.9783  0.9782  0.9782
[49 : 64]:	0.9782  0.9780  0.9779  0.9779  0.9776  0.9769  0.9766  0.9765  0.9763  0.9753  0.9752  0.9751  0.9750  0.9749  0.9746  0.9746
2023-11-11 07:38:21 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 07:38:21 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #641: GFLOPs: 986.2010. Time: 144.0955 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #642: GFLOPs: 1214.1589. Time: 117.0416 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #643: GFLOPs: 855.3197. Time: 166.1451 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #644: GFLOPs: 5011.7185. Time: 28.3550 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #645: GFLOPs: 4928.9085. Time: 28.8314 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #646: GFLOPs: 5066.3152. Time: 28.0494 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #647: GFLOPs: 5119.6773. Time: 27.7570 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #648: GFLOPs: 4207.8659. Time: 33.7718 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #649: GFLOPs: 5022.9381. Time: 28.2916 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #650: GFLOPs: 5059.8037. Time: 28.0855 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #651: GFLOPs: 4983.6438. Time: 28.5147 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #652: GFLOPs: 4996.7516. Time: 28.4399 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #653: GFLOPs: 4992.7804. Time: 28.4625 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #654: GFLOPs: 5065.4667. Time: 28.0541 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #655: GFLOPs: 5079.1442. Time: 27.9786 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #656: GFLOPs: 5089.4966. Time: 27.9216 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #657: GFLOPs: 5050.2433. Time: 28.1387 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #658: GFLOPs: 5044.6877. Time: 28.1697 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #659: GFLOPs: 5016.4730. Time: 28.3281 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #660: GFLOPs: 4966.2797. Time: 28.6144 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #661: GFLOPs: 4983.9061. Time: 28.5132 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #662: GFLOPs: 5046.2328. Time: 28.1610 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #663: GFLOPs: 5004.2229. Time: 28.3974 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #664: GFLOPs: 5048.5164. Time: 28.1483 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #665: GFLOPs: 5064.5506. Time: 28.0592 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #666: GFLOPs: 5091.2244. Time: 27.9122 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #667: GFLOPs: 5065.8403. Time: 28.0520 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #668: GFLOPs: 5003.8418. Time: 28.3996 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #669: GFLOPs: 5063.4318. Time: 28.0654 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #670: GFLOPs: 5112.8673. Time: 27.7940 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #671: GFLOPs: 5074.4045. Time: 28.0047 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #672: GFLOPs: 5068.4534. Time: 28.0376 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #673: GFLOPs: 5039.6357. Time: 28.1979 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #674: GFLOPs: 4989.9146. Time: 28.4789 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #675: GFLOPs: 5058.7969. Time: 28.0911 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #676: GFLOPs: 4995.6605. Time: 28.4461 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #677: GFLOPs: 5049.4342. Time: 28.1432 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #678: GFLOPs: 5051.9979. Time: 28.1289 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #679: GFLOPs: 5093.8009. Time: 27.8981 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #680: GFLOPs: 5073.0250. Time: 28.0123 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #681: GFLOPs: 5046.4014. Time: 28.1601 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #682: GFLOPs: 5011.8593. Time: 28.3542 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #683: GFLOPs: 5099.0318. Time: 27.8694 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #684: GFLOPs: 5031.7606. Time: 28.2420 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #685: GFLOPs: 5093.0888. Time: 27.9020 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #686: GFLOPs: 5005.5481. Time: 28.3899 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #687: GFLOPs: 5057.3024. Time: 28.0994 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #688: GFLOPs: 5003.9977. Time: 28.3987 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #689: GFLOPs: 5054.6996. Time: 28.1139 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #690: GFLOPs: 5045.3863. Time: 28.1658 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #691: GFLOPs: 5080.2013. Time: 27.9727 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #692: GFLOPs: 5020.9028. Time: 28.3031 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #693: GFLOPs: 5018.1842. Time: 28.3184 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #694: GFLOPs: 5046.0187. Time: 28.1622 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #695: GFLOPs: 4943.1623. Time: 28.7482 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #696: GFLOPs: 5083.9153. Time: 27.9523 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #697: GFLOPs: 5052.4512. Time: 28.1264 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #698: GFLOPs: 5059.8705. Time: 28.0851 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #699: GFLOPs: 4993.8812. Time: 28.4563 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #700: GFLOPs: 5070.5702. Time: 28.0259 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #701: GFLOPs: 5045.7953. Time: 28.1635 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #702: GFLOPs: 32.7664. Time: 4336.9722 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #703: GFLOPs: 78.1295. Time: 1818.8661 us. Best GFLOPs: 5148.9275
2023-11-11 07:38:57 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #704: GFLOPs: 462.3972. Time: 307.3270 us. Best GFLOPs: 5148.9275
2023-11-11 08:10:09 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 08:10:12 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 08:10:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 404 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:10:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 802 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:10:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1205 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:10:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1611 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:10:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2010 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:10:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2411 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:10:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2813 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:10:55 [INFO] [evolutionary_search.cc:723] Sampled 57 candidate(s)
2023-11-11 08:11:12 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 154 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:11:30 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 123 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:11:49 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 141 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:12:08 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 146 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:12:13 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0737  1.0070  0.9947  0.9922  0.9892  0.9891  0.9851  0.9844  0.9839  0.9839  0.9827  0.9827  0.9821  0.9819  0.9815  0.9810
[17 : 32]:	0.9799  0.9795  0.9793  0.9793  0.9786  0.9782  0.9778  0.9777  0.9776  0.9775  0.9773  0.9771  0.9770  0.9767  0.9766  0.9763
[33 : 48]:	0.9754  0.9749  0.9745  0.9744  0.9742  0.9741  0.9739  0.9736  0.9735  0.9733  0.9731  0.9730  0.9730  0.9728  0.9728  0.9726
[49 : 64]:	0.9725  0.9721  0.9719  0.9718  0.9716  0.9714  0.9712  0.9711  0.9710  0.9710  0.9710  0.9708  0.9708  0.9705  0.9701  0.9697
2023-11-11 08:12:13 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 08:12:13 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #705: GFLOPs: 3103.5611. Time: 45.7884 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #706: GFLOPs: 2784.8277. Time: 51.0291 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #707: GFLOPs: 3676.8897. Time: 38.6487 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #708: GFLOPs: 4827.3592. Time: 29.4379 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #709: GFLOPs: 4862.7113. Time: 29.2238 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #710: GFLOPs: 5006.6907. Time: 28.3834 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #711: GFLOPs: 5020.0360. Time: 28.3080 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #712: GFLOPs: 4952.5432. Time: 28.6938 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #713: GFLOPs: 5025.0736. Time: 28.2796 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #714: GFLOPs: 4683.7525. Time: 30.3404 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #715: GFLOPs: 4720.1708. Time: 30.1064 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #716: GFLOPs: 5043.6776. Time: 28.1753 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #717: GFLOPs: 5046.0311. Time: 28.1622 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #718: GFLOPs: 4966.6279. Time: 28.6124 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #719: GFLOPs: 4965.2573. Time: 28.6203 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #720: GFLOPs: 5057.6626. Time: 28.0974 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #721: GFLOPs: 4953.8403. Time: 28.6863 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #722: GFLOPs: 4998.1882. Time: 28.4317 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #723: GFLOPs: 4966.1985. Time: 28.6149 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #724: GFLOPs: 4974.2348. Time: 28.5686 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #725: GFLOPs: 4978.3939. Time: 28.5448 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #726: GFLOPs: 5027.6121. Time: 28.2653 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #727: GFLOPs: 4982.5272. Time: 28.5211 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #728: GFLOPs: 5068.8563. Time: 28.0353 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #729: GFLOPs: 4959.2297. Time: 28.6551 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #730: GFLOPs: 4979.1138. Time: 28.5406 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #731: GFLOPs: 4803.0284. Time: 29.5870 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #732: GFLOPs: 5018.3373. Time: 28.3176 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #733: GFLOPs: 4468.1437. Time: 31.8045 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #734: GFLOPs: 5021.2694. Time: 28.3010 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #735: GFLOPs: 5010.2242. Time: 28.3634 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #736: GFLOPs: 4775.8172. Time: 29.7556 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #737: GFLOPs: 4993.3141. Time: 28.4595 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #738: GFLOPs: 4945.3203. Time: 28.7357 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #739: GFLOPs: 4799.7900. Time: 29.6069 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #740: GFLOPs: 4929.7326. Time: 28.8265 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #741: GFLOPs: 5028.3102. Time: 28.2614 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #742: GFLOPs: 4996.3176. Time: 28.4424 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #743: GFLOPs: 5010.9187. Time: 28.3595 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #744: GFLOPs: 4958.3088. Time: 28.6604 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #745: GFLOPs: 4678.3600. Time: 30.3754 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #746: GFLOPs: 4789.5312. Time: 29.6704 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #747: GFLOPs: 4970.2789. Time: 28.5914 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #748: GFLOPs: 5007.7690. Time: 28.3773 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #749: GFLOPs: 4707.7531. Time: 30.1858 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #750: GFLOPs: 4679.9240. Time: 30.3653 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #751: GFLOPs: 4982.8306. Time: 28.5194 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #752: GFLOPs: 4691.5112. Time: 30.2903 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #753: GFLOPs: 4960.4948. Time: 28.6478 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #754: GFLOPs: 4989.9908. Time: 28.4784 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #755: GFLOPs: 5027.9715. Time: 28.2633 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #756: GFLOPs: 4962.0604. Time: 28.6387 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #757: GFLOPs: 5017.2383. Time: 28.3238 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #758: GFLOPs: 4919.6157. Time: 28.8858 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #759: GFLOPs: 4690.8107. Time: 30.2948 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #760: GFLOPs: 4792.2809. Time: 29.6533 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #761: GFLOPs: 5037.8433. Time: 28.2079 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #762: GFLOPs: 4941.7229. Time: 28.7566 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #763: GFLOPs: 5058.5572. Time: 28.0924 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #764: GFLOPs: 4920.5037. Time: 28.8806 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #765: GFLOPs: 5130.6028. Time: 27.6979 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #766: GFLOPs: 1276.8412. Time: 111.2959 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #767: GFLOPs: 3376.2801. Time: 42.0899 us. Best GFLOPs: 5148.9275
2023-11-11 08:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #768: GFLOPs: 1483.6378. Time: 95.7829 us. Best GFLOPs: 5148.9275
2023-11-11 08:43:02 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 08:43:05 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 08:43:11 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 399 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:43:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 801 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:43:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1202 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:43:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1599 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:43:35 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1994 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:43:35 [INFO] [evolutionary_search.cc:723] Sampled 56 candidate(s)
2023-11-11 08:43:52 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 165 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:44:10 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 120 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:44:30 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 167 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:44:48 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 122 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 08:44:53 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.1389  1.1330  1.0302  0.9903  0.9879  0.9832  0.9823  0.9817  0.9810  0.9788  0.9787  0.9785  0.9782  0.9782  0.9779  0.9779
[17 : 32]:	0.9776  0.9775  0.9775  0.9774  0.9773  0.9771  0.9770  0.9765  0.9756  0.9741  0.9740  0.9739  0.9738  0.9738  0.9738  0.9738
[33 : 48]:	0.9735  0.9731  0.9731  0.9730  0.9728  0.9728  0.9728  0.9727  0.9726  0.9726  0.9726  0.9724  0.9723  0.9721  0.9721  0.9713
[49 : 64]:	0.9711  0.9710  0.9710  0.9708  0.9701  0.9699  0.9697  0.9696  0.9692  0.9692  0.9691  0.9689  0.9686  0.9686  0.9686  0.9686
2023-11-11 08:44:54 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 08:44:54 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #769: GFLOPs: 3517.2244. Time: 40.4032 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #770: GFLOPs: 3393.3085. Time: 41.8786 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #771: GFLOPs: 2974.0854. Time: 47.7818 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #772: GFLOPs: 5043.0695. Time: 28.1787 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #773: GFLOPs: 5040.4660. Time: 28.1933 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #774: GFLOPs: 5015.9737. Time: 28.3309 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #775: GFLOPs: 5066.7907. Time: 28.0468 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #776: GFLOPs: 5009.4279. Time: 28.3679 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #777: GFLOPs: 5031.9617. Time: 28.2409 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #778: GFLOPs: 5004.0430. Time: 28.3985 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #779: GFLOPs: 5042.9016. Time: 28.1796 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #780: GFLOPs: 5021.8363. Time: 28.2978 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #781: GFLOPs: 4993.6484. Time: 28.4576 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #782: GFLOPs: 5030.9241. Time: 28.2467 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #783: GFLOPs: 5063.2282. Time: 28.0665 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #784: GFLOPs: 5134.1082. Time: 27.6790 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #785: GFLOPs: 4968.7222. Time: 28.6003 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #786: GFLOPs: 5007.2383. Time: 28.3803 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #787: GFLOPs: 5068.5540. Time: 28.0370 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #788: GFLOPs: 5046.7045. Time: 28.1584 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #789: GFLOPs: 5001.8668. Time: 28.4108 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #790: GFLOPs: 4904.7632. Time: 28.9733 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #791: GFLOPs: 5042.7668. Time: 28.1804 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #792: GFLOPs: 5056.2543. Time: 28.1052 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #793: GFLOPs: 5006.0449. Time: 28.3871 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #794: GFLOPs: 4979.3118. Time: 28.5395 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #795: GFLOPs: 5037.2792. Time: 28.2111 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #796: GFLOPs: 4995.7928. Time: 28.4454 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #797: GFLOPs: 5024.2054. Time: 28.2845 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #798: GFLOPs: 4964.9921. Time: 28.6218 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #799: GFLOPs: 4996.5182. Time: 28.4412 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #800: GFLOPs: 5027.3807. Time: 28.2666 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #801: GFLOPs: 5052.9431. Time: 28.1236 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #802: GFLOPs: 4987.0289. Time: 28.4954 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #803: GFLOPs: 5112.6621. Time: 27.7951 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #804: GFLOPs: 4994.3480. Time: 28.4536 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #805: GFLOPs: 5076.3244. Time: 27.9941 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #806: GFLOPs: 5011.2538. Time: 28.3576 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #807: GFLOPs: 5015.7265. Time: 28.3323 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #808: GFLOPs: 5064.2115. Time: 28.0611 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #809: GFLOPs: 5019.4645. Time: 28.3112 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #810: GFLOPs: 5027.6459. Time: 28.2651 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #811: GFLOPs: 4965.8510. Time: 28.6169 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #812: GFLOPs: 4977.4229. Time: 28.5503 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #813: GFLOPs: 5017.1054. Time: 28.3245 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #814: GFLOPs: 5008.5321. Time: 28.3730 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #815: GFLOPs: 4998.4677. Time: 28.4301 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #816: GFLOPs: 5014.8758. Time: 28.3371 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #817: GFLOPs: 5022.7696. Time: 28.2926 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #818: GFLOPs: 4983.9061. Time: 28.5132 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #819: GFLOPs: 5018.9701. Time: 28.3140 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #820: GFLOPs: 5085.6731. Time: 27.9426 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #821: GFLOPs: 4949.6421. Time: 28.7106 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #822: GFLOPs: 5025.5742. Time: 28.2768 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #823: GFLOPs: 5006.0118. Time: 28.3873 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #824: GFLOPs: 4988.7728. Time: 28.4854 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #825: GFLOPs: 4906.1328. Time: 28.9652 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #826: GFLOPs: 4997.4195. Time: 28.4361 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #827: GFLOPs: 4912.7895. Time: 28.9260 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #828: GFLOPs: 5002.5695. Time: 28.4068 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #829: GFLOPs: 4988.7158. Time: 28.4857 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #830: GFLOPs: 165.7109. Time: 857.5606 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #831: GFLOPs: 1456.8097. Time: 97.5468 us. Best GFLOPs: 5148.9275
2023-11-11 08:45:31 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #832: GFLOPs: 33.2339. Time: 4275.9679 us. Best GFLOPs: 5148.9275
2023-11-11 09:09:09 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 09:09:12 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 09:09:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 402 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:09:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 802 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:09:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1200 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:09:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1602 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:09:43 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2004 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:09:49 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2408 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:09:49 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2023-11-11 09:10:05 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 135 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:10:24 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 131 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:10:43 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 142 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:11:02 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 153 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:11:07 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0776  1.0555  0.9893  0.9891  0.9882  0.9871  0.9856  0.9854  0.9847  0.9843  0.9836  0.9836  0.9833  0.9832  0.9821  0.9820
[17 : 32]:	0.9819  0.9819  0.9818  0.9812  0.9809  0.9807  0.9802  0.9801  0.9795  0.9794  0.9785  0.9780  0.9780  0.9777  0.9776  0.9776
[33 : 48]:	0.9776  0.9774  0.9772  0.9772  0.9772  0.9770  0.9766  0.9765  0.9762  0.9762  0.9758  0.9758  0.9757  0.9752  0.9751  0.9751
[49 : 64]:	0.9749  0.9746  0.9741  0.9739  0.9738  0.9737  0.9736  0.9735  0.9732  0.9732  0.9732  0.9731  0.9730  0.9728  0.9728  0.9727
2023-11-11 09:11:08 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 09:11:08 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #833: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(16) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(8)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(64)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(64))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(16) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(64) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[8, 1, 4, 8, 2])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[8, 8, 8])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143 = sch.split(loop=l141, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b144 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b144, ann_key="meta_schedule.unroll_explicit")
b145, b146, b147, b148, b149, b150, b151, b152, b153 = sch.get_child_blocks(b144)
l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b145)
l160, l161, l162, l163, l164, l165 = sch.get_loops(block=b146)
l166, l167, l168, l169, l170, l171 = sch.get_loops(block=b147)
l172, l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b148)
l179, l180, l181, l182, l183, l184 = sch.get_loops(block=b149)
l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198 = sch.get_loops(block=b150)
l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b151)
l206, l207, l208, l209, l210, l211, l212, l213 = sch.get_loops(block=b152)
l214, l215, l216, l217 = sch.get_loops(block=b153)
b218 = sch.get_block(name="data_pack", func_name="main")
l219, l220, l221, l222, l223, l224 = sch.get_loops(block=b218)
b225 = sch.decompose_reduction(block=b218, loop=l223)
b226 = sch.get_block(name="bgemm", func_name="main")
l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240 = sch.get_loops(block=b226)
b241 = sch.decompose_reduction(block=b226, loop=l230)
b242 = sch.get_block(name="inverse", func_name="main")
l243, l244, l245, l246, l247, l248, l249, l250 = sch.get_loops(block=b242)
b251 = sch.decompose_reduction(block=b242, loop=l249)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #834: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(16) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(8)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(64)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(64))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(16) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(64) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(16), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(32) // T.int64(8) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(8) * T.int64(64) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(16) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[8, 1, 4, 8, 2])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[8, 8, 8])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143 = sch.split(loop=l141, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b144 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b144, ann_key="meta_schedule.unroll_explicit")
b145, b146, b147, b148, b149, b150, b151, b152, b153 = sch.get_child_blocks(b144)
l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b145)
l160, l161, l162, l163, l164, l165 = sch.get_loops(block=b146)
sch.annotate(block_or_loop=l160, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l160, ann_key="pragma_unroll_explicit", ann_val=1)
l166, l167, l168, l169, l170, l171 = sch.get_loops(block=b147)
l172, l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b148)
l179, l180, l181, l182, l183, l184 = sch.get_loops(block=b149)
l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198 = sch.get_loops(block=b150)
sch.annotate(block_or_loop=l185, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l185, ann_key="pragma_unroll_explicit", ann_val=1)
l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b151)
l206, l207, l208, l209, l210, l211, l212, l213 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l206, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l206, ann_key="pragma_unroll_explicit", ann_val=1)
l214, l215, l216, l217 = sch.get_loops(block=b153)
b218 = sch.get_block(name="data_pack", func_name="main")
l219, l220, l221, l222, l223, l224 = sch.get_loops(block=b218)
b225 = sch.decompose_reduction(block=b218, loop=l223)
b226 = sch.get_block(name="bgemm", func_name="main")
l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240 = sch.get_loops(block=b226)
b241 = sch.decompose_reduction(block=b226, loop=l230)
b242 = sch.get_block(name="inverse", func_name="main")
l243, l244, l245, l246, l247, l248, l249, l250 = sch.get_loops(block=b242)
b251 = sch.decompose_reduction(block=b242, loop=l249)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #835: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 64, 2])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #836: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(64) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 2, 64])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #837: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(16) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 8, 16])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #838: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(32) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 4, 32])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #839: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 16, 8])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #840: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 16, 8])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #841: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 128, 1])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #842: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 64, 2])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #843: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(16) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 8, 16])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #844: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 2, 2])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 128, 1])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #845: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 2, 2])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 128, 1])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #846: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(16) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 8, 16])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #847: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(64), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(64) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 2, 64])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #848: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(8)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(64) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[8, 32, 2])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #849: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 32, 4])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #850: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(8)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(64) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[8, 8, 8])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #851: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(512), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(32) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(8) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(8)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(32))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(32))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(32) * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(32) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(8) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(64) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(8), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(128) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(128) // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(32) * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(8) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[32, 1, 2, 2, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[8, 8, 8])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 32, 2], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 32, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #852: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(16) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 8, 16])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #853: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 128, 1])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #854: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(8) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(8) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(8) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 1, 8, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 2, 8, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 32, 4])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #855: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(8)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(64) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[8, 8, 8])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #856: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(32), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(32) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 4, 32])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #857: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 128, 1])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135 = sch.split(loop=l133, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l136, l137, l138, l139, l140 = sch.get_loops(block=b107)
l141, l142, l143 = sch.split(loop=l140, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l143)
sch.bind(loop=l142, thread_axis="threadIdx.x")
b144 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b144, ann_key="meta_schedule.unroll_explicit")
b145, b146, b147, b148, b149, b150, b151, b152, b153 = sch.get_child_blocks(b144)
l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b145)
l160, l161, l162, l163, l164, l165 = sch.get_loops(block=b146)
l166, l167, l168, l169, l170, l171 = sch.get_loops(block=b147)
l172, l173, l174, l175, l176, l177 = sch.get_loops(block=b148)
l178, l179, l180, l181, l182, l183, l184 = sch.get_loops(block=b149)
l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198 = sch.get_loops(block=b150)
l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b151)
l206, l207, l208, l209, l210, l211, l212, l213 = sch.get_loops(block=b152)
l214, l215, l216, l217 = sch.get_loops(block=b153)
b218 = sch.get_block(name="data_pack", func_name="main")
l219, l220, l221, l222, l223, l224 = sch.get_loops(block=b218)
b225 = sch.decompose_reduction(block=b218, loop=l223)
b226 = sch.get_block(name="bgemm", func_name="main")
l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240 = sch.get_loops(block=b226)
b241 = sch.decompose_reduction(block=b226, loop=l230)
b242 = sch.get_block(name="inverse", func_name="main")
l243, l244, l245, l246, l247, l248, l249, l250 = sch.get_loops(block=b242)
b251 = sch.decompose_reduction(block=b242, loop=l249)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #858: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(128), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 128, 1])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #859: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 16, 8])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #860: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(64) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(4) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 16, 8])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
sch.annotate(block_or_loop=l161, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l161, ann_key="pragma_unroll_explicit", ann_val=1)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #861: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(64)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(32))
                                    v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(32))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 64, 2])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143 = sch.split(loop=l141, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b144 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b144, ann_key="meta_schedule.unroll_explicit")
b145, b146, b147, b148, b149, b150, b151, b152, b153 = sch.get_child_blocks(b144)
l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b145)
l160, l161, l162, l163, l164, l165 = sch.get_loops(block=b146)
l166, l167, l168, l169, l170, l171 = sch.get_loops(block=b147)
l172, l173, l174, l175, l176, l177, l178 = sch.get_loops(block=b148)
l179, l180, l181, l182, l183, l184 = sch.get_loops(block=b149)
l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198 = sch.get_loops(block=b150)
l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b151)
l206, l207, l208, l209, l210, l211, l212, l213 = sch.get_loops(block=b152)
l214, l215, l216, l217 = sch.get_loops(block=b153)
b218 = sch.get_block(name="data_pack", func_name="main")
l219, l220, l221, l222, l223, l224 = sch.get_loops(block=b218)
b225 = sch.decompose_reduction(block=b218, loop=l223)
b226 = sch.get_block(name="bgemm", func_name="main")
l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240 = sch.get_loops(block=b226)
b241 = sch.decompose_reduction(block=b226, loop=l230)
b242 = sch.get_block(name="inverse", func_name="main")
l243, l244, l245, l246, l247, l248, l249, l250 = sch.get_loops(block=b242)
b251 = sch.decompose_reduction(block=b242, loop=l249)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #862: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                    v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(16) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 8, 16])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135 = sch.split(loop=l133, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l136, l137, l138, l139, l140 = sch.get_loops(block=b107)
l141, l142, l143 = sch.split(loop=l140, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l143)
sch.bind(loop=l142, thread_axis="threadIdx.x")
b144 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b144, ann_key="meta_schedule.unroll_explicit")
b145, b146, b147, b148, b149, b150, b151, b152, b153 = sch.get_child_blocks(b144)
l154, l155, l156, l157, l158, l159 = sch.get_loops(block=b145)
l160, l161, l162, l163, l164, l165 = sch.get_loops(block=b146)
sch.annotate(block_or_loop=l160, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l160, ann_key="pragma_unroll_explicit", ann_val=1)
l166, l167, l168, l169, l170, l171 = sch.get_loops(block=b147)
l172, l173, l174, l175, l176, l177 = sch.get_loops(block=b148)
l178, l179, l180, l181, l182, l183, l184 = sch.get_loops(block=b149)
l185, l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198 = sch.get_loops(block=b150)
sch.annotate(block_or_loop=l185, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l185, ann_key="pragma_unroll_explicit", ann_val=1)
l199, l200, l201, l202, l203, l204, l205 = sch.get_loops(block=b151)
l206, l207, l208, l209, l210, l211, l212, l213 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l206, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l206, ann_key="pragma_unroll_explicit", ann_val=1)
l214, l215, l216, l217 = sch.get_loops(block=b153)
b218 = sch.get_block(name="data_pack", func_name="main")
l219, l220, l221, l222, l223, l224 = sch.get_loops(block=b218)
b225 = sch.decompose_reduction(block=b218, loop=l223)
b226 = sch.get_block(name="bgemm", func_name="main")
l227, l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240 = sch.get_loops(block=b226)
b241 = sch.decompose_reduction(block=b226, loop=l230)
b242 = sch.get_block(name="inverse", func_name="main")
l243, l244, l245, l246, l247, l248, l249, l250 = sch.get_loops(block=b242)
b251 = sch.decompose_reduction(block=b242, loop=l249)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #863: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(64), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(8) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(64), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_1_nu_1_co_1_p_1_fused * T.int64(16) + eps_2_nu_2_co_2_p_2_fused // T.int64(16) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_2_nu_2_co_2_p_2_fused % T.int64(16) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 4])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 16, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 64, 2])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:121] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #864: Error in running:
LocalRunner: An exception occurred
Subprocess terminated
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(512), T.int64(7), T.int64(7)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)))
        inverse_local = T.alloc_buffer((T.int64(512), T.int64(16), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(16)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(512), T.int64(512)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax0)
                        v_p = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps and v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps < T.int64(8) and T.int64(1) <= v_p % T.int64(4) * T.int64(2) + v_nu and v_p % T.int64(4) * T.int64(2) + v_nu < T.int64(8), p0[v_p // T.int64(16), v_ci, v_p % T.int64(16) // T.int64(4) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(4) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                            v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(512), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(16))
                                    v_p = T.axis.spatial(T.int64(16), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(16))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(512), ci_p_fused_0 * T.int64(2) + ci_p_fused_1 // T.int64(16) + ax2)
                        v3 = T.axis.spatial(T.int64(16), ci_p_fused_1 % T.int64(16) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(256), thread="blockIdx.x"):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(8) * T.int64(2) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(4)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(16))
                                        v3 = T.axis.spatial(T.int64(16), (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(16))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16))
                                        v2 = T.axis.spatial(T.int64(512), ci_0 * T.int64(128) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(512) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(32), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(8) * T.int64(2) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(512), ci_0 * T.int64(128) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(64) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(64) // T.int64(16) + ax1)
                            v2 = T.axis.spatial(T.int64(512), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused // T.int64(8) * T.int64(2) + ax2)
                            v3 = T.axis.spatial(T.int64(16), eps_1_nu_1_co_1_p_1_fused * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(8) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(128), thread="blockIdx.x"):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16) + ax0)
                                        v_p = T.axis.spatial(T.int64(16), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(512), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(16))
                        v_h = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(7), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1)
                        T.where((n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(16) // T.int64(4) * T.int64(2) + h_1 < T.int64(7) and (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(4) * T.int64(2) + w_1 < T.int64(7))
                        T.reads(inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w])
                        T.writes(T_add[v_n, v_co, v_h, v_w])
                        T_add[v_n, v_co, v_h, v_w] = inverse_local[v_co, v_n * T.int64(16) + v_h // T.int64(2) * T.int64(4) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w]
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="root", func_name="main")
b6, b7 = sch.get_producers(block=b2)
sch.compute_inline(block=b7)
b8, = sch.get_consumers(block=b2)
l9, l10, l11, l12 = sch.get_loops(block=b8)
l13, l14 = sch.split(loop=l11, factors=[None, 2], preserve_unit_iters=True)
l15, l16 = sch.split(loop=l12, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l13, l15, l14, l16)
sch.compute_at(block=b2, loop=l15, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l17, l18, l19, l20, l21, l22, l23, l24, l25, l26 = sch.get_loops(block=b2)
sch.unroll(loop=l23)
sch.unroll(loop=l24)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
b27, b28 = sch.get_producers(block=b0)
sch.compute_inline(block=b28)
b29, = sch.get_producers(block=b27)
l30, l31, l32, l33, l34, l35 = sch.get_loops(block=b0)
sch.reorder(l32, l33, l30, l31, l34, l35)
sch.unroll(loop=l30)
sch.unroll(loop=l31)
sch.unroll(loop=l34)
sch.unroll(loop=l35)
l36 = sch.fuse(l32, l33, preserve_unit_iters=True)
v37 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l38, l39 = sch.split(loop=l36, factors=[None, v37], preserve_unit_iters=True)
sch.bind(loop=l38, thread_axis="blockIdx.x")
sch.bind(loop=l39, thread_axis="threadIdx.x")
b40 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b40, loop=l39, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b27, loop=l39, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b27, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b29)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l41, l42, l43, l44, l45 = sch.get_loops(block=b1)
v46, v47, v48, v49, v50 = sch.sample_perfect_tile(loop=l41, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l51, l52, l53, l54, l55 = sch.split(loop=l41, factors=[v46, v47, v48, v49, v50], preserve_unit_iters=True)
v56, v57, v58, v59, v60 = sch.sample_perfect_tile(loop=l42, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l61, l62, l63, l64, l65 = sch.split(loop=l42, factors=[v56, v57, v58, v59, v60], preserve_unit_iters=True)
v66, v67, v68, v69, v70 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[16, 1, 16, 2, 1])
l71, l72, l73, l74, l75 = sch.split(loop=l43, factors=[v66, v67, v68, v69, v70], preserve_unit_iters=True)
v76, v77, v78, v79, v80 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 2, 8, 1, 1])
l81, l82, l83, l84, l85 = sch.split(loop=l44, factors=[v76, v77, v78, v79, v80], preserve_unit_iters=True)
v86, v87, v88 = sch.sample_perfect_tile(loop=l45, n=3, max_innermost_factor=64, decision=[4, 32, 4])
l89, l90, l91 = sch.split(loop=l45, factors=[v86, v87, v88], preserve_unit_iters=True)
sch.reorder(l51, l61, l71, l81, l52, l62, l72, l82, l53, l63, l73, l83, l89, l90, l54, l64, l74, l84, l91, l55, l65, l75, l85)
l92 = sch.fuse(l51, l61, l71, l81, preserve_unit_iters=True)
sch.bind(loop=l92, thread_axis="blockIdx.x")
l93 = sch.fuse(l52, l62, l72, l82, preserve_unit_iters=True)
sch.bind(loop=l93, thread_axis="vthread.x")
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b95 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b95, loop=l94, preserve_unit_loops=True, index=-1)
b96 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b96, loop=l89, preserve_unit_loops=True, index=-1)
l97, l98, l99, l100, l101, l102, l103, l104 = sch.get_loops(block=b96)
l105 = sch.fuse(l101, l102, l103, l104, preserve_unit_iters=True)
v106 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch", ann_val=v106)
b107 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b107, loop=l89, preserve_unit_loops=True, index=-1)
l108, l109, l110, l111, l112, l113, l114, l115 = sch.get_loops(block=b107)
l116 = sch.fuse(l112, l113, l114, l115, preserve_unit_iters=True)
v117 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch", ann_val=v117)
sch.reverse_compute_inline(block=b4)
v118 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b5, ann_key="meta_schedule.unroll_explicit", ann_val=v118)
l119, l120, l121, l122, l123, l124 = sch.get_loops(block=b3)
l125 = sch.fuse(l119, l120, l121, l122, preserve_unit_iters=True)
v126 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l127, l128 = sch.split(loop=l125, factors=[None, v126], preserve_unit_iters=True)
sch.bind(loop=l127, thread_axis="blockIdx.x")
sch.bind(loop=l128, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b96, ann_key="meta_schedule.cooperative_fetch")
l129, l130, l131, l132, l133 = sch.get_loops(block=b96)
l134, l135, l136 = sch.split(loop=l133, factors=[None, 128, 4], preserve_unit_iters=True)
sch.vectorize(loop=l136)
sch.bind(loop=l135, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b107, ann_key="meta_schedule.cooperative_fetch")
l137, l138, l139, l140, l141 = sch.get_loops(block=b107)
l142, l143, l144 = sch.split(loop=l141, factors=[None, 128, 4], preserve_unit_iters=True)
sch.vectorize(loop=l144)
sch.bind(loop=l143, thread_axis="threadIdx.x")
b145 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b145, ann_key="meta_schedule.unroll_explicit")
b146, b147, b148, b149, b150, b151, b152, b153, b154 = sch.get_child_blocks(b145)
l155, l156, l157, l158, l159, l160 = sch.get_loops(block=b146)
l161, l162, l163, l164, l165, l166 = sch.get_loops(block=b147)
l167, l168, l169, l170, l171, l172 = sch.get_loops(block=b148)
l173, l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b149)
l180, l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b150)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b151)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b152)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b153)
l216, l217, l218, l219 = sch.get_loops(block=b154)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #865: GFLOPs: 4967.5670. Time: 28.6070 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #866: GFLOPs: 4732.1339. Time: 30.0302 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #867: GFLOPs: 4980.7391. Time: 28.5313 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #868: GFLOPs: 4726.6286. Time: 30.0652 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #869: GFLOPs: 5053.9561. Time: 28.1180 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #870: GFLOPs: 4958.6110. Time: 28.6587 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #871: GFLOPs: 4977.2905. Time: 28.5511 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #872: GFLOPs: 5012.7482. Time: 28.3491 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #873: GFLOPs: 5012.1170. Time: 28.3527 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #874: GFLOPs: 5029.2509. Time: 28.2561 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #875: GFLOPs: 5057.3024. Time: 28.0994 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #876: GFLOPs: 5045.3863. Time: 28.1658 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #877: GFLOPs: 5042.7668. Time: 28.1804 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #878: GFLOPs: 5027.8467. Time: 28.2640 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #879: GFLOPs: 5004.1433. Time: 28.3979 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #880: GFLOPs: 5039.8019. Time: 28.1970 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #881: GFLOPs: 5051.4578. Time: 28.1319 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #882: GFLOPs: 4993.8146. Time: 28.4566 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #883: GFLOPs: 5014.9427. Time: 28.3367 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #884: GFLOPs: 5034.5416. Time: 28.2264 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #885: GFLOPs: 5046.2669. Time: 28.1608 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #886: GFLOPs: 4978.5253. Time: 28.5440 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #887: GFLOPs: 5003.3398. Time: 28.4025 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #888: GFLOPs: 4664.9507. Time: 30.4627 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #889: GFLOPs: 5030.8907. Time: 28.2469 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #890: GFLOPs: 5106.8597. Time: 27.8267 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #891: GFLOPs: 5034.5275. Time: 28.2265 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #892: GFLOPs: 5052.1669. Time: 28.1280 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #893: GFLOPs: 5033.2678. Time: 28.2336 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #894: GFLOPs: 168.5814. Time: 842.9585 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #895: GFLOPs: 78.2233. Time: 1816.6856 us. Best GFLOPs: 5148.9275
2023-11-11 09:11:34 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #896: GFLOPs: 2726.0459. Time: 52.1294 us. Best GFLOPs: 5148.9275
2023-11-11 09:42:05 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 09:42:08 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 09:42:14 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:42:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 801 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:42:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1203 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:42:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1608 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:42:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2003 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:42:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:42:44 [INFO] [evolutionary_search.cc:723] Sampled 59 candidate(s)
2023-11-11 09:43:00 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 148 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:43:18 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 146 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:43:37 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 171 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:43:57 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 153 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 09:44:01 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.0870  1.0839  1.0331  0.9947  0.9910  0.9906  0.9896  0.9893  0.9879  0.9876  0.9863  0.9846  0.9844  0.9844  0.9841  0.9838
[17 : 32]:	0.9834  0.9829  0.9828  0.9825  0.9822  0.9818  0.9809  0.9807  0.9801  0.9797  0.9786  0.9786  0.9778  0.9777  0.9775  0.9775
[33 : 48]:	0.9773  0.9765  0.9765  0.9760  0.9756  0.9755  0.9753  0.9751  0.9750  0.9749  0.9747  0.9740  0.9740  0.9739  0.9738  0.9735
[49 : 64]:	0.9732  0.9731  0.9728  0.9728  0.9726  0.9725  0.9723  0.9720  0.9720  0.9718  0.9716  0.9715  0.9714  0.9708  0.9708  0.9707
2023-11-11 09:44:02 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 09:44:02 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #897: GFLOPs: 3458.9909. Time: 41.0834 us. Best GFLOPs: 5148.9275
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #898: GFLOPs: 3471.9328. Time: 40.9303 us. Best GFLOPs: 5148.9275
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #899: GFLOPs: 2988.3257. Time: 47.5541 us. Best GFLOPs: 5148.9275
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #900: GFLOPs: 3757.8483. Time: 37.8161 us. Best GFLOPs: 5148.9275
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #901: GFLOPs: 5104.5846. Time: 27.8391 us. Best GFLOPs: 5148.9275
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #902: GFLOPs: 3760.3647. Time: 37.7908 us. Best GFLOPs: 5148.9275
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #903: GFLOPs: 5085.9640. Time: 27.9410 us. Best GFLOPs: 5148.9275
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #904: GFLOPs: 4765.7105. Time: 29.8187 us. Best GFLOPs: 5148.9275
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #905: GFLOPs: 5085.8756. Time: 27.9415 us. Best GFLOPs: 5148.9275
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #906: GFLOPs: 5179.3225. Time: 27.4374 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #907: GFLOPs: 5068.8228. Time: 28.0355 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #908: GFLOPs: 4747.0265. Time: 29.9360 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #909: GFLOPs: 5082.1250. Time: 27.9621 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #910: GFLOPs: 5071.1081. Time: 28.0229 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #911: GFLOPs: 5072.5202. Time: 28.0151 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #912: GFLOPs: 5043.3238. Time: 28.1773 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #913: GFLOPs: 5080.7555. Time: 27.9697 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #914: GFLOPs: 5128.3247. Time: 27.7102 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #915: GFLOPs: 5121.7071. Time: 27.7460 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #916: GFLOPs: 5108.7250. Time: 27.8166 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #917: GFLOPs: 5032.3634. Time: 28.2386 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #918: GFLOPs: 5138.8806. Time: 27.6533 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #919: GFLOPs: 5104.8166. Time: 27.8379 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #920: GFLOPs: 5050.4795. Time: 28.1374 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #921: GFLOPs: 4989.4967. Time: 28.4813 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #922: GFLOPs: 5087.5672. Time: 27.9322 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #923: GFLOPs: 5075.3814. Time: 27.9993 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #924: GFLOPs: 5120.1226. Time: 27.7546 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #925: GFLOPs: 4751.4707. Time: 29.9080 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #926: GFLOPs: 5164.7175. Time: 27.5150 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #927: GFLOPs: 5041.9601. Time: 28.1849 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #928: GFLOPs: 5104.3040. Time: 27.8406 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #929: GFLOPs: 5043.6414. Time: 28.1755 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #930: GFLOPs: 5050.7157. Time: 28.1360 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #931: GFLOPs: 5086.4844. Time: 27.9382 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #932: GFLOPs: 5024.3224. Time: 28.2838 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #933: GFLOPs: 5054.3281. Time: 28.1159 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #934: GFLOPs: 5154.6585. Time: 27.5687 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #935: GFLOPs: 5136.8004. Time: 27.6645 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #936: GFLOPs: 5023.5380. Time: 28.2883 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #937: GFLOPs: 5055.8908. Time: 28.1072 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #938: GFLOPs: 5013.6788. Time: 28.3439 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #939: GFLOPs: 5071.2088. Time: 28.0223 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #940: GFLOPs: 4986.6673. Time: 28.4974 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #941: GFLOPs: 5055.2062. Time: 28.1110 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #942: GFLOPs: 5033.2009. Time: 28.2339 us. Best GFLOPs: 5179.3225
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #943: GFLOPs: 5227.3331. Time: 27.1854 us. Best GFLOPs: 5227.3331
2023-11-11 09:44:37 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #944: GFLOPs: 5042.5654. Time: 28.1815 us. Best GFLOPs: 5227.3331
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #945: GFLOPs: 5032.3416. Time: 28.2388 us. Best GFLOPs: 5227.3331
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #946: GFLOPs: 4993.4811. Time: 28.4585 us. Best GFLOPs: 5227.3331
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #947: GFLOPs: 5046.9740. Time: 28.1569 us. Best GFLOPs: 5227.3331
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #948: GFLOPs: 5126.6604. Time: 27.7192 us. Best GFLOPs: 5227.3331
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #949: GFLOPs: 5035.0441. Time: 28.2236 us. Best GFLOPs: 5227.3331
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #950: GFLOPs: 5086.3831. Time: 27.9387 us. Best GFLOPs: 5227.3331
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #951: GFLOPs: 5097.3648. Time: 27.8785 us. Best GFLOPs: 5227.3331
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #952: GFLOPs: 5043.4729. Time: 28.1764 us. Best GFLOPs: 5227.3331
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #953: GFLOPs: 5239.7045. Time: 27.1212 us. Best GFLOPs: 5239.7045
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #954: GFLOPs: 5054.1540. Time: 28.1169 us. Best GFLOPs: 5239.7045
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #955: GFLOPs: 5080.8221. Time: 27.9693 us. Best GFLOPs: 5239.7045
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #956: GFLOPs: 4744.3208. Time: 29.9531 us. Best GFLOPs: 5239.7045
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #957: GFLOPs: 5005.3066. Time: 28.3913 us. Best GFLOPs: 5239.7045
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #958: GFLOPs: 835.6563. Time: 170.0545 us. Best GFLOPs: 5239.7045
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #959: GFLOPs: 1517.0341. Time: 93.6743 us. Best GFLOPs: 5239.7045
2023-11-11 09:44:38 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #960: GFLOPs: 906.3520. Time: 156.7902 us. Best GFLOPs: 5239.7045
2023-11-11 10:10:25 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 10:10:28 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 10:10:35 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 398 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 10:10:41 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 798 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 10:10:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1201 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 10:10:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 1601 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 10:10:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2004 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 10:11:05 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 2406 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 10:11:05 [INFO] [evolutionary_search.cc:723] Sampled 54 candidate(s)
2023-11-11 10:11:21 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 140 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 10:11:41 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 166 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 10:12:00 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 152 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 10:12:20 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310bad9f88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310e77bca8)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310eeacc18)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c0528e8)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x563110610988)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eb99518)]: 149 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310e76d6e8)]: 0 failure(s)
2023-11-11 10:12:25 [INFO] [evolutionary_search.cc:649] Scores of the best 40 candidates:
[1 : 16]:	0.9705  0.9701  0.9692  0.9690  0.9690  0.9677  0.9675  0.9675  0.9670  0.9667  0.9662  0.9662  0.9661  0.9657  0.9654  0.9650
[17 : 32]:	0.9647  0.9646  0.9645  0.9639  0.9638  0.9638  0.9634  0.9633  0.9633  0.9633  0.9629  0.9629  0.9628  0.9626  0.9624  0.9623
[33 : 40]:	0.9622  0.9620  0.9620  0.9619  0.9619  0.9619  0.9615  0.9615
2023-11-11 10:12:25 [INFO] [evolutionary_search.cc:727] Got 40 candidate(s) with evolutionary search
2023-11-11 10:12:25 [INFO] [evolutionary_search.cc:730] Sending 40 candidates(s) for measurement
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #961: GFLOPs: 5134.3127. Time: 27.6779 us. Best GFLOPs: 5239.7045
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #962: GFLOPs: 5136.6259. Time: 27.6655 us. Best GFLOPs: 5239.7045
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #963: GFLOPs: 5119.0948. Time: 27.7602 us. Best GFLOPs: 5239.7045
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #964: GFLOPs: 5163.2903. Time: 27.5226 us. Best GFLOPs: 5239.7045
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #965: GFLOPs: 5168.9801. Time: 27.4923 us. Best GFLOPs: 5239.7045
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #966: GFLOPs: 5109.6911. Time: 27.8113 us. Best GFLOPs: 5239.7045
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #967: GFLOPs: 5098.7920. Time: 27.8707 us. Best GFLOPs: 5239.7045
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #968: GFLOPs: 5135.8800. Time: 27.6695 us. Best GFLOPs: 5239.7045
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #969: GFLOPs: 5249.2931. Time: 27.0717 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #970: GFLOPs: 5115.2950. Time: 27.7808 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #971: GFLOPs: 5161.6536. Time: 27.5313 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #972: GFLOPs: 5090.0724. Time: 27.9185 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #973: GFLOPs: 5113.0038. Time: 27.7933 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #974: GFLOPs: 5048.7601. Time: 28.1469 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #975: GFLOPs: 4610.4027. Time: 30.8232 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #976: GFLOPs: 5125.2341. Time: 27.7270 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #977: GFLOPs: 5145.4060. Time: 27.6183 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #978: GFLOPs: 5108.0171. Time: 27.8204 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #979: GFLOPs: 5062.6181. Time: 28.0699 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #980: GFLOPs: 5048.6499. Time: 28.1476 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #981: GFLOPs: 5074.8151. Time: 28.0024 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #982: GFLOPs: 5073.0922. Time: 28.0119 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #983: GFLOPs: 5141.8852. Time: 27.6372 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #984: GFLOPs: 5062.3150. Time: 28.0716 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #985: GFLOPs: 5182.5132. Time: 27.4205 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #986: GFLOPs: 5143.5684. Time: 27.6281 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #987: GFLOPs: 5076.9277. Time: 27.9908 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #988: GFLOPs: 5176.6207. Time: 27.4517 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #989: GFLOPs: 5086.5182. Time: 27.9380 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #990: GFLOPs: 5087.7704. Time: 27.9311 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #991: GFLOPs: 5038.4995. Time: 28.2043 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #992: GFLOPs: 5044.1126. Time: 28.1729 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #993: GFLOPs: 5058.8249. Time: 28.0909 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #994: GFLOPs: 5124.6916. Time: 27.7299 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #995: GFLOPs: 5124.9632. Time: 27.7284 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #996: GFLOPs: 5114.3374. Time: 27.7860 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #997: GFLOPs: 5012.8151. Time: 28.3488 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #998: GFLOPs: 5071.5140. Time: 28.0207 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #999: GFLOPs: 25.2321. Time: 5631.9999 us. Best GFLOPs: 5249.2931
2023-11-11 10:12:50 [INFO] [task_scheduler.cc:131] [Task #22: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_3] Trial #1000: GFLOPs: 1114.8811. Time: 127.4639 us. Best GFLOPs: 5249.2931
