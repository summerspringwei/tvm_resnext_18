2023-11-10 23:34:17 [INFO] [task_scheduler.cc:160] Initializing Task #20: "fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2"
2023-11-10 23:34:17 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        data_pad = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(16), T.int64(16)))
        input_tile = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)))
        B = T.alloc_buffer((T.int64(4), T.int64(4)))
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        A = T.alloc_buffer((T.int64(4), T.int64(2)))
        inverse = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)))
        conv2d_winograd = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)))
        T_add = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)))
        T_add_1 = T.alloc_buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)))
        for i0, i1, i2, i3 in T.grid(T.int64(1), T.int64(256), T.int64(16), T.int64(16)):
            with T.block("data_pad"):
                v_i0, v_i1, v_i2, v_i3 = T.axis.remap("SSSS", [i0, i1, i2, i3])
                T.reads(p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)])
                T.writes(data_pad[v_i0, v_i1, v_i2, v_i3])
                data_pad[v_i0, v_i1, v_i2, v_i3] = T.if_then_else(T.int64(1) <= v_i2 and v_i2 < T.int64(15) and T.int64(1) <= v_i3 and v_i3 < T.int64(15), p0[v_i0, v_i1, v_i2 - T.int64(1), v_i3 - T.int64(1)], T.float32(0))
        for ci, p, eps, nu in T.grid(T.int64(256), T.int64(49), T.int64(4), T.int64(4)):
            with T.block("input_tile"):
                v_ci, v_p, v_eps, v_nu = T.axis.remap("SSSS", [ci, p, eps, nu])
                T.reads(data_pad[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps, v_p % T.int64(7) * T.int64(2) + v_nu])
                T.writes(input_tile[v_ci, v_p, v_eps, v_nu])
                T.block_attr({"schedule_rule": "None"})
                input_tile[v_ci, v_p, v_eps, v_nu] = data_pad[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps, v_p % T.int64(7) * T.int64(2) + v_nu]
        for i, j in T.grid(T.int64(4), T.int64(4)):
            with T.block("B"):
                v_i, v_j = T.axis.remap("SS", [i, j])
                T.reads()
                T.writes(B[v_i, v_j])
                T.block_attr({"schedule_rule": "None"})
                B[v_i, v_j] = T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
        for eps, nu, ci, p, r_a, r_b in T.grid(T.int64(4), T.int64(4), T.int64(256), T.int64(49), T.int64(4), T.int64(4)):
            with T.block("data_pack"):
                v_eps, v_nu, v_ci, v_p, v_r_a, v_r_b = T.axis.remap("SSSSRR", [eps, nu, ci, p, r_a, r_b])
                T.reads(input_tile[v_ci, v_p, v_r_a, v_r_b], B[T.min(v_r_a, v_r_b):T.min(v_r_a, v_r_b) + (T.max(v_r_a, v_r_b) + T.int64(1) - T.min(v_r_a, v_r_b)), T.min(v_eps, v_nu):T.min(v_eps, v_nu) + (T.max(v_eps, v_nu) + T.int64(1) - T.min(v_eps, v_nu))])
                T.writes(data_pack[v_eps, v_nu, v_ci, v_p])
                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                with T.init():
                    data_pack[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                data_pack[v_eps, v_nu, v_ci, v_p] = data_pack[v_eps, v_nu, v_ci, v_p] + input_tile[v_ci, v_p, v_r_a, v_r_b] * B[v_r_a, v_eps] * B[v_r_b, v_nu]
        for eps, nu, co, p, ci in T.grid(T.int64(4), T.int64(4), T.int64(256), T.int64(49), T.int64(256)):
            with T.block("bgemm"):
                v_eps, v_nu, v_co, v_p, v_ci = T.axis.remap("SSSSR", [eps, nu, co, p, ci])
                T.reads(data_pack[v_eps, v_nu, v_ci, v_p], p1[v_eps, v_nu, v_ci, v_co])
                T.writes(bgemm[v_eps, v_nu, v_co, v_p])
                with T.init():
                    bgemm[v_eps, v_nu, v_co, v_p] = T.float32(0)
                bgemm[v_eps, v_nu, v_co, v_p] = bgemm[v_eps, v_nu, v_co, v_p] + data_pack[v_eps, v_nu, v_ci, v_p] * p1[v_eps, v_nu, v_ci, v_co]
        for i, j in T.grid(T.int64(4), T.int64(2)):
            with T.block("A"):
                v_i, v_j = T.axis.remap("SS", [i, j])
                T.reads()
                T.writes(A[v_i, v_j])
                T.block_attr({"schedule_rule": "None"})
                A[v_i, v_j] = T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(3) and v_j % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(2) and v_j % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_i % T.int64(4) == T.int64(1) and v_j % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_i % T.int64(4) == T.int64(0) and v_j % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
        for co, p, vh, vw, r_a, r_b in T.grid(T.int64(256), T.int64(49), T.int64(2), T.int64(2), T.int64(4), T.int64(4)):
            with T.block("inverse"):
                v_co, v_p, v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSSSRR", [co, p, vh, vw, r_a, r_b])
                T.reads(bgemm[v_r_a, v_r_b, v_co, v_p], A[T.min(v_r_a, v_r_b):T.min(v_r_a, v_r_b) + (T.max(v_r_a, v_r_b) + T.int64(1) - T.min(v_r_a, v_r_b)), T.min(v_vh, v_vw):T.min(v_vh, v_vw) + (T.max(v_vh, v_vw) + T.int64(1) - T.min(v_vh, v_vw))])
                T.writes(inverse[v_co, v_p, v_vh, v_vw])
                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                with T.init():
                    inverse[v_co, v_p, v_vh, v_vw] = T.float32(0)
                inverse[v_co, v_p, v_vh, v_vw] = inverse[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * A[v_r_a, v_vh] * A[v_r_b, v_vw]
        for n, co, h, w in T.grid(T.int64(1), T.int64(256), T.int64(14), T.int64(14)):
            with T.block("conv2d_winograd"):
                v_n, v_co, v_h, v_w = T.axis.remap("SSSS", [n, co, h, w])
                T.reads(inverse[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)])
                T.writes(conv2d_winograd[v_n, v_co, v_h, v_w])
                conv2d_winograd[v_n, v_co, v_h, v_w] = inverse[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(14), T.int64(14)):
            with T.block("T_add"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(conv2d_winograd[v_ax0, v_ax1, v_ax2, v_ax3], p2[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_add[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add[v_ax0, v_ax1, v_ax2, v_ax3] = conv2d_winograd[v_ax0, v_ax1, v_ax2, v_ax3] + p2[v_ax0, v_ax1, v_ax2, v_ax3]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(14), T.int64(14)):
            with T.block("T_add_1"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_add[v_ax0, v_ax1, v_ax2, v_ax3], p3[v_ax0, v_ax1, T.int64(0), T.int64(0)])
                T.writes(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T_add_1[v_ax0, v_ax1, v_ax2, v_ax3] = T_add[v_ax0, v_ax1, v_ax2, v_ax3] + p3[v_ax0, v_ax1, T.int64(0), T.int64(0)]
        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(256), T.int64(14), T.int64(14)):
            with T.block("T_relu"):
                v_ax0, v_ax1, v_ax2, v_ax3 = T.axis.remap("SSSS", [ax0, ax1, ax2, ax3])
                T.reads(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3])
                T.writes(T_relu[v_ax0, v_ax1, v_ax2, v_ax3])
                T_relu[v_ax0, v_ax1, v_ax2, v_ax3] = T.max(T_add_1[v_ax0, v_ax1, v_ax2, v_ax3], T.float32(0))
2023-11-10 23:34:17 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2023-11-10 23:34:17 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 512})
            input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
            data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
            bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
            inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
            data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
            bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
            data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
            for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x"):
                for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("input_tile"):
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                            v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                            T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                            T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                            T.block_attr({"schedule_rule": "None"})
                            input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                    for eps in T.unroll(T.int64(4)):
                        for nu in T.unroll(T.int64(4)):
                            for r_a in T.unroll(T.int64(4)):
                                for r_b in T.unroll(T.int64(4)):
                                    with T.block("data_pack"):
                                        v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                        v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                        T.reads(input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                        T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                        with T.init():
                                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                                        data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("data_pack_local"):
                            v0, v1 = T.axis.remap("SS", [ax0, ax1])
                            v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                            v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                            T.reads(data_pack_local[v0, v1, v2, v3])
                            T.writes(data_pack[v0, v1, v2, v3])
                            data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
            for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(32), thread="blockIdx.x"):
                for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(16), thread="vthread.x"):
                    for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(28), thread="threadIdx.x"):
                        for ci_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(100352)):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(25088))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + ax0_ax1_ax2_ax3_fused % T.int64(25088) // T.int64(12544))
                                    v2 = T.axis.spatial(T.int64(256), ax0_ax1_ax2_ax3_fused % T.int64(12544) // T.int64(49))
                                    v3 = T.axis.spatial(T.int64(49), ax0_ax1_ax2_ax3_fused % T.int64(49))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(32768)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(8192))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + ax0_ax1_ax2_ax3_fused % T.int64(8192) // T.int64(4096))
                                    v2 = T.axis.spatial(T.int64(256), ax0_ax1_ax2_ax3_fused % T.int64(4096) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(16))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 4})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(256), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                                with T.block("bgemm"):
                                    v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(4) + eps_3 + eps_4)
                                    v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) // T.int64(2) + nu_3 + nu_4)
                                    v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(16) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused // T.int64(7) * T.int64(2) + co_3 * T.int64(2) + co_4)
                                    v_p = T.axis.spatial(T.int64(49), eps_2_nu_2_co_2_p_2_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                    v_ci = T.axis.reduce(T.int64(256), ci_0 * T.int64(256) + ci_1 + ci_2)
                                    T.reads(data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                    T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                                    bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(7)):
                            with T.block("bgemm_local"):
                                v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(4) + ax0)
                                v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) // T.int64(2) + ax1)
                                v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(16) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused // T.int64(7) * T.int64(2) + ax2)
                                v3 = T.axis.spatial(T.int64(49), eps_2_nu_2_co_2_p_2_fused % T.int64(7) * T.int64(7) + ax3)
                                T.reads(bgemm_local[v0, v1, v2, v3])
                                T.writes(bgemm[v0, v1, v2, v3])
                                bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
            for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x"):
                for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                        for ax2 in T.unroll(T.int64(2)):
                            for ax3 in T.unroll(T.int64(2)):
                                for ax4 in T.unroll(T.int64(4)):
                                    for ax5 in T.unroll(T.int64(4)):
                                        with T.block("inverse"):
                                            v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                            v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                            v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                            T.reads(bgemm[v_r_a, v_r_b, v_co, v_p])
                                            T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                            with T.init():
                                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                                            inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                    for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                        with T.block("conv2d_winograd"):
                            v_n = T.axis.spatial(T.int64(1), T.int64(0))
                            v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49))
                            v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                            v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                            T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                            T.writes(T_relu[v_n, v_co, v_h, v_w])
                            T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 4, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 2])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[1, 1, 7, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[1, 256, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
2023-11-10 23:34:17 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 512})
            input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
            data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
            bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
            inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
            data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
            bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
            data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
            for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x"):
                for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("input_tile"):
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                            v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                            T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                            T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                            T.block_attr({"schedule_rule": "None"})
                            input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                    for eps in T.unroll(T.int64(4)):
                        for nu in T.unroll(T.int64(4)):
                            for r_a in T.unroll(T.int64(4)):
                                for r_b in T.unroll(T.int64(4)):
                                    with T.block("data_pack"):
                                        v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                        v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                        T.reads(input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                        T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                        with T.init():
                                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                                        data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("data_pack_local"):
                            v0, v1 = T.axis.remap("SS", [ax0, ax1])
                            v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                            v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                            T.reads(data_pack_local[v0, v1, v2, v3])
                            T.writes(data_pack[v0, v1, v2, v3])
                            data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
            for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(32), thread="blockIdx.x"):
                for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(16), thread="vthread.x"):
                    for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(28), thread="threadIdx.x"):
                        for ci_0_fused in T.serial(T.int64(1), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(100352)):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(25088))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + ax0_ax1_ax2_ax3_fused % T.int64(25088) // T.int64(12544))
                                    v2 = T.axis.spatial(T.int64(256), ax0_ax1_ax2_ax3_fused % T.int64(12544) // T.int64(49))
                                    v3 = T.axis.spatial(T.int64(49), ax0_ax1_ax2_ax3_fused % T.int64(49))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(32768)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(8192))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + ax0_ax1_ax2_ax3_fused % T.int64(8192) // T.int64(4096))
                                    v2 = T.axis.spatial(T.int64(256), ax0_ax1_ax2_ax3_fused % T.int64(4096) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(16))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 4})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(256), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                                with T.block("bgemm"):
                                    v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(4) + eps_3 + eps_4)
                                    v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) // T.int64(2) + nu_3 + nu_4)
                                    v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(16) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused // T.int64(7) * T.int64(2) + co_3 * T.int64(2) + co_4)
                                    v_p = T.axis.spatial(T.int64(49), eps_2_nu_2_co_2_p_2_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                    v_ci = T.axis.reduce(T.int64(256), ci_1 + ci_2)
                                    T.reads(data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                    T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                                    bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(7)):
                            with T.block("bgemm_local"):
                                v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(4) + ax0)
                                v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) // T.int64(2) + ax1)
                                v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(16) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused // T.int64(7) * T.int64(2) + ax2)
                                v3 = T.axis.spatial(T.int64(49), eps_2_nu_2_co_2_p_2_fused % T.int64(7) * T.int64(7) + ax3)
                                T.reads(bgemm_local[v0, v1, v2, v3])
                                T.writes(bgemm[v0, v1, v2, v3])
                                bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
            for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x"):
                for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                        for ax2 in T.unroll(T.int64(2)):
                            for ax3 in T.unroll(T.int64(2)):
                                for ax4 in T.unroll(T.int64(4)):
                                    for ax5 in T.unroll(T.int64(4)):
                                        with T.block("inverse"):
                                            v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                            v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                            v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                            T.reads(bgemm[v_r_a, v_r_b, v_co, v_p])
                                            T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                            with T.init():
                                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                                            inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                    for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                        with T.block("conv2d_winograd"):
                            v_n = T.axis.spatial(T.int64(1), T.int64(0))
                            v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49))
                            v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                            v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                            T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                            T.writes(T_relu[v_n, v_co, v_h, v_w])
                            T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 4, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 2])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[1, 1, 7, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[1, 256, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
2023-11-10 23:34:17 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 512})
            input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
            data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
            bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
            inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
            data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
            bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
            data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
            for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x"):
                for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                        with T.block("input_tile"):
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                            v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                            T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                            T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                            T.block_attr({"schedule_rule": "None"})
                            input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                    for eps in T.unroll(T.int64(4)):
                        for nu in T.unroll(T.int64(4)):
                            for r_a in T.unroll(T.int64(4)):
                                for r_b in T.unroll(T.int64(4)):
                                    with T.block("data_pack"):
                                        v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                        v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                        T.reads(input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                        T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                        with T.init():
                                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                                        data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                        with T.block("data_pack_local"):
                            v0, v1 = T.axis.remap("SS", [ax0, ax1])
                            v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                            v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                            T.reads(data_pack_local[v0, v1, v2, v3])
                            T.writes(data_pack[v0, v1, v2, v3])
                            data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
            for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(32), thread="blockIdx.x"):
                for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(16), thread="vthread.x"):
                    for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(28), thread="threadIdx.x"):
                        for ci_0_fused in T.serial(T.int64(1), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(100352)):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(25088))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + ax0_ax1_ax2_ax3_fused % T.int64(25088) // T.int64(12544))
                                    v2 = T.axis.spatial(T.int64(256), ax0_ax1_ax2_ax3_fused % T.int64(12544) // T.int64(49))
                                    v3 = T.axis.spatial(T.int64(49), ax0_ax1_ax2_ax3_fused % T.int64(49))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                            for ax0_ax1_ax2_ax3_fused in range(T.int64(32768)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), ax0_ax1_ax2_ax3_fused // T.int64(8192))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + ax0_ax1_ax2_ax3_fused % T.int64(8192) // T.int64(4096))
                                    v2 = T.axis.spatial(T.int64(256), ax0_ax1_ax2_ax3_fused % T.int64(4096) // T.int64(16))
                                    v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(16) + ax0_ax1_ax2_ax3_fused % T.int64(16))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 4})
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                            for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(256), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                                with T.block("bgemm"):
                                    v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(4) + eps_3 + eps_4)
                                    v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) // T.int64(2) + nu_3 + nu_4)
                                    v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(16) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused // T.int64(7) * T.int64(2) + co_3 * T.int64(2) + co_4)
                                    v_p = T.axis.spatial(T.int64(49), eps_2_nu_2_co_2_p_2_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                    v_ci = T.axis.reduce(T.int64(256), ci_1 + ci_2)
                                    T.reads(data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                    T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                                    bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                        for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(7)):
                            with T.block("bgemm_local"):
                                v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(4) + ax0)
                                v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(16) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused % T.int64(4) // T.int64(2) + ax1)
                                v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(16) * T.int64(16) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused // T.int64(7) * T.int64(2) + ax2)
                                v3 = T.axis.spatial(T.int64(49), eps_2_nu_2_co_2_p_2_fused % T.int64(7) * T.int64(7) + ax3)
                                T.reads(bgemm_local[v0, v1, v2, v3])
                                T.writes(bgemm[v0, v1, v2, v3])
                                bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
            for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(196), thread="blockIdx.x"):
                for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                        for ax2 in T.unroll(T.int64(2)):
                            for ax3 in T.unroll(T.int64(2)):
                                for ax4 in T.unroll(T.int64(4)):
                                    for ax5 in T.unroll(T.int64(4)):
                                        with T.block("inverse"):
                                            v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                            v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                            v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                            T.reads(bgemm[v_r_a, v_r_b, v_co, v_p])
                                            T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                            with T.init():
                                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                                            inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                    for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                        with T.block("conv2d_winograd"):
                            v_n = T.axis.spatial(T.int64(1), T.int64(0))
                            v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49))
                            v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                            v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                            T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                            T.writes(T_relu[v_n, v_co, v_h, v_w])
                            T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 4, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[16, 2, 4, 1, 2])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[1, 1, 7, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[1, 256, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
2023-11-11 00:04:01 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 00:04:01 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2023-11-11 00:04:09 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 497 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:04:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 993 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:04:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1493 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:04:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1982 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:04:33 [INFO] [evolutionary_search.cc:723] Sampled 66 candidate(s)
2023-11-11 00:04:51 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 125 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:05:09 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 123 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:05:27 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 127 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:05:44 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 100 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:05:45 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9997  0.9996  0.9991  0.9982  0.9971  0.9971  0.9956  0.9944  0.9933  0.9932  0.9919  0.9910  0.9905  0.9905  0.9901  0.9882
[17 : 32]:	0.9881  0.9874  0.9848  0.9847  0.9843  0.9818  0.9814  0.9806  0.9802  0.9798  0.9797  0.9781  0.9775  0.9769  0.9768  0.9758
[33 : 48]:	0.9754  0.9739  0.9725  0.9718  0.9711  0.9692  0.9688  0.9684  0.9681  0.9678  0.9674  0.9665  0.9664  0.9656  0.9654  0.9643
[49 : 64]:	0.9627  0.9624  0.9611  0.9608  0.9605  0.9603  0.9601  0.9598  0.9595  0.9593  0.9593  0.9592  0.9591  0.9582  0.9581  0.9578
2023-11-11 00:05:45 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 00:05:45 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #1: GFLOPs: 1330.8311. Time: 86.3770 us. Best GFLOPs: 1330.8311
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #2: GFLOPs: 38.0062. Time: 3024.5949 us. Best GFLOPs: 1330.8311
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #3: GFLOPs: 104.1342. Time: 1103.8945 us. Best GFLOPs: 1330.8311
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #4: GFLOPs: 141.5875. Time: 811.8879 us. Best GFLOPs: 1330.8311
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #5: GFLOPs: 1449.9327. Time: 79.2818 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #6: GFLOPs: 26.4546. Time: 4345.3013 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #7: GFLOPs: 34.7805. Time: 3305.1086 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #8: GFLOPs: 192.4464. Time: 597.3258 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #9: GFLOPs: 910.5214. Time: 126.2499 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #10: GFLOPs: 839.6533. Time: 136.9056 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #11: GFLOPs: 80.8044. Time: 1422.6100 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #12: GFLOPs: 115.9214. Time: 991.6477 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #13: GFLOPs: 1018.3054. Time: 112.8868 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #14: GFLOPs: 739.4917. Time: 155.4490 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #15: GFLOPs: 113.6817. Time: 1011.1845 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #16: GFLOPs: 796.0412. Time: 144.4061 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #17: GFLOPs: 70.3377. Time: 1634.3040 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #18: GFLOPs: 1253.9396. Time: 91.6736 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #19: GFLOPs: 71.3374. Time: 1611.4021 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #20: GFLOPs: 11.0777. Time: 10377.0111 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #21: GFLOPs: 54.1540. Time: 2122.7093 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #22: GFLOPs: 63.1514. Time: 1820.2810 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #23: GFLOPs: 12.4536. Time: 9230.5221 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #24: GFLOPs: 523.2120. Time: 219.7068 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #25: GFLOPs: 26.9702. Time: 4262.2292 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #26: GFLOPs: 77.9951. Time: 1473.8523 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #27: GFLOPs: 523.2287. Time: 219.6998 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #28: GFLOPs: 972.7030. Time: 118.1792 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #29: GFLOPs: 879.3619. Time: 130.7234 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #30: GFLOPs: 8.2875. Time: 13870.7199 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #31: GFLOPs: 60.4211. Time: 1902.5340 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #32: GFLOPs: 966.7315. Time: 118.9091 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #33: GFLOPs: 110.7902. Time: 1037.5759 us. Best GFLOPs: 1449.9327
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #34: GFLOPs: 1858.7224. Time: 61.8453 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #35: GFLOPs: 33.9035. Time: 3390.6006 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #36: GFLOPs: 528.0905. Time: 217.6771 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #37: GFLOPs: 53.0056. Time: 2168.7013 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #38: GFLOPs: 83.0747. Time: 1383.7326 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #39: GFLOPs: 57.5977. Time: 1995.7960 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #40: GFLOPs: 293.0522. Time: 392.2619 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #41: GFLOPs: 6.4652. Time: 17780.2238 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #42: GFLOPs: 1373.4026. Time: 83.6996 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #43: GFLOPs: 508.7395. Time: 225.9569 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #44: GFLOPs: 1636.3314. Time: 70.2506 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #45: GFLOPs: 13.3333. Time: 8621.4828 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #46: GFLOPs: 201.3302. Time: 570.9686 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #47: GFLOPs: 6.7112. Time: 17128.6188 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #48: GFLOPs: 1690.3251. Time: 68.0066 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #49: GFLOPs: 83.4384. Time: 1377.7008 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #50: GFLOPs: 1320.9743. Time: 87.0215 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #51: GFLOPs: 119.3817. Time: 962.9046 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #52: GFLOPs: 36.8238. Time: 3121.7105 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #53: GFLOPs: 250.3934. Time: 459.0904 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #54: GFLOPs: 60.2950. Time: 1906.5141 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #55: GFLOPs: 35.4971. Time: 3238.3834 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #56: GFLOPs: 97.0871. Time: 1184.0211 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #57: GFLOPs: 216.0595. Time: 532.0443 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #58: GFLOPs: 20.3992. Time: 5635.1856 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #59: GFLOPs: 909.8745. Time: 126.3396 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #60: GFLOPs: 30.3667. Time: 3785.5004 us. Best GFLOPs: 1858.7224
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #61: GFLOPs: 2039.6316. Time: 56.3598 us. Best GFLOPs: 2039.6316
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #62: GFLOPs: 300.3861. Time: 382.6848 us. Best GFLOPs: 2039.6316
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #63: GFLOPs: 34.5241. Time: 3329.6516 us. Best GFLOPs: 2039.6316
2023-11-11 00:28:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #64: GFLOPs: 83.2274. Time: 1381.1936 us. Best GFLOPs: 2039.6316
2023-11-11 00:45:09 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 00:45:11 [INFO] [evolutionary_search.cc:715] Picked top 64 candidate(s) from database
2023-11-11 00:45:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 436 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:45:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 868 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:45:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1304 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:45:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1739 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:45:39 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2023-11-11 00:45:58 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 115 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:46:20 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 87 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:46:43 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 87 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:47:06 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 112 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 00:47:13 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.1589  1.1045  1.1044  1.0768  1.0675  1.0664  1.0624  1.0618  1.0577  1.0498  1.0423  1.0316  1.0306  1.0299  1.0171  1.0156
[17 : 32]:	1.0137  1.0136  1.0134  1.0132  1.0126  1.0126  1.0126  1.0109  1.0089  1.0052  1.0046  1.0033  1.0033  1.0029  1.0014  1.0009
[33 : 48]:	0.9911  0.9885  0.9873  0.9849  0.9836  0.9833  0.9810  0.9799  0.9792  0.9762  0.9755  0.9755  0.9727  0.9722  0.9707  0.9677
[49 : 64]:	0.9629  0.9628  0.9624  0.9577  0.9571  0.9551  0.9517  0.9498  0.9497  0.9491  0.9455  0.9454  0.9438  0.9419  0.9409  0.9392
2023-11-11 00:47:13 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 00:47:13 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #65: GFLOPs: 2714.3774. Time: 42.3498 us. Best GFLOPs: 2714.3774
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #66: GFLOPs: 1640.0527. Time: 70.0912 us. Best GFLOPs: 2714.3774
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #67: GFLOPs: 2062.0179. Time: 55.7479 us. Best GFLOPs: 2714.3774
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #68: GFLOPs: 1788.0041. Time: 64.2914 us. Best GFLOPs: 2714.3774
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #69: GFLOPs: 1211.8534. Time: 94.8574 us. Best GFLOPs: 2714.3774
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #70: GFLOPs: 2294.0716. Time: 50.1088 us. Best GFLOPs: 2714.3774
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #71: GFLOPs: 2397.5685. Time: 47.9457 us. Best GFLOPs: 2714.3774
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #72: GFLOPs: 2763.1156. Time: 41.6028 us. Best GFLOPs: 2763.1156
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #73: GFLOPs: 1954.2424. Time: 58.8224 us. Best GFLOPs: 2763.1156
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #74: GFLOPs: 2905.0375. Time: 39.5703 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #75: GFLOPs: 1437.3576. Time: 79.9754 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #76: GFLOPs: 2534.9562. Time: 45.3472 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #77: GFLOPs: 2053.5405. Time: 55.9781 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #78: GFLOPs: 2052.8393. Time: 55.9972 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #79: GFLOPs: 1186.1007. Time: 96.9169 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #80: GFLOPs: 1946.8049. Time: 59.0471 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #81: GFLOPs: 2761.2370. Time: 41.6311 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #82: GFLOPs: 2032.7903. Time: 56.5495 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #83: GFLOPs: 2033.2258. Time: 56.5374 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #84: GFLOPs: 2276.7205. Time: 50.4907 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #85: GFLOPs: 2761.9179. Time: 41.6208 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #86: GFLOPs: 2734.5750. Time: 42.0370 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #87: GFLOPs: 2351.5695. Time: 48.8836 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #88: GFLOPs: 2716.8437. Time: 42.3113 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #89: GFLOPs: 2083.8581. Time: 55.1636 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #90: GFLOPs: 2719.0227. Time: 42.2774 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #91: GFLOPs: 1201.1833. Time: 95.7000 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #92: GFLOPs: 2018.6775. Time: 56.9448 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #93: GFLOPs: 2056.5483. Time: 55.8962 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #94: GFLOPs: 2438.3018. Time: 47.1448 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #95: GFLOPs: 2041.2857. Time: 56.3141 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #96: GFLOPs: 1090.7035. Time: 105.3936 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #97: GFLOPs: 2056.3075. Time: 55.9027 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #98: GFLOPs: 2027.2620. Time: 56.7037 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #99: GFLOPs: 2030.7265. Time: 56.6069 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #100: GFLOPs: 2031.4450. Time: 56.5869 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #101: GFLOPs: 1723.1912. Time: 66.7095 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #102: GFLOPs: 2658.3014. Time: 43.2431 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #103: GFLOPs: 1798.0449. Time: 63.9323 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #104: GFLOPs: 2820.4830. Time: 40.7566 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #105: GFLOPs: 2859.0053. Time: 40.2074 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #106: GFLOPs: 1711.2365. Time: 67.1755 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #107: GFLOPs: 2844.1308. Time: 40.4177 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #108: GFLOPs: 2845.8377. Time: 40.3935 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #109: GFLOPs: 1999.7767. Time: 57.4830 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #110: GFLOPs: 2029.2444. Time: 56.6483 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #111: GFLOPs: 2215.2712. Time: 51.8913 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #112: GFLOPs: 2175.2452. Time: 52.8461 us. Best GFLOPs: 2905.0375
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #113: GFLOPs: 2983.4348. Time: 38.5305 us. Best GFLOPs: 2983.4348
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #114: GFLOPs: 1786.2297. Time: 64.3552 us. Best GFLOPs: 2983.4348
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #115: GFLOPs: 2832.9187. Time: 40.5777 us. Best GFLOPs: 2983.4348
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #116: GFLOPs: 2265.7753. Time: 50.7346 us. Best GFLOPs: 2983.4348
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #117: GFLOPs: 2934.3274. Time: 39.1753 us. Best GFLOPs: 2983.4348
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #118: GFLOPs: 631.5987. Time: 182.0036 us. Best GFLOPs: 2983.4348
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #119: GFLOPs: 1028.9373. Time: 111.7203 us. Best GFLOPs: 2983.4348
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #120: GFLOPs: 2981.1538. Time: 38.5600 us. Best GFLOPs: 2983.4348
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #121: GFLOPs: 1962.4757. Time: 58.5756 us. Best GFLOPs: 2983.4348
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #122: GFLOPs: 2836.6223. Time: 40.5247 us. Best GFLOPs: 2983.4348
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #123: GFLOPs: 2817.0042. Time: 40.8069 us. Best GFLOPs: 2983.4348
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #124: GFLOPs: 2440.4926. Time: 47.1025 us. Best GFLOPs: 2983.4348
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #125: GFLOPs: 2354.6141. Time: 48.8204 us. Best GFLOPs: 2983.4348
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #126: GFLOPs: 15.7756. Time: 7286.7840 us. Best GFLOPs: 2983.4348
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #127: GFLOPs: 543.0804. Time: 211.6689 us. Best GFLOPs: 2983.4348
2023-11-11 00:47:46 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #128: GFLOPs: 212.0300. Time: 542.1554 us. Best GFLOPs: 2983.4348
2023-11-11 01:37:41 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 01:37:45 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 01:37:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 396 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 01:37:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 796 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 01:38:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1192 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 01:38:10 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1587 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 01:38:10 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2023-11-11 01:38:31 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 148 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 01:38:54 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 122 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 01:39:17 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 110 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 01:39:40 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 113 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 01:39:47 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.1391  1.1354  1.1334  1.1235  1.1208  1.0735  1.0698  0.9996  0.9890  0.9847  0.9840  0.9825  0.9821  0.9810  0.9809  0.9802
[17 : 32]:	0.9782  0.9775  0.9770  0.9749  0.9732  0.9726  0.9712  0.9711  0.9708  0.9707  0.9697  0.9697  0.9692  0.9684  0.9680  0.9679
[33 : 48]:	0.9669  0.9667  0.9665  0.9650  0.9650  0.9646  0.9641  0.9641  0.9640  0.9622  0.9606  0.9602  0.9579  0.9565  0.9565  0.9528
[49 : 64]:	0.9522  0.9518  0.9477  0.9452  0.9451  0.9443  0.9427  0.9391  0.9385  0.9375  0.9373  0.9373  0.9359  0.9352  0.9351  0.9347
2023-11-11 01:39:47 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 01:39:47 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #129: GFLOPs: 1275.8097. Time: 90.1022 us. Best GFLOPs: 2983.4348
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #130: GFLOPs: 1298.0141. Time: 88.5608 us. Best GFLOPs: 2983.4348
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #131: GFLOPs: 1271.9074. Time: 90.3786 us. Best GFLOPs: 2983.4348
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #132: GFLOPs: 1447.5558. Time: 79.4119 us. Best GFLOPs: 2983.4348
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #133: GFLOPs: 1298.3982. Time: 88.5346 us. Best GFLOPs: 2983.4348
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #134: GFLOPs: 1606.3598. Time: 71.5613 us. Best GFLOPs: 2983.4348
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #135: GFLOPs: 1794.4288. Time: 64.0612 us. Best GFLOPs: 2983.4348
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #136: GFLOPs: 3134.1824. Time: 36.6773 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #137: GFLOPs: 2894.8541. Time: 39.7095 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #138: GFLOPs: 2965.9866. Time: 38.7572 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #139: GFLOPs: 3080.5886. Time: 37.3153 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #140: GFLOPs: 3012.3535. Time: 38.1606 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #141: GFLOPs: 2964.1069. Time: 38.7817 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #142: GFLOPs: 3093.0548. Time: 37.1649 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #143: GFLOPs: 3093.4728. Time: 37.1599 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #144: GFLOPs: 3123.6159. Time: 36.8013 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #145: GFLOPs: 3058.0387. Time: 37.5905 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #146: GFLOPs: 2725.9409. Time: 42.1701 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #147: GFLOPs: 3124.2731. Time: 36.7936 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #148: GFLOPs: 3038.0555. Time: 37.8378 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #149: GFLOPs: 3067.0680. Time: 37.4798 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #150: GFLOPs: 2966.5114. Time: 38.7503 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #151: GFLOPs: 2965.2568. Time: 38.7667 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #152: GFLOPs: 3013.5369. Time: 38.1456 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #153: GFLOPs: 3092.2812. Time: 37.1742 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #154: GFLOPs: 2966.6855. Time: 38.7480 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #155: GFLOPs: 3008.7384. Time: 38.2065 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #156: GFLOPs: 3008.9461. Time: 38.2038 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #157: GFLOPs: 3005.5273. Time: 38.2473 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #158: GFLOPs: 2862.8177. Time: 40.1539 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #159: GFLOPs: 3090.1094. Time: 37.2004 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #160: GFLOPs: 1826.8355. Time: 62.9248 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #161: GFLOPs: 2880.8491. Time: 39.9025 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #162: GFLOPs: 3089.8706. Time: 37.2032 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #163: GFLOPs: 2854.7516. Time: 40.2673 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #164: GFLOPs: 2877.7014. Time: 39.9462 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #165: GFLOPs: 2878.0623. Time: 39.9412 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #166: GFLOPs: 2864.4512. Time: 40.1310 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #167: GFLOPs: 2861.4620. Time: 40.1729 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #168: GFLOPs: 2860.8553. Time: 40.1814 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #169: GFLOPs: 2785.7803. Time: 41.2643 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #170: GFLOPs: 2859.6801. Time: 40.1979 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #171: GFLOPs: 2877.8145. Time: 39.9446 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #172: GFLOPs: 2865.8985. Time: 40.1107 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #173: GFLOPs: 1897.5077. Time: 60.5812 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #174: GFLOPs: 2760.6597. Time: 41.6398 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #175: GFLOPs: 2785.3570. Time: 41.2705 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #176: GFLOPs: 2849.0555. Time: 40.3478 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #177: GFLOPs: 2850.6888. Time: 40.3247 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #178: GFLOPs: 2784.9848. Time: 41.2761 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #179: GFLOPs: 1909.9214. Time: 60.1874 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #180: GFLOPs: 2655.5718. Time: 43.2876 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #181: GFLOPs: 2873.7325. Time: 40.0014 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #182: GFLOPs: 2760.8581. Time: 41.6368 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #183: GFLOPs: 2784.9199. Time: 41.2770 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #184: GFLOPs: 2536.2123. Time: 45.3248 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #185: GFLOPs: 2717.4054. Time: 42.3026 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #186: GFLOPs: 2760.2087. Time: 41.6466 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #187: GFLOPs: 1605.5631. Time: 71.5968 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #188: GFLOPs: 3061.9211. Time: 37.5428 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #189: GFLOPs: 2898.1850. Time: 39.6639 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #190: GFLOPs: 209.9672. Time: 547.4819 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #191: GFLOPs: 391.9832. Time: 293.2606 us. Best GFLOPs: 3134.1824
2023-11-11 01:40:20 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #192: GFLOPs: 1405.1731. Time: 81.8072 us. Best GFLOPs: 3134.1824
2023-11-11 02:17:10 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 02:17:13 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 02:17:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 405 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:17:27 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 799 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:17:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1197 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:17:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1602 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:17:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1997 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:17:47 [INFO] [evolutionary_search.cc:723] Sampled 53 candidate(s)
2023-11-11 02:18:08 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 117 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:18:31 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 107 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:18:57 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 134 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:19:21 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 115 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:19:28 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.5960  1.5892  1.3851  1.3697  1.3089  1.3030  1.2047  1.2033  1.1700  1.1139  0.9997  0.9829  0.9817  0.9809  0.9798  0.9772
[17 : 32]:	0.9739  0.9733  0.9731  0.9730  0.9728  0.9725  0.9715  0.9707  0.9707  0.9706  0.9695  0.9692  0.9692  0.9682  0.9663  0.9662
[33 : 48]:	0.9647  0.9634  0.9622  0.9622  0.9617  0.9592  0.9590  0.9582  0.9582  0.9567  0.9560  0.9559  0.9547  0.9532  0.9532  0.9532
[49 : 64]:	0.9530  0.9524  0.9507  0.9505  0.9488  0.9488  0.9479  0.9475  0.9474  0.9472  0.9441  0.9432  0.9424  0.9416  0.9413  0.9409
2023-11-11 02:19:28 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 02:19:28 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #193: GFLOPs: 677.0454. Time: 169.7866 us. Best GFLOPs: 3134.1824
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #194: GFLOPs: 678.8137. Time: 169.3443 us. Best GFLOPs: 3134.1824
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #195: GFLOPs: 2506.2406. Time: 45.8668 us. Best GFLOPs: 3134.1824
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #196: GFLOPs: 2490.7049. Time: 46.1529 us. Best GFLOPs: 3134.1824
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #197: GFLOPs: 2375.5693. Time: 48.3898 us. Best GFLOPs: 3134.1824
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #198: GFLOPs: 2540.3446. Time: 45.2510 us. Best GFLOPs: 3134.1824
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #199: GFLOPs: 2511.8219. Time: 45.7649 us. Best GFLOPs: 3134.1824
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #200: GFLOPs: 2492.9874. Time: 46.1106 us. Best GFLOPs: 3134.1824
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #201: GFLOPs: 1507.0715. Time: 76.2759 us. Best GFLOPs: 3134.1824
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #202: GFLOPs: 2169.1853. Time: 52.9937 us. Best GFLOPs: 3134.1824
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #203: GFLOPs: 3281.9547. Time: 35.0258 us. Best GFLOPs: 3281.9547
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #204: GFLOPs: 3283.7880. Time: 35.0063 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #205: GFLOPs: 2949.2187. Time: 38.9775 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #206: GFLOPs: 3207.6551. Time: 35.8371 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #207: GFLOPs: 3208.5062. Time: 35.8276 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #208: GFLOPs: 3104.6169. Time: 37.0265 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #209: GFLOPs: 3124.6019. Time: 36.7897 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #210: GFLOPs: 3038.8489. Time: 37.8279 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #211: GFLOPs: 3208.0265. Time: 35.8330 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #212: GFLOPs: 3088.9342. Time: 37.2145 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #213: GFLOPs: 3209.9516. Time: 35.8115 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #214: GFLOPs: 3208.9317. Time: 35.8229 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #215: GFLOPs: 3045.4889. Time: 37.7454 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #216: GFLOPs: 3045.1115. Time: 37.7501 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #217: GFLOPs: 3044.3469. Time: 37.7596 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #218: GFLOPs: 3209.9110. Time: 35.8120 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #219: GFLOPs: 2740.7602. Time: 41.9421 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #220: GFLOPs: 3040.2322. Time: 37.8107 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #221: GFLOPs: 3040.6062. Time: 37.8060 us. Best GFLOPs: 3283.7880
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #222: GFLOPs: 3287.2253. Time: 34.9697 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #223: GFLOPs: 3091.8135. Time: 37.1799 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #224: GFLOPs: 3092.1790. Time: 37.1755 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #225: GFLOPs: 3092.8695. Time: 37.1672 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #226: GFLOPs: 3182.6855. Time: 36.1183 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #227: GFLOPs: 3104.7160. Time: 37.0254 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #228: GFLOPs: 3105.0784. Time: 37.0210 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #229: GFLOPs: 3104.6959. Time: 37.0256 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #230: GFLOPs: 2973.3512. Time: 38.6612 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #231: GFLOPs: 3179.6206. Time: 36.1531 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #232: GFLOPs: 3002.3341. Time: 38.2879 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #233: GFLOPs: 3002.5165. Time: 38.2856 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #234: GFLOPs: 3041.9653. Time: 37.7891 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #235: GFLOPs: 3209.6352. Time: 35.8150 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #236: GFLOPs: 3153.7494. Time: 36.4497 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #237: GFLOPs: 3018.5892. Time: 38.0818 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #238: GFLOPs: 2961.2262. Time: 38.8195 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #239: GFLOPs: 2961.6262. Time: 38.8142 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #240: GFLOPs: 2962.3925. Time: 38.8042 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #241: GFLOPs: 2955.3652. Time: 38.8964 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #242: GFLOPs: 2961.2262. Time: 38.8195 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #243: GFLOPs: 3006.9440. Time: 38.2293 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #244: GFLOPs: 3238.6127. Time: 35.4946 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #245: GFLOPs: 3020.1862. Time: 38.0616 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #246: GFLOPs: 3019.9331. Time: 38.0648 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #247: GFLOPs: 3019.6693. Time: 38.0681 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #248: GFLOPs: 3106.3958. Time: 37.0053 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #249: GFLOPs: 3041.0858. Time: 37.8001 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #250: GFLOPs: 2951.5740. Time: 38.9464 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #251: GFLOPs: 2983.5324. Time: 38.5292 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #252: GFLOPs: 2979.2759. Time: 38.5843 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #253: GFLOPs: 3060.4447. Time: 37.5610 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #254: GFLOPs: 912.3246. Time: 126.0003 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #255: GFLOPs: 513.8822. Time: 223.6956 us. Best GFLOPs: 3287.2253
2023-11-11 02:20:01 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #256: GFLOPs: 1215.6090. Time: 94.5643 us. Best GFLOPs: 3287.2253
2023-11-11 02:29:36 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 02:29:39 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 02:29:46 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 394 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:29:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 795 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:30:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1187 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:30:07 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1588 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:30:07 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2023-11-11 02:30:26 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 94 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:30:50 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 109 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:31:14 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 108 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:31:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 125 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 02:31:45 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.4979  1.0875  0.9991  0.9956  0.9940  0.9915  0.9895  0.9881  0.9857  0.9785  0.9772  0.9770  0.9769  0.9769  0.9759  0.9747
[17 : 32]:	0.9731  0.9723  0.9712  0.9712  0.9711  0.9686  0.9675  0.9674  0.9674  0.9669  0.9662  0.9638  0.9636  0.9625  0.9625  0.9616
[33 : 48]:	0.9615  0.9613  0.9577  0.9577  0.9577  0.9569  0.9563  0.9563  0.9558  0.9547  0.9543  0.9542  0.9536  0.9517  0.9516  0.9516
[49 : 64]:	0.9512  0.9504  0.9502  0.9480  0.9479  0.9479  0.9475  0.9455  0.9447  0.9444  0.9413  0.9412  0.9409  0.9395  0.9361  0.9360
2023-11-11 02:31:45 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 02:31:45 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #257: GFLOPs: 101.5877. Time: 1131.5660 us. Best GFLOPs: 3287.2253
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #258: GFLOPs: 39.9299. Time: 2878.8735 us. Best GFLOPs: 3287.2253
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #259: GFLOPs: 3103.7898. Time: 37.0364 us. Best GFLOPs: 3287.2253
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #260: GFLOPs: 3121.8095. Time: 36.8226 us. Best GFLOPs: 3287.2253
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #261: GFLOPs: 3086.5045. Time: 37.2438 us. Best GFLOPs: 3287.2253
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #262: GFLOPs: 3127.6422. Time: 36.7540 us. Best GFLOPs: 3287.2253
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #263: GFLOPs: 3105.8221. Time: 37.0122 us. Best GFLOPs: 3287.2253
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #264: GFLOPs: 3120.1650. Time: 36.8420 us. Best GFLOPs: 3287.2253
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #265: GFLOPs: 3104.4290. Time: 37.0288 us. Best GFLOPs: 3287.2253
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #266: GFLOPs: 2985.8925. Time: 38.4988 us. Best GFLOPs: 3287.2253
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #267: GFLOPs: 2937.1745. Time: 39.1373 us. Best GFLOPs: 3287.2253
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #268: GFLOPs: 3128.3315. Time: 36.7459 us. Best GFLOPs: 3287.2253
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #269: GFLOPs: 3340.8541. Time: 34.4083 us. Best GFLOPs: 3340.8541
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #270: GFLOPs: 3388.0730. Time: 33.9288 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #271: GFLOPs: 3105.9831. Time: 37.0103 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #272: GFLOPs: 2986.4902. Time: 38.4911 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #273: GFLOPs: 3272.6915. Time: 35.1250 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #274: GFLOPs: 3004.3646. Time: 38.2621 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #275: GFLOPs: 3324.1910. Time: 34.5808 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #276: GFLOPs: 3337.6731. Time: 34.4411 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #277: GFLOPs: 2984.9358. Time: 38.5111 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #278: GFLOPs: 3134.4308. Time: 36.6744 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #279: GFLOPs: 2937.5923. Time: 39.1318 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #280: GFLOPs: 3375.4553. Time: 34.0556 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #281: GFLOPs: 3315.6232. Time: 34.6702 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #282: GFLOPs: 3315.9766. Time: 34.6665 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #283: GFLOPs: 3106.3731. Time: 37.0056 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #284: GFLOPs: 3036.1570. Time: 37.8614 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #285: GFLOPs: 3131.0534. Time: 36.7139 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #286: GFLOPs: 3112.0205. Time: 36.9385 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #287: GFLOPs: 3107.8755. Time: 36.9877 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #288: GFLOPs: 3222.3315. Time: 35.6739 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #289: GFLOPs: 3142.0434. Time: 36.5855 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #290: GFLOPs: 3120.8252. Time: 36.8342 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #291: GFLOPs: 2985.9665. Time: 38.4978 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #292: GFLOPs: 3077.3274. Time: 37.3549 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #293: GFLOPs: 3095.5287. Time: 37.1352 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #294: GFLOPs: 3089.4811. Time: 37.2079 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #295: GFLOPs: 3066.5168. Time: 37.4866 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #296: GFLOPs: 3067.3026. Time: 37.4770 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #297: GFLOPs: 3096.0912. Time: 37.1285 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #298: GFLOPs: 3077.8806. Time: 37.3482 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #299: GFLOPs: 3096.2508. Time: 37.1266 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #300: GFLOPs: 3037.5125. Time: 37.8445 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #301: GFLOPs: 2964.8684. Time: 38.7718 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #302: GFLOPs: 3121.0543. Time: 36.8315 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #303: GFLOPs: 3336.4231. Time: 34.4540 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #304: GFLOPs: 3223.1117. Time: 35.6653 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #305: GFLOPs: 3338.5877. Time: 34.4317 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #306: GFLOPs: 3037.2251. Time: 37.8481 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #307: GFLOPs: 3117.2323. Time: 36.8767 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #308: GFLOPs: 3287.6164. Time: 34.9655 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #309: GFLOPs: 3121.8505. Time: 36.8221 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #310: GFLOPs: 3095.1657. Time: 37.1396 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #311: GFLOPs: 3320.5107. Time: 34.6191 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #312: GFLOPs: 2990.1294. Time: 38.4442 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #313: GFLOPs: 3062.7209. Time: 37.5330 us. Best GFLOPs: 3388.0730
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #314: GFLOPs: 3467.7880. Time: 33.1489 us. Best GFLOPs: 3467.7880
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #315: GFLOPs: 2999.4919. Time: 38.3242 us. Best GFLOPs: 3467.7880
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #316: GFLOPs: 3337.7193. Time: 34.4406 us. Best GFLOPs: 3467.7880
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #317: GFLOPs: 3311.7983. Time: 34.7102 us. Best GFLOPs: 3467.7880
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #318: GFLOPs: 561.8884. Time: 204.5837 us. Best GFLOPs: 3467.7880
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #319: GFLOPs: 823.3718. Time: 139.6128 us. Best GFLOPs: 3467.7880
2023-11-11 02:32:22 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #320: GFLOPs: 123.1823. Time: 933.1958 us. Best GFLOPs: 3467.7880
2023-11-11 03:37:01 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 03:37:04 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 03:37:10 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 398 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 03:37:17 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 797 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 03:37:23 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1190 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 03:37:29 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1590 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 03:37:29 [INFO] [evolutionary_search.cc:723] Sampled 50 candidate(s)
2023-11-11 03:37:48 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 96 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 03:38:10 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 94 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 03:38:34 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 94 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 03:38:58 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 105 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 03:39:04 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.3566  1.3552  1.2021  1.1971  1.1096  1.0791  0.9693  0.9641  0.9638  0.9610  0.9606  0.9606  0.9597  0.9591  0.9591  0.9587
[17 : 32]:	0.9580  0.9580  0.9541  0.9540  0.9522  0.9522  0.9522  0.9521  0.9515  0.9511  0.9508  0.9508  0.9508  0.9507  0.9507  0.9504
[33 : 48]:	0.9502  0.9490  0.9490  0.9490  0.9480  0.9480  0.9480  0.9471  0.9465  0.9464  0.9458  0.9452  0.9440  0.9440  0.9436  0.9434
[49 : 64]:	0.9423  0.9420  0.9420  0.9404  0.9401  0.9390  0.9340  0.9328  0.9313  0.9305  0.9301  0.9283  0.9283  0.9277  0.9247  0.9240
2023-11-11 03:39:05 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 03:39:05 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #321: GFLOPs: 1203.5270. Time: 95.5136 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #322: GFLOPs: 1208.1635. Time: 95.1471 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #323: GFLOPs: 1209.3050. Time: 95.0573 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #324: GFLOPs: 1205.8275. Time: 95.3314 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #325: GFLOPs: 984.0980. Time: 116.8107 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #326: GFLOPs: 1167.2523. Time: 98.4819 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #327: GFLOPs: 3388.5329. Time: 33.9242 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #328: GFLOPs: 3388.9149. Time: 33.9204 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #329: GFLOPs: 3387.9163. Time: 33.9304 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #330: GFLOPs: 3464.6062. Time: 33.1793 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #331: GFLOPs: 3463.9143. Time: 33.1859 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #332: GFLOPs: 3389.2994. Time: 33.9165 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #333: GFLOPs: 3360.9509. Time: 34.2026 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #334: GFLOPs: 3378.6568. Time: 34.0233 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #335: GFLOPs: 3454.6100. Time: 33.2753 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #336: GFLOPs: 3393.3613. Time: 33.8759 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #337: GFLOPs: 3422.1805. Time: 33.5906 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #338: GFLOPs: 3369.5612. Time: 34.1152 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #339: GFLOPs: 3450.2173. Time: 33.3177 us. Best GFLOPs: 3467.7880
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #340: GFLOPs: 3539.8545. Time: 32.4740 us. Best GFLOPs: 3539.8545
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #341: GFLOPs: 3424.5387. Time: 33.5675 us. Best GFLOPs: 3539.8545
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #342: GFLOPs: 3279.5604. Time: 35.0514 us. Best GFLOPs: 3539.8545
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #343: GFLOPs: 3316.3176. Time: 34.6629 us. Best GFLOPs: 3539.8545
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #344: GFLOPs: 3451.2443. Time: 33.3078 us. Best GFLOPs: 3539.8545
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #345: GFLOPs: 3432.8167. Time: 33.4866 us. Best GFLOPs: 3539.8545
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #346: GFLOPs: 3450.7407. Time: 33.3126 us. Best GFLOPs: 3539.8545
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #347: GFLOPs: 3425.5504. Time: 33.5576 us. Best GFLOPs: 3539.8545
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #348: GFLOPs: 3279.0773. Time: 35.0566 us. Best GFLOPs: 3539.8545
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #349: GFLOPs: 3316.4476. Time: 34.6616 us. Best GFLOPs: 3539.8545
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #350: GFLOPs: 3278.9929. Time: 35.0575 us. Best GFLOPs: 3539.8545
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #351: GFLOPs: 3425.6481. Time: 33.5566 us. Best GFLOPs: 3539.8545
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #352: GFLOPs: 3330.8956. Time: 34.5112 us. Best GFLOPs: 3539.8545
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #353: GFLOPs: 3637.7265. Time: 31.6003 us. Best GFLOPs: 3637.7265
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #354: GFLOPs: 3281.3920. Time: 35.0318 us. Best GFLOPs: 3637.7265
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #355: GFLOPs: 3426.0343. Time: 33.5529 us. Best GFLOPs: 3637.7265
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #356: GFLOPs: 3426.2925. Time: 33.5503 us. Best GFLOPs: 3637.7265
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #357: GFLOPs: 3451.1249. Time: 33.3089 us. Best GFLOPs: 3637.7265
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #358: GFLOPs: 3352.5109. Time: 34.2887 us. Best GFLOPs: 3637.7265
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #359: GFLOPs: 3352.2990. Time: 34.2909 us. Best GFLOPs: 3637.7265
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #360: GFLOPs: 3426.6751. Time: 33.5466 us. Best GFLOPs: 3637.7265
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #361: GFLOPs: 3332.9277. Time: 34.4902 us. Best GFLOPs: 3637.7265
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #362: GFLOPs: 3254.5168. Time: 35.3211 us. Best GFLOPs: 3637.7265
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #363: GFLOPs: 3578.7042. Time: 32.1215 us. Best GFLOPs: 3637.7265
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #364: GFLOPs: 3279.9421. Time: 35.0473 us. Best GFLOPs: 3637.7265
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #365: GFLOPs: 3425.6852. Time: 33.5563 us. Best GFLOPs: 3637.7265
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #366: GFLOPs: 3280.3979. Time: 35.0425 us. Best GFLOPs: 3637.7265
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #367: GFLOPs: 3431.0822. Time: 33.5035 us. Best GFLOPs: 3637.7265
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #368: GFLOPs: 3663.2054. Time: 31.3805 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #369: GFLOPs: 3662.2400. Time: 31.3888 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #370: GFLOPs: 3426.1093. Time: 33.5521 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #371: GFLOPs: 3318.7384. Time: 34.6376 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #372: GFLOPs: 3381.8616. Time: 33.9911 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #373: GFLOPs: 3349.7318. Time: 34.3171 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #374: GFLOPs: 3364.4880. Time: 34.1666 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #375: GFLOPs: 3375.5116. Time: 34.0550 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #376: GFLOPs: 3327.3831. Time: 34.5476 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #377: GFLOPs: 3502.1830. Time: 32.8233 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #378: GFLOPs: 3507.4138. Time: 32.7744 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #379: GFLOPs: 3378.9216. Time: 34.0207 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #380: GFLOPs: 3276.5070. Time: 35.0841 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #381: GFLOPs: 3427.6432. Time: 33.5371 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #382: GFLOPs: 247.3356. Time: 464.7661 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #383: GFLOPs: 545.8739. Time: 210.5857 us. Best GFLOPs: 3663.2054
2023-11-11 03:39:37 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #384: GFLOPs: 405.2233. Time: 283.6787 us. Best GFLOPs: 3663.2054
2023-11-11 04:10:06 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 04:10:09 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 04:10:16 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 401 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:10:22 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 803 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:10:28 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1195 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:10:34 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1596 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:10:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 2002 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:10:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 2404 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:10:47 [INFO] [evolutionary_search.cc:723] Sampled 56 candidate(s)
2023-11-11 04:11:05 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 71 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:11:27 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 84 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:11:50 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 91 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:12:12 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 86 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:12:18 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9800  0.9782  0.9700  0.9700  0.9668  0.9642  0.9628  0.9620  0.9589  0.9587  0.9587  0.9540  0.9539  0.9507  0.9507  0.9492
[17 : 32]:	0.9473  0.9449  0.9449  0.9409  0.9397  0.9396  0.9372  0.9362  0.9362  0.9356  0.9349  0.9333  0.9330  0.9329  0.9327  0.9326
[33 : 48]:	0.9323  0.9318  0.9318  0.9316  0.9315  0.9315  0.9308  0.9293  0.9293  0.9293  0.9291  0.9290  0.9280  0.9276  0.9270  0.9268
[49 : 64]:	0.9259  0.9254  0.9254  0.9254  0.9251  0.9250  0.9243  0.9241  0.9241  0.9241  0.9241  0.9231  0.9226  0.9226  0.9226  0.9221
2023-11-11 04:12:19 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 04:12:19 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #385: GFLOPs: 3641.9567. Time: 31.5636 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #386: GFLOPs: 3642.4885. Time: 31.5590 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #387: GFLOPs: 3603.2489. Time: 31.9027 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #388: GFLOPs: 3603.4903. Time: 31.9005 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #389: GFLOPs: 3642.3635. Time: 31.5601 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #390: GFLOPs: 3374.0004. Time: 34.0703 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #391: GFLOPs: 3508.4242. Time: 32.7649 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #392: GFLOPs: 3503.2475. Time: 32.8133 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #393: GFLOPs: 3474.3534. Time: 33.0862 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #394: GFLOPs: 3560.7789. Time: 32.2832 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #395: GFLOPs: 3491.6556. Time: 32.9223 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #396: GFLOPs: 3519.6693. Time: 32.6602 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #397: GFLOPs: 3318.7194. Time: 34.6378 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #398: GFLOPs: 3430.7654. Time: 33.5066 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #399: GFLOPs: 3390.7384. Time: 33.9021 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #400: GFLOPs: 3434.3436. Time: 33.4717 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #401: GFLOPs: 3519.7549. Time: 32.6594 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #402: GFLOPs: 3368.5827. Time: 34.1251 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #403: GFLOPs: 3419.7679. Time: 33.6143 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #404: GFLOPs: 3439.5053. Time: 33.4214 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #405: GFLOPs: 3560.6739. Time: 32.2841 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #406: GFLOPs: 3286.7765. Time: 34.9745 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #407: GFLOPs: 3370.2333. Time: 34.1084 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #408: GFLOPs: 3413.4714. Time: 33.6763 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #409: GFLOPs: 3413.5636. Time: 33.6754 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #410: GFLOPs: 3394.2640. Time: 33.8669 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #411: GFLOPs: 3272.8288. Time: 35.1235 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #412: GFLOPs: 3407.8812. Time: 33.7316 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #413: GFLOPs: 3380.7324. Time: 34.0025 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #414: GFLOPs: 3387.8038. Time: 33.9315 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #415: GFLOPs: 3413.4273. Time: 33.6768 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #416: GFLOPs: 3412.4485. Time: 33.6864 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #417: GFLOPs: 3502.4259. Time: 32.8210 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #418: GFLOPs: 3413.2481. Time: 33.6785 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #419: GFLOPs: 3412.5041. Time: 33.6859 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #420: GFLOPs: 3413.5182. Time: 33.6759 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #421: GFLOPs: 3382.6316. Time: 33.9834 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #422: GFLOPs: 3410.0718. Time: 33.7099 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #423: GFLOPs: 3423.7642. Time: 33.5751 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #424: GFLOPs: 3384.4660. Time: 33.9649 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #425: GFLOPs: 3422.9251. Time: 33.5833 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #426: GFLOPs: 3422.2477. Time: 33.5900 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #427: GFLOPs: 3375.3730. Time: 34.0564 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #428: GFLOPs: 3340.4616. Time: 34.4124 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #429: GFLOPs: 3271.8247. Time: 35.1343 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #430: GFLOPs: 3409.3969. Time: 33.7166 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #431: GFLOPs: 3412.5394. Time: 33.6855 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #432: GFLOPs: 3381.2049. Time: 33.9977 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #433: GFLOPs: 3412.3999. Time: 33.6869 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #434: GFLOPs: 3355.5295. Time: 34.2578 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #435: GFLOPs: 3367.3824. Time: 34.1373 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #436: GFLOPs: 3381.8341. Time: 33.9914 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #437: GFLOPs: 3355.1134. Time: 34.2621 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #438: GFLOPs: 3437.3670. Time: 33.4422 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #439: GFLOPs: 3385.2942. Time: 33.9566 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #440: GFLOPs: 3431.0918. Time: 33.5034 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #441: GFLOPs: 3371.0627. Time: 34.1000 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #442: GFLOPs: 3370.5129. Time: 34.1056 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #443: GFLOPs: 3370.1134. Time: 34.1096 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #444: GFLOPs: 3357.5967. Time: 34.2368 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #445: GFLOPs: 3302.6259. Time: 34.8066 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #446: GFLOPs: 879.6930. Time: 130.6742 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #447: GFLOPs: 842.4179. Time: 136.4563 us. Best GFLOPs: 3663.2054
2023-11-11 04:12:51 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #448: GFLOPs: 545.8739. Time: 210.5857 us. Best GFLOPs: 3663.2054
2023-11-11 04:46:08 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 04:46:11 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 04:46:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 392 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:46:24 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 795 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:46:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1186 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:46:37 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1586 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:46:37 [INFO] [evolutionary_search.cc:723] Sampled 54 candidate(s)
2023-11-11 04:46:56 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 77 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:47:18 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 83 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:47:41 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 73 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:48:04 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 86 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 04:48:10 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.1971  1.1472  1.0898  0.9805  0.9791  0.9791  0.9781  0.9781  0.9753  0.9752  0.9750  0.9718  0.9700  0.9699  0.9692  0.9668
[17 : 32]:	0.9665  0.9643  0.9633  0.9614  0.9601  0.9600  0.9597  0.9584  0.9570  0.9566  0.9545  0.9541  0.9539  0.9516  0.9511  0.9506
[33 : 48]:	0.9493  0.9492  0.9487  0.9462  0.9462  0.9452  0.9438  0.9412  0.9409  0.9409  0.9409  0.9403  0.9396  0.9395  0.9395  0.9393
[49 : 64]:	0.9393  0.9389  0.9382  0.9379  0.9374  0.9367  0.9367  0.9364  0.9353  0.9347  0.9345  0.9343  0.9340  0.9340  0.9337  0.9328
2023-11-11 04:48:11 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 04:48:11 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #449: GFLOPs: 1466.5113. Time: 78.3855 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #450: GFLOPs: 1452.8825. Time: 79.1208 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #451: GFLOPs: 1475.9989. Time: 77.8816 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #452: GFLOPs: 3557.2576. Time: 32.3151 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #453: GFLOPs: 3646.8444. Time: 31.5213 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #454: GFLOPs: 3647.7257. Time: 31.5137 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #455: GFLOPs: 3521.9561. Time: 32.6390 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #456: GFLOPs: 3557.6781. Time: 32.3113 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #457: GFLOPs: 3557.9406. Time: 32.3089 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #458: GFLOPs: 3558.4551. Time: 32.3042 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #459: GFLOPs: 3596.7912. Time: 31.9599 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #460: GFLOPs: 3522.3055. Time: 32.6358 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #461: GFLOPs: 3521.9092. Time: 32.6395 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #462: GFLOPs: 3472.5188. Time: 33.1037 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #463: GFLOPs: 3557.9284. Time: 32.3090 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #464: GFLOPs: 3621.4253. Time: 31.7425 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #465: GFLOPs: 3507.9335. Time: 32.7695 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #466: GFLOPs: 3625.6829. Time: 31.7053 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #467: GFLOPs: 3556.4280. Time: 32.3227 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #468: GFLOPs: 3625.0052. Time: 31.7112 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #469: GFLOPs: 3280.5262. Time: 35.0411 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #470: GFLOPs: 3624.7034. Time: 31.7138 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #471: GFLOPs: 3483.2296. Time: 33.0019 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #472: GFLOPs: 3517.7184. Time: 32.6783 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #473: GFLOPs: 3535.3386. Time: 32.5155 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #474: GFLOPs: 3512.0994. Time: 32.7306 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #475: GFLOPs: 3482.6309. Time: 33.0076 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #476: GFLOPs: 3517.5565. Time: 32.6798 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #477: GFLOPs: 3280.0288. Time: 35.0464 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #478: GFLOPs: 3553.7070. Time: 32.3474 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #479: GFLOPs: 3449.4648. Time: 33.3249 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #480: GFLOPs: 3548.9682. Time: 32.3906 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #481: GFLOPs: 3483.7251. Time: 32.9972 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #482: GFLOPs: 3637.5131. Time: 31.6021 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #483: GFLOPs: 3362.9827. Time: 34.1819 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #484: GFLOPs: 3555.6451. Time: 32.3298 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #485: GFLOPs: 3514.8996. Time: 32.7046 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #486: GFLOPs: 3551.0781. Time: 32.3714 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #487: GFLOPs: 3315.9920. Time: 34.6663 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #488: GFLOPs: 3401.9445. Time: 33.7904 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #489: GFLOPs: 3400.4997. Time: 33.8048 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #490: GFLOPs: 3401.2058. Time: 33.7978 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #491: GFLOPs: 3401.0937. Time: 33.7989 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #492: GFLOPs: 3476.6094. Time: 33.0647 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #493: GFLOPs: 3441.6377. Time: 33.4007 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #494: GFLOPs: 3474.9811. Time: 33.0802 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #495: GFLOPs: 3215.7316. Time: 35.7471 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #496: GFLOPs: 3451.8608. Time: 33.3018 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #497: GFLOPs: 3486.4797. Time: 32.9711 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #498: GFLOPs: 3215.6687. Time: 35.7478 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #499: GFLOPs: 3339.8660. Time: 34.4185 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #500: GFLOPs: 3485.8759. Time: 32.9769 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #501: GFLOPs: 3492.8725. Time: 32.9108 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #502: GFLOPs: 3334.4332. Time: 34.4746 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #503: GFLOPs: 3366.9423. Time: 34.1417 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #504: GFLOPs: 3495.9188. Time: 32.8821 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #505: GFLOPs: 3478.4688. Time: 33.0471 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #506: GFLOPs: 3362.7651. Time: 34.1841 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #507: GFLOPs: 3430.3473. Time: 33.5107 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #508: GFLOPs: 3478.7672. Time: 33.0442 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #509: GFLOPs: 3474.6833. Time: 33.0831 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #510: GFLOPs: 37.2152. Time: 3088.8806 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #511: GFLOPs: 75.2804. Time: 1527.0012 us. Best GFLOPs: 3663.2054
2023-11-11 04:49:08 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #512: GFLOPs: 370.7671. Time: 310.0416 us. Best GFLOPs: 3663.2054
2023-11-11 05:23:08 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 05:23:12 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 05:23:18 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 394 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 05:23:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 793 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 05:23:32 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1190 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 05:23:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1584 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 05:23:38 [INFO] [evolutionary_search.cc:723] Sampled 56 candidate(s)
2023-11-11 05:23:58 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 97 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 05:24:21 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 103 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 05:24:44 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 110 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 05:25:08 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 133 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 05:25:14 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	1.4615  1.1975  1.1804  1.0928  1.0859  1.0847  1.0063  0.9876  0.9784  0.9777  0.9724  0.9718  0.9718  0.9698  0.9688  0.9668
[17 : 32]:	0.9667  0.9625  0.9625  0.9614  0.9614  0.9610  0.9597  0.9584  0.9584  0.9582  0.9582  0.9574  0.9570  0.9570  0.9559  0.9555
[33 : 48]:	0.9555  0.9552  0.9548  0.9545  0.9544  0.9543  0.9537  0.9516  0.9511  0.9509  0.9506  0.9504  0.9488  0.9485  0.9484  0.9481
[49 : 64]:	0.9467  0.9458  0.9456  0.9452  0.9450  0.9449  0.9447  0.9437  0.9434  0.9434  0.9434  0.9434  0.9428  0.9426  0.9426  0.9422
2023-11-11 05:25:15 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 05:25:15 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #513: GFLOPs: 1512.5697. Time: 75.9986 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #514: GFLOPs: 1702.9284. Time: 67.5033 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #515: GFLOPs: 1403.1196. Time: 81.9269 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #516: GFLOPs: 1419.1844. Time: 80.9995 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #517: GFLOPs: 1432.7093. Time: 80.2348 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #518: GFLOPs: 1431.7202. Time: 80.2903 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #519: GFLOPs: 1166.4284. Time: 98.5515 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #520: GFLOPs: 1499.5468. Time: 76.6586 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #521: GFLOPs: 3607.9042. Time: 31.8615 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #522: GFLOPs: 3633.4418. Time: 31.6376 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #523: GFLOPs: 3606.7119. Time: 31.8720 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #524: GFLOPs: 3563.9209. Time: 32.2547 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #525: GFLOPs: 3519.6012. Time: 32.6609 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #526: GFLOPs: 3607.4006. Time: 31.8659 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #527: GFLOPs: 3520.1385. Time: 32.6559 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #528: GFLOPs: 3609.4178. Time: 31.8481 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #529: GFLOPs: 3580.5686. Time: 32.1047 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #530: GFLOPs: 3614.1517. Time: 31.8064 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #531: GFLOPs: 3572.3385. Time: 32.1787 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #532: GFLOPs: 3585.1548. Time: 32.0637 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #533: GFLOPs: 3608.8393. Time: 31.8532 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #534: GFLOPs: 3524.7230. Time: 32.6134 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #535: GFLOPs: 3285.0558. Time: 34.9928 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #536: GFLOPs: 3543.1857. Time: 32.4435 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #537: GFLOPs: 3558.2314. Time: 32.3063 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #538: GFLOPs: 3543.5810. Time: 32.4398 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #539: GFLOPs: 3558.1995. Time: 32.3066 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #540: GFLOPs: 3493.6062. Time: 32.9039 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #541: GFLOPs: 3558.3481. Time: 32.3052 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #542: GFLOPs: 3557.0222. Time: 32.3173 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #543: GFLOPs: 3486.2130. Time: 32.9737 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #544: GFLOPs: 3524.8384. Time: 32.6123 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #545: GFLOPs: 3525.2770. Time: 32.6083 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #546: GFLOPs: 3541.5289. Time: 32.4586 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #547: GFLOPs: 3322.6923. Time: 34.5964 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #548: GFLOPs: 3457.1668. Time: 33.2507 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #549: GFLOPs: 3542.4439. Time: 32.4503 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #550: GFLOPs: 3284.7122. Time: 34.9964 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #551: GFLOPs: 3494.6309. Time: 32.8942 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #552: GFLOPs: 3525.3808. Time: 32.6073 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #553: GFLOPs: 3494.5467. Time: 32.8950 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #554: GFLOPs: 3549.0406. Time: 32.3899 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #555: GFLOPs: 3549.1591. Time: 32.3889 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #556: GFLOPs: 3524.4224. Time: 32.6162 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #557: GFLOPs: 3498.6138. Time: 32.8568 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #558: GFLOPs: 3456.8151. Time: 33.2541 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #559: GFLOPs: 3498.7979. Time: 32.8551 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #560: GFLOPs: 3548.9934. Time: 32.3904 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #561: GFLOPs: 3320.4946. Time: 34.6193 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #562: GFLOPs: 3468.8043. Time: 33.1391 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #563: GFLOPs: 3323.0358. Time: 34.5928 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #564: GFLOPs: 3548.2795. Time: 32.3969 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #565: GFLOPs: 3487.4723. Time: 32.9618 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #566: GFLOPs: 3417.1153. Time: 33.6404 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #567: GFLOPs: 3487.3336. Time: 32.9631 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #568: GFLOPs: 3402.3305. Time: 33.7866 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #569: GFLOPs: 3498.9836. Time: 32.8533 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #570: GFLOPs: 3498.6138. Time: 32.8568 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #571: GFLOPs: 3498.8488. Time: 32.8546 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #572: GFLOPs: 3480.3990. Time: 33.0287 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #573: GFLOPs: 3479.7095. Time: 33.0353 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #574: GFLOPs: 24.3531. Time: 4720.2675 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #575: GFLOPs: 94.8983. Time: 1211.3303 us. Best GFLOPs: 3663.2054
2023-11-11 05:25:47 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #576: GFLOPs: 1902.7195. Time: 60.4152 us. Best GFLOPs: 3663.2054
2023-11-11 06:08:37 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 06:08:41 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 06:08:48 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 393 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:08:54 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 790 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:09:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1189 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:09:07 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1586 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:09:07 [INFO] [evolutionary_search.cc:723] Sampled 54 candidate(s)
2023-11-11 06:09:26 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 106 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:09:50 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 127 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:10:14 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 145 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:10:38 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 146 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:10:45 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9850  0.9822  0.9809  0.9809  0.9809  0.9802  0.9801  0.9787  0.9787  0.9784  0.9772  0.9761  0.9734  0.9729  0.9725  0.9722
[17 : 32]:	0.9706  0.9696  0.9685  0.9682  0.9679  0.9676  0.9675  0.9672  0.9672  0.9672  0.9661  0.9661  0.9659  0.9649  0.9649  0.9641
[33 : 48]:	0.9641  0.9641  0.9636  0.9636  0.9631  0.9620  0.9617  0.9617  0.9611  0.9610  0.9598  0.9598  0.9595  0.9591  0.9591  0.9587
[49 : 64]:	0.9583  0.9583  0.9583  0.9581  0.9580  0.9577  0.9573  0.9571  0.9571  0.9562  0.9561  0.9561  0.9551  0.9548  0.9548  0.9548
2023-11-11 06:10:45 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 06:10:45 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #577: GFLOPs: 133.1048. Time: 863.6292 us. Best GFLOPs: 3663.2054
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #578: GFLOPs: 3623.1713. Time: 31.7272 us. Best GFLOPs: 3663.2054
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #579: GFLOPs: 3622.9321. Time: 31.7293 us. Best GFLOPs: 3663.2054
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #580: GFLOPs: 3623.4584. Time: 31.7247 us. Best GFLOPs: 3663.2054
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #581: GFLOPs: 3623.8384. Time: 31.7214 us. Best GFLOPs: 3663.2054
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #582: GFLOPs: 3622.9798. Time: 31.7289 us. Best GFLOPs: 3663.2054
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #583: GFLOPs: 3669.3255. Time: 31.3282 us. Best GFLOPs: 3669.3255
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #584: GFLOPs: 3621.7787. Time: 31.7394 us. Best GFLOPs: 3669.3255
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #585: GFLOPs: 3672.6734. Time: 31.2996 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #586: GFLOPs: 3645.0778. Time: 31.5366 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #587: GFLOPs: 3623.3867. Time: 31.7254 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #588: GFLOPs: 3639.9002. Time: 31.5814 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #589: GFLOPs: 3591.2238. Time: 32.0095 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #590: GFLOPs: 3587.9591. Time: 32.0386 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #591: GFLOPs: 3623.0460. Time: 31.7283 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #592: GFLOPs: 3614.0297. Time: 31.8075 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #593: GFLOPs: 3578.7828. Time: 32.1208 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #594: GFLOPs: 3536.8262. Time: 32.5018 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #595: GFLOPs: 3627.1956. Time: 31.6920 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #596: GFLOPs: 3535.8720. Time: 32.5106 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #597: GFLOPs: 3596.9819. Time: 31.9582 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #598: GFLOPs: 92.0735. Time: 1248.4941 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #599: GFLOPs: 3638.7196. Time: 31.5917 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #600: GFLOPs: 3556.4427. Time: 32.3225 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #601: GFLOPs: 3541.8591. Time: 32.4556 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #602: GFLOPs: 3571.4604. Time: 32.1866 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #603: GFLOPs: 3596.0262. Time: 31.9667 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #604: GFLOPs: 3538.0378. Time: 32.4907 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #605: GFLOPs: 3582.3840. Time: 32.0885 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #606: GFLOPs: 3581.2533. Time: 32.0986 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #607: GFLOPs: 3581.4659. Time: 32.0967 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #608: GFLOPs: 3571.6976. Time: 32.1845 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #609: GFLOPs: 3542.7473. Time: 32.4475 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #610: GFLOPs: 3542.5371. Time: 32.4494 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #611: GFLOPs: 3556.4835. Time: 32.3222 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #612: GFLOPs: 3581.7965. Time: 32.0937 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #613: GFLOPs: 3648.8857. Time: 31.5036 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #614: GFLOPs: 3596.0185. Time: 31.9668 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #615: GFLOPs: 3540.9739. Time: 32.4637 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #616: GFLOPs: 3560.6739. Time: 32.2841 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #617: GFLOPs: 3538.3702. Time: 32.4876 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #618: GFLOPs: 3512.4484. Time: 32.7274 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #619: GFLOPs: 3598.5734. Time: 31.9441 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #620: GFLOPs: 3541.0904. Time: 32.4627 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #621: GFLOPs: 3550.8319. Time: 32.3736 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #622: GFLOPs: 3541.0834. Time: 32.4627 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #623: GFLOPs: 3548.3262. Time: 32.3965 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #624: GFLOPs: 3541.6705. Time: 32.4573 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #625: GFLOPs: 3500.4782. Time: 32.8393 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #626: GFLOPs: 3468.5981. Time: 33.1411 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #627: GFLOPs: 3501.2393. Time: 32.8322 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #628: GFLOPs: 3644.1593. Time: 31.5445 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #629: GFLOPs: 3552.1679. Time: 32.3614 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #630: GFLOPs: 3625.6375. Time: 31.7057 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #631: GFLOPs: 3586.6468. Time: 32.0503 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #632: GFLOPs: 3460.8900. Time: 33.2149 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #633: GFLOPs: 3630.6012. Time: 31.6623 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #634: GFLOPs: 3500.6161. Time: 32.8380 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #635: GFLOPs: 3502.0676. Time: 32.8244 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #636: GFLOPs: 3501.3558. Time: 32.8311 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #637: GFLOPs: 3500.5471. Time: 32.8386 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #638: GFLOPs: 1402.5878. Time: 81.9579 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #639: GFLOPs: 565.4015. Time: 203.3125 us. Best GFLOPs: 3672.6734
2023-11-11 06:11:25 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #640: GFLOPs: 1866.9144. Time: 61.5739 us. Best GFLOPs: 3672.6734
2023-11-11 06:47:03 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 06:47:07 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 06:47:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 405 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:47:20 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 804 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:47:26 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1201 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:47:33 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1603 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:47:39 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 2003 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:47:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 2403 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:47:45 [INFO] [evolutionary_search.cc:723] Sampled 57 candidate(s)
2023-11-11 06:48:05 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 118 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:48:28 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 135 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:48:52 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 138 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:49:17 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 169 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 06:49:23 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9893  0.9888  0.9865  0.9850  0.9850  0.9850  0.9847  0.9837  0.9835  0.9834  0.9832  0.9822  0.9813  0.9804  0.9791  0.9784
[17 : 32]:	0.9760  0.9752  0.9742  0.9738  0.9728  0.9715  0.9711  0.9705  0.9703  0.9690  0.9683  0.9681  0.9676  0.9674  0.9673  0.9672
[33 : 48]:	0.9658  0.9647  0.9644  0.9642  0.9639  0.9639  0.9637  0.9635  0.9629  0.9628  0.9627  0.9622  0.9619  0.9616  0.9609  0.9609
[49 : 64]:	0.9607  0.9596  0.9593  0.9592  0.9588  0.9574  0.9574  0.9572  0.9572  0.9572  0.9565  0.9565  0.9565  0.9565  0.9562  0.9555
2023-11-11 06:49:23 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 06:49:23 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #641: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(30) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(30) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 8, 2])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #642: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #643: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 2, 8])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #644: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #645: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(16) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 1, 16])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #646: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #647: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(16) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 1, 16])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #648: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 8, 2])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #649: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 8, 2])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #650: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 2, 8])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #651: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #652: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 8, 2])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #653: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 8, 2])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #654: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #655: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #656: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #657: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 2, 8])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #658: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(196), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 2, 8])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #659: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 4, 4])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #660: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(30) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(30) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #661: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(30) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(30) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 8, 2])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #662: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 2, 8])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #663: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 2, 8])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #664: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 4, 4])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #665: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 2, 8])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #666: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #667: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 4, 4])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #668: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 4, 4])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #669: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 8, 2])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #670: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 4, 4])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #671: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #672: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 8, 2])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #673: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(196), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #674: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(196), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 8, 2])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #675: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(112))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(112) // T.int64(7))
                                        v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(7))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(224))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 8, 2])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138, l139 = sch.split(loop=l136, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l139)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l140, l141, l142, l143, l144 = sch.get_loops(block=b109)
l145, l146, l147 = sch.split(loop=l144, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l147)
sch.bind(loop=l146, thread_axis="threadIdx.x")
b148 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b148, ann_key="meta_schedule.unroll_explicit")
b149, b150, b151, b152, b153, b154, b155, b156, b157 = sch.get_child_blocks(b148)
l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b149)
l164, l165, l166, l167, l168, l169 = sch.get_loops(block=b150)
sch.annotate(block_or_loop=l164, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l164, ann_key="pragma_unroll_explicit", ann_val=1)
l170, l171, l172, l173, l174, l175 = sch.get_loops(block=b151)
l176, l177, l178, l179, l180, l181, l182 = sch.get_loops(block=b152)
l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b153)
l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l190, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l190, ann_key="pragma_unroll_explicit", ann_val=1)
l204, l205, l206, l207, l208, l209, l210 = sch.get_loops(block=b155)
l211, l212, l213, l214, l215, l216, l217, l218 = sch.get_loops(block=b156)
sch.annotate(block_or_loop=l211, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l211, ann_key="pragma_unroll_explicit", ann_val=1)
l219, l220, l221, l222 = sch.get_loops(block=b157)
b223 = sch.get_block(name="data_pack", func_name="main")
l224, l225, l226, l227, l228, l229 = sch.get_loops(block=b223)
b230 = sch.decompose_reduction(block=b223, loop=l228)
b231 = sch.get_block(name="bgemm", func_name="main")
l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243, l244, l245 = sch.get_loops(block=b231)
b246 = sch.decompose_reduction(block=b231, loop=l235)
b247 = sch.get_block(name="inverse", func_name="main")
l248, l249, l250, l251, l252, l253, l254, l255 = sch.get_loops(block=b247)
b256 = sch.decompose_reduction(block=b247, loop=l254)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #676: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(16) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 1, 16])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #677: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(196), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 2, 8])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #678: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(112) // T.int64(7))
                                        v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(7))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(224))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(16) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 1, 16])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138, l139 = sch.split(loop=l136, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l139)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l140, l141, l142, l143, l144 = sch.get_loops(block=b109)
l145, l146, l147 = sch.split(loop=l144, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l147)
sch.bind(loop=l146, thread_axis="threadIdx.x")
b148 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b148, ann_key="meta_schedule.unroll_explicit")
b149, b150, b151, b152, b153, b154, b155, b156, b157 = sch.get_child_blocks(b148)
l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b149)
l164, l165, l166, l167, l168, l169 = sch.get_loops(block=b150)
sch.annotate(block_or_loop=l164, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l164, ann_key="pragma_unroll_explicit", ann_val=1)
l170, l171, l172, l173, l174, l175 = sch.get_loops(block=b151)
l176, l177, l178, l179, l180, l181, l182 = sch.get_loops(block=b152)
l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b153)
l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l190, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l190, ann_key="pragma_unroll_explicit", ann_val=1)
l204, l205, l206, l207, l208, l209, l210 = sch.get_loops(block=b155)
l211, l212, l213, l214, l215, l216, l217, l218 = sch.get_loops(block=b156)
sch.annotate(block_or_loop=l211, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l211, ann_key="pragma_unroll_explicit", ann_val=1)
l219, l220, l221, l222 = sch.get_loops(block=b157)
b223 = sch.get_block(name="data_pack", func_name="main")
l224, l225, l226, l227, l228, l229 = sch.get_loops(block=b223)
b230 = sch.decompose_reduction(block=b223, loop=l228)
b231 = sch.get_block(name="bgemm", func_name="main")
l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243, l244, l245 = sch.get_loops(block=b231)
b246 = sch.decompose_reduction(block=b231, loop=l235)
b247 = sch.get_block(name="inverse", func_name="main")
l248, l249, l250, l251, l252, l253, l254, l255 = sch.get_loops(block=b247)
b256 = sch.decompose_reduction(block=b247, loop=l254)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #679: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(112))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(112) // T.int64(7))
                                        v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(7))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(224))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(196), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138, l139 = sch.split(loop=l136, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l139)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l140, l141, l142, l143, l144 = sch.get_loops(block=b109)
l145, l146, l147 = sch.split(loop=l144, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l147)
sch.bind(loop=l146, thread_axis="threadIdx.x")
b148 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b148, ann_key="meta_schedule.unroll_explicit")
b149, b150, b151, b152, b153, b154, b155, b156, b157 = sch.get_child_blocks(b148)
l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b149)
l164, l165, l166, l167, l168, l169 = sch.get_loops(block=b150)
sch.annotate(block_or_loop=l164, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l164, ann_key="pragma_unroll_explicit", ann_val=1)
l170, l171, l172, l173, l174, l175 = sch.get_loops(block=b151)
l176, l177, l178, l179, l180, l181, l182 = sch.get_loops(block=b152)
l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b153)
l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l190, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l190, ann_key="pragma_unroll_explicit", ann_val=1)
l204, l205, l206, l207, l208, l209, l210 = sch.get_loops(block=b155)
l211, l212, l213, l214, l215, l216, l217, l218 = sch.get_loops(block=b156)
sch.annotate(block_or_loop=l211, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l211, ann_key="pragma_unroll_explicit", ann_val=1)
l219, l220, l221, l222 = sch.get_loops(block=b157)
b223 = sch.get_block(name="data_pack", func_name="main")
l224, l225, l226, l227, l228, l229 = sch.get_loops(block=b223)
b230 = sch.decompose_reduction(block=b223, loop=l228)
b231 = sch.get_block(name="bgemm", func_name="main")
l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243, l244, l245 = sch.get_loops(block=b231)
b246 = sch.decompose_reduction(block=b231, loop=l235)
b247 = sch.get_block(name="inverse", func_name="main")
l248, l249, l250, l251, l252, l253, l254, l255 = sch.get_loops(block=b247)
b256 = sch.decompose_reduction(block=b247, loop=l254)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #680: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(16) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 1, 16])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #681: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #682: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 2, 8])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #683: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 4, 4])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #684: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 4, 4])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #685: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(112))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(112) // T.int64(7))
                                        v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(7))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(224))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 4, 4])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138, l139 = sch.split(loop=l136, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l139)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l140, l141, l142, l143, l144 = sch.get_loops(block=b109)
l145, l146, l147 = sch.split(loop=l144, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l147)
sch.bind(loop=l146, thread_axis="threadIdx.x")
b148 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b148, ann_key="meta_schedule.unroll_explicit")
b149, b150, b151, b152, b153, b154, b155, b156, b157 = sch.get_child_blocks(b148)
l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b149)
l164, l165, l166, l167, l168, l169 = sch.get_loops(block=b150)
sch.annotate(block_or_loop=l164, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l164, ann_key="pragma_unroll_explicit", ann_val=1)
l170, l171, l172, l173, l174, l175 = sch.get_loops(block=b151)
l176, l177, l178, l179, l180, l181, l182 = sch.get_loops(block=b152)
l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b153)
l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l190, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l190, ann_key="pragma_unroll_explicit", ann_val=1)
l204, l205, l206, l207, l208, l209, l210 = sch.get_loops(block=b155)
l211, l212, l213, l214, l215, l216, l217, l218 = sch.get_loops(block=b156)
sch.annotate(block_or_loop=l211, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l211, ann_key="pragma_unroll_explicit", ann_val=1)
l219, l220, l221, l222 = sch.get_loops(block=b157)
b223 = sch.get_block(name="data_pack", func_name="main")
l224, l225, l226, l227, l228, l229 = sch.get_loops(block=b223)
b230 = sch.decompose_reduction(block=b223, loop=l228)
b231 = sch.get_block(name="bgemm", func_name="main")
l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243, l244, l245 = sch.get_loops(block=b231)
b246 = sch.decompose_reduction(block=b231, loop=l235)
b247 = sch.get_block(name="inverse", func_name="main")
l248, l249, l250, l251, l252, l253, l254, l255 = sch.get_loops(block=b247)
b256 = sch.decompose_reduction(block=b247, loop=l254)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #686: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(32) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 2, 8])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #687: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(256) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(11) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 4, 4])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #688: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #689: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 4, 4])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #690: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(112) // T.int64(7))
                                        v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(7))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) * T.int64(2) + ax0_ax1_ax2_ax3_fused_2 < T.int64(224))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(16) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 1, 16])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138, l139 = sch.split(loop=l136, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l139)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l140, l141, l142, l143, l144 = sch.get_loops(block=b109)
l145, l146, l147 = sch.split(loop=l144, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l147)
sch.bind(loop=l146, thread_axis="threadIdx.x")
b148 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b148, ann_key="meta_schedule.unroll_explicit")
b149, b150, b151, b152, b153, b154, b155, b156, b157 = sch.get_child_blocks(b148)
l158, l159, l160, l161, l162, l163 = sch.get_loops(block=b149)
l164, l165, l166, l167, l168, l169 = sch.get_loops(block=b150)
sch.annotate(block_or_loop=l164, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l164, ann_key="pragma_unroll_explicit", ann_val=1)
l170, l171, l172, l173, l174, l175 = sch.get_loops(block=b151)
l176, l177, l178, l179, l180, l181, l182 = sch.get_loops(block=b152)
l183, l184, l185, l186, l187, l188, l189 = sch.get_loops(block=b153)
l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201, l202, l203 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l190, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l190, ann_key="pragma_unroll_explicit", ann_val=1)
l204, l205, l206, l207, l208, l209, l210 = sch.get_loops(block=b155)
l211, l212, l213, l214, l215, l216, l217, l218 = sch.get_loops(block=b156)
sch.annotate(block_or_loop=l211, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l211, ann_key="pragma_unroll_explicit", ann_val=1)
l219, l220, l221, l222 = sch.get_loops(block=b157)
b223 = sch.get_block(name="data_pack", func_name="main")
l224, l225, l226, l227, l228, l229 = sch.get_loops(block=b223)
b230 = sch.decompose_reduction(block=b223, loop=l228)
b231 = sch.get_block(name="bgemm", func_name="main")
l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243, l244, l245 = sch.get_loops(block=b231)
b246 = sch.decompose_reduction(block=b231, loop=l235)
b247 = sch.get_block(name="inverse", func_name="main")
l248, l249, l250, l251, l252, l253, l254, l255 = sch.get_loops(block=b247)
b256 = sch.decompose_reduction(block=b247, loop=l254)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #691: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(2) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 8, 2])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #692: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(8)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(2)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(128) + ax0_ax1_ax2_ax3_fused_1 * T.int64(2) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 2, 8])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 2], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #693: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 4, 4])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #694: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(16) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 1024, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 1, 16])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=1024)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #695: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("p1_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(512))
                                        v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(512) // T.int64(32))
                                        v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(256) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(32))
                                        T.reads(p1[v0, v1, v2, v3])
                                        T.writes(p1_shared[v0, v1, v2, v3])
                                        p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(4), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(196), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 4, 4])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145, l146 = sch.split(loop=l143, factors=[None, 64, 4], preserve_unit_iters=True)
sch.vectorize(loop=l146)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b147 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b147, ann_key="meta_schedule.unroll_explicit")
b148, b149, b150, b151, b152, b153, b154, b155, b156 = sch.get_child_blocks(b147)
l157, l158, l159, l160, l161, l162 = sch.get_loops(block=b148)
l163, l164, l165, l166, l167, l168 = sch.get_loops(block=b149)
sch.annotate(block_or_loop=l163, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l163, ann_key="pragma_unroll_explicit", ann_val=1)
l169, l170, l171, l172, l173, l174 = sch.get_loops(block=b150)
l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b151)
l181, l182, l183, l184, l185, l186, l187 = sch.get_loops(block=b152)
l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200, l201 = sch.get_loops(block=b153)
sch.annotate(block_or_loop=l188, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l188, ann_key="pragma_unroll_explicit", ann_val=1)
l202, l203, l204, l205, l206, l207, l208 = sch.get_loops(block=b154)
l209, l210, l211, l212, l213, l214, l215, l216 = sch.get_loops(block=b155)
sch.annotate(block_or_loop=l209, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l209, ann_key="pragma_unroll_explicit", ann_val=1)
l217, l218, l219, l220 = sch.get_loops(block=b156)
b221 = sch.get_block(name="data_pack", func_name="main")
l222, l223, l224, l225, l226, l227 = sch.get_loops(block=b221)
b228 = sch.decompose_reduction(block=b221, loop=l226)
b229 = sch.get_block(name="bgemm", func_name="main")
l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242, l243 = sch.get_loops(block=b229)
b244 = sch.decompose_reduction(block=b229, loop=l233)
b245 = sch.get_block(name="inverse", func_name="main")
l246, l247, l248, l249, l250, l251, l252, l253 = sch.get_loops(block=b245)
b254 = sch.decompose_reduction(block=b245, loop=l252)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #696: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(32))
                                    v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(32))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(16) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 1, 16])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145 = sch.split(loop=l143, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b150)
l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b151)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b153)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b155)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #697: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(32))
                                    v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(32))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145 = sch.split(loop=l143, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b150)
l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b151)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b153)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b155)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #698: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(32))
                                    v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(32))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 64, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=2)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145 = sch.split(loop=l143, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b150)
l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b151)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b153)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=64)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b155)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #699: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(32))
                                    v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(32))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145 = sch.split(loop=l143, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b150)
l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b151)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b153)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b155)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #700: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init * T.int64(7) + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(32))
                                    v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(32))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 * T.int64(7) + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(16) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(112) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(112) // T.int64(56) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 1, 7])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 1, 16])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145 = sch.split(loop=l143, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b150)
l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b151)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b153)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b155)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #701: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(448), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(1), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3_init + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(4)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(112))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1 < T.int64(224))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(16)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(32))
                                    v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(64) + ax0_ax1_ax2_ax3_fused_1) % T.int64(32))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(16), T.int64(1), T.int64(1), T.int64(1), T.int64(7), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + co_3 + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(7)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(224) * T.int64(2) + eps_2_nu_2_co_2_p_2_fused // T.int64(32) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused % T.int64(224) // T.int64(56) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(56) // T.int64(7) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(32) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 512, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(128) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 1, 2, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[4, 1, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[8, 1, 32, 1, 1])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 1, 7, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 16, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=3)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145 = sch.split(loop=l143, factors=[None, 64], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b150)
l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b151)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b153)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=512)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b155)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2023-11-11 06:49:38 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #702: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(30) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(30) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(224), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(14) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused // T.int64(7) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) // T.int64(7) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + eps_2_nu_2_co_2_p_2_fused % T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0_fused in T.serial(T.int64(16), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(32)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                                with T.block("data_pack_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) // T.int64(448))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(448) // T.int64(112))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(112) // T.int64(7))
                                    v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(7))
                                    T.reads(data_pack[v0, v1, v2, v3])
                                    T.writes(data_pack_shared[v0, v1, v2, v3])
                                    data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(37)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(56), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) // T.int64(512))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(512) // T.int64(128))
                                    v2 = T.axis.spatial(T.int64(256), ci_0_fused * T.int64(16) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(128) // T.int64(8))
                                    v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused // T.int64(7) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1) % T.int64(8))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(56) + ax0_ax1_ax2_ax3_fused_1 < T.int64(2048))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(8), T.int64(2), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(14) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused // T.int64(7) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) // T.int64(7) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + eps_2_nu_2_co_2_p_2_fused % T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0_fused * T.int64(16) + ci_1 * T.int64(8) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(14) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused // T.int64(7) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused % T.int64(14) // T.int64(7) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + eps_2_nu_2_co_2_p_2_fused % T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(49), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(256), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(256) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 1, 1, 2])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 4, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[32, 1, 2, 1, 4])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 7, 1, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[16, 2, 8])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
l120 = sch.fuse(l91, preserve_unit_iters=True)
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l120, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v121 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v121)
l122, l123, l124, l125, l126, l127 = sch.get_loops(block=b3)
l128 = sch.fuse(l122, l123, l124, l125, preserve_unit_iters=True)
v129 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=3)
l130, l131 = sch.split(loop=l128, factors=[None, v129], preserve_unit_iters=True)
sch.bind(loop=l130, thread_axis="blockIdx.x")
sch.bind(loop=l131, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l132, l133, l134, l135, l136 = sch.get_loops(block=b98)
l137, l138 = sch.split(loop=l136, factors=[None, 56], preserve_unit_iters=True)
sch.bind(loop=l138, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145 = sch.split(loop=l143, factors=[None, 56], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179 = sch.get_loops(block=b150)
l180, l181, l182, l183, l184, l185 = sch.get_loops(block=b151)
l186, l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l186, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l186, ann_key="pragma_unroll_explicit", ann_val=1)
l200, l201, l202, l203, l204, l205, l206 = sch.get_loops(block=b153)
l207, l208, l209, l210, l211, l212, l213, l214 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l207, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l207, ann_key="pragma_unroll_explicit", ann_val=1)
l215, l216, l217, l218 = sch.get_loops(block=b155)
b219 = sch.get_block(name="data_pack", func_name="main")
l220, l221, l222, l223, l224, l225 = sch.get_loops(block=b219)
b226 = sch.decompose_reduction(block=b219, loop=l224)
b227 = sch.get_block(name="bgemm", func_name="main")
l228, l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241 = sch.get_loops(block=b227)
b242 = sch.decompose_reduction(block=b227, loop=l231)
b243 = sch.get_block(name="inverse", func_name="main")
l244, l245, l246, l247, l248, l249, l250, l251 = sch.get_loops(block=b243)
b252 = sch.decompose_reduction(block=b243, loop=l250)
2023-11-11 06:49:39 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #703: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(392), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(32), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(32) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(64), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(98), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + eps_3_init * T.int64(2) + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(32) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused // T.int64(49) * T.int64(4) + co_3_init * T.int64(4) + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_2_nu_2_co_2_p_2_fused % T.int64(49) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(128)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(98), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(392) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(196))
                                        v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(392) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(196) // T.int64(98))
                                        v2 = T.axis.spatial(T.int64(256), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(392) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(98) // T.int64(49))
                                        v3 = T.axis.spatial(T.int64(49), (ax0_ax1_ax2_ax3_fused_0 * T.int64(392) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(49))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(2)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(98), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1) // T.int64(32))
                                    v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1) % T.int64(32) // T.int64(16))
                                    v2 = T.axis.spatial(T.int64(256), ci_0 * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1) % T.int64(16) // T.int64(8))
                                    v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(32) * T.int64(8) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1) % T.int64(8))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(98) + ax0_ax1_ax2_ax3_fused_1 < T.int64(128))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1), T.int64(4), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + eps_3 * T.int64(2) + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(32) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused // T.int64(49) * T.int64(4) + co_3 * T.int64(4) + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_2_nu_2_co_2_p_2_fused % T.int64(49) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0 * T.int64(2) + ci_1 + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(2), T.int64(1), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_1_nu_1_co_1_p_1_fused // T.int64(2) * T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(32) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(32) * T.int64(8) + eps_2_nu_2_co_2_p_2_fused // T.int64(49) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_2_nu_2_co_2_p_2_fused % T.int64(49) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(13), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(1024), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.where(n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1 < T.int64(12544))
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.where(n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1 < T.int64(12544))
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.where(n_co_h_0_w_0_fused_0 * T.int64(1024) + n_co_h_0_w_0_fused_1 < T.int64(12544))
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=0)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[1, 2, 1, 1, 2])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[32, 1, 2, 1, 4])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[1, 1, 49, 1, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[128, 2, 1])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=5)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b98)
l136, l137, l138 = sch.split(loop=l135, factors=[None, 98, 4], preserve_unit_iters=True)
sch.vectorize(loop=l138)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145 = sch.split(loop=l143, factors=[None, 98], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b151)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b153)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b155)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 06:49:39 [INFO] [task_scheduler.cc:121] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #704: Error in running:
LocalRunner: An exception occurred
Traceback (most recent call last):
  File "/home2/xiachunwei/Software/tvm/python/tvm/exec/popen_worker.py", line 87, in main
    result = fn(*args, **kwargs)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 152, in _worker_func
    repeated_args: List[T_ARGUMENT_LIST] = f_alloc_argument(
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/local_runner.py", line 360, in default_alloc_argument
    return alloc_argument_common(f_random_fill, device, args_info, alloc_repeat)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 74, in alloc_argument_common
    arg: Any = dispatcher.get(arg_type, None)(*arg_info)
  File "/home2/xiachunwei/Software/tvm/python/tvm/meta_schedule/runner/utils.py", line 56, in alloc_tensor
    arg = ndarray.empty(shape=shape, dtype=dtype, device=device)
  File "/home2/xiachunwei/Software/tvm/python/tvm/runtime/ndarray.py", line 391, in empty
    arr = _ffi_api.TVMArrayAllocWithScope(shape, dtype, device, mem_scope)
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/_ctypes/packed_func.py", line 239, in __call__
    raise_last_ffi_error()
  File "/home2/xiachunwei/Software/tvm/python/tvm/_ffi/base.py", line 481, in raise_last_ffi_error
    raise py_err
tvm.error.InternalError: Traceback (most recent call last):
  4: _ZN3tvm7runtime13PackedFun
  3: tvm::runtime::TypedPackedFunc<tvm::runtime::NDArray (tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>::AssignTypedLambda<tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)>(tvm::runtime::NDArray (*)(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}::operator()(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*) const
  2: tvm::runtime::NDArray::Empty(tvm::runtime::ShapeTuple, DLDataType, DLDevice, tvm::runtime::Optional<tvm::runtime::String>)
  1: tvm::runtime::DeviceAPI::AllocDataSpace(DLDevice, int, long const*, DLDataType, tvm::runtime::Optional<tvm::runtime::String>)
  0: tvm::runtime::CUDADeviceAPI::AllocDataSpace(DLDevice, unsigned long, unsigned long, DLDataType)
  File "/home2/xiachunwei/Software/tvm/src/runtime/cuda/cuda_device_api.cc", line 126
InternalError: Check failed: (e == cudaSuccess || e == cudaErrorCudartUnloading) is false: CUDA: misaligned address

# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p1: T.Buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), "float32"), p2: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32"), p3: T.Buffer((T.int64(1), T.int64(256), T.int64(1), T.int64(1)), "float32"), T_relu: T.Buffer((T.int64(1), T.int64(256), T.int64(14), T.int64(14)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        input_tile_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(4), T.int64(4)), scope="local")
        data_pack = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        bgemm = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)))
        inverse_local = T.alloc_buffer((T.int64(256), T.int64(49), T.int64(2), T.int64(2)), scope="local")
        data_pack_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        bgemm_local = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="local")
        data_pack_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(49)), scope="shared")
        p1_shared = T.alloc_buffer((T.int64(4), T.int64(4), T.int64(256), T.int64(256)), scope="shared")
        for ci_p_fused_0 in T.thread_binding(T.int64(98), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for ci_p_fused_1 in T.thread_binding(T.int64(128), thread="threadIdx.x"):
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(1), T.int64(4), T.int64(4)):
                    with T.block("input_tile"):
                        v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49) + ax0)
                        v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(30) + ci_p_fused_1) % T.int64(49) + ax1)
                        v_eps, v_nu = T.axis.remap("SS", [ax2, ax3])
                        T.reads(p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)])
                        T.writes(input_tile_local[v_ci, v_p, v_eps, v_nu])
                        T.block_attr({"schedule_rule": "None"})
                        input_tile_local[v_ci, v_p, v_eps, v_nu] = T.if_then_else(T.int64(1) <= v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps and v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps < T.int64(15) and T.int64(1) <= v_p % T.int64(7) * T.int64(2) + v_nu and v_p % T.int64(7) * T.int64(2) + v_nu < T.int64(15), p0[v_p // T.int64(49), v_ci, v_p % T.int64(49) // T.int64(7) * T.int64(2) + v_eps - T.int64(1), v_p % T.int64(7) * T.int64(2) + v_nu - T.int64(1)], T.float32(0))
                for eps in T.unroll(T.int64(4)):
                    for nu in T.unroll(T.int64(4)):
                        with T.block("data_pack_init"):
                            v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                            v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49))
                            v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(49))
                            T.reads()
                            T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                            T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                            data_pack_local[v_eps, v_nu, v_ci, v_p] = T.float32(0)
                        for r_a in T.unroll(T.int64(4)):
                            for r_b in T.unroll(T.int64(4)):
                                with T.block("data_pack_update"):
                                    v_eps, v_nu = T.axis.remap("SS", [eps, nu])
                                    v_ci = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49))
                                    v_p = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) % T.int64(49))
                                    v_r_a, v_r_b = T.axis.remap("RR", [r_a, r_b])
                                    T.reads(data_pack_local[v_eps, v_nu, v_ci, v_p], input_tile_local[v_ci, v_p, v_r_a, v_r_b])
                                    T.writes(data_pack_local[v_eps, v_nu, v_ci, v_p])
                                    T.block_attr({"schedule_rule": "conv2d_nchw_winograd_data_pack"})
                                    data_pack_local[v_eps, v_nu, v_ci, v_p] = data_pack_local[v_eps, v_nu, v_ci, v_p] + input_tile_local[v_ci, v_p, v_r_a, v_r_b] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_eps % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_eps % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_eps % T.int64(4) == T.int64(0), T.float32(1), T.float32(0))))))))))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(3), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_nu % T.int64(4) == T.int64(0), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(3), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(2), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_nu % T.int64(4) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(3), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(2), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_nu % T.int64(4) == T.int64(0), T.float32(1), T.float32(0)))))))))))))))))
                for ax0, ax1, ax2, ax3 in T.grid(T.int64(4), T.int64(4), T.int64(1), T.int64(1)):
                    with T.block("data_pack_local"):
                        v0, v1 = T.axis.remap("SS", [ax0, ax1])
                        v2 = T.axis.spatial(T.int64(256), (ci_p_fused_0 * T.int64(128) + ci_p_fused_1) // T.int64(49) + ax2)
                        v3 = T.axis.spatial(T.int64(49), (ci_p_fused_0 * T.int64(30) + ci_p_fused_1) % T.int64(49) + ax3)
                        T.reads(data_pack_local[v0, v1, v2, v3])
                        T.writes(data_pack[v0, v1, v2, v3])
                        data_pack[v0, v1, v2, v3] = data_pack_local[v0, v1, v2, v3]
        for eps_0_nu_0_co_0_p_0_fused in T.thread_binding(T.int64(56), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for eps_1_nu_1_co_1_p_1_fused in T.thread_binding(T.int64(4), thread="vthread.x"):
                for eps_2_nu_2_co_2_p_2_fused in T.thread_binding(T.int64(112), thread="threadIdx.x"):
                    for eps_3_init, nu_3_init, co_3_init, p_3_init, eps_4_init, nu_4_init, co_4_init, p_4_init in T.grid(T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                        with T.block("bgemm_init"):
                            v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(28) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) + eps_3_init + eps_4_init)
                            v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(56) * T.int64(2) + nu_3_init + nu_4_init)
                            v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(28) // T.int64(7) * T.int64(64) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(56) // T.int64(7) * T.int64(4) + co_3_init * T.int64(2) + co_4_init)
                            v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + eps_2_nu_2_co_2_p_2_fused % T.int64(7) + p_3_init + p_4_init)
                            T.reads()
                            T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                            T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                            bgemm_local[v_eps, v_nu, v_co, v_p] = T.float32(0)
                    for ci_0 in range(T.int64(64)):
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(1)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(112), thread="threadIdx.x"):
                                for ax0_ax1_ax2_ax3_fused_2 in T.vectorized(T.int64(4)):
                                    with T.block("data_pack_shared"):
                                        v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(28) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(448) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) // T.int64(112))
                                        v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(448) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(112) // T.int64(28))
                                        v2 = T.axis.spatial(T.int64(256), ci_0 * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(448) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(28) // T.int64(7))
                                        v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(448) + ax0_ax1_ax2_ax3_fused_1 * T.int64(4) + ax0_ax1_ax2_ax3_fused_2) % T.int64(7))
                                        T.where((ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1) * T.int64(4) + ax0_ax1_ax2_ax3_fused_2 < T.int64(224))
                                        T.reads(data_pack[v0, v1, v2, v3])
                                        T.writes(data_pack_shared[v0, v1, v2, v3])
                                        data_pack_shared[v0, v1, v2, v3] = data_pack[v0, v1, v2, v3]
                        for ax0_ax1_ax2_ax3_fused_0 in range(T.int64(19)):
                            for ax0_ax1_ax2_ax3_fused_1 in T.thread_binding(T.int64(112), thread="threadIdx.x"):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(28) * T.int64(2) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1) // T.int64(1024))
                                    v1 = T.axis.spatial(T.int64(4), (ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1) % T.int64(1024) // T.int64(256))
                                    v2 = T.axis.spatial(T.int64(256), ci_0 * T.int64(4) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1) % T.int64(256) // T.int64(64))
                                    v3 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(28) // T.int64(7) * T.int64(64) + (ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1) % T.int64(64))
                                    T.where(ax0_ax1_ax2_ax3_fused_0 * T.int64(112) + ax0_ax1_ax2_ax3_fused_1 < T.int64(2048))
                                    T.reads(p1[v0, v1, v2, v3])
                                    T.writes(p1_shared[v0, v1, v2, v3])
                                    p1_shared[v0, v1, v2, v3] = p1[v0, v1, v2, v3]
                        for ci_1, eps_3, nu_3, co_3, p_3, ci_2, eps_4, nu_4, co_4, p_4 in T.grid(T.int64(1), T.int64(1), T.int64(2), T.int64(2), T.int64(1), T.int64(4), T.int64(1), T.int64(1), T.int64(2), T.int64(1)):
                            with T.block("bgemm_update"):
                                v_eps = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(28) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) + eps_3 + eps_4)
                                v_nu = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(56) * T.int64(2) + nu_3 + nu_4)
                                v_co = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(28) // T.int64(7) * T.int64(64) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(56) // T.int64(7) * T.int64(4) + co_3 * T.int64(2) + co_4)
                                v_p = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + eps_2_nu_2_co_2_p_2_fused % T.int64(7) + p_3 + p_4)
                                v_ci = T.axis.reduce(T.int64(256), ci_0 * T.int64(4) + ci_1 * T.int64(4) + ci_2)
                                T.reads(bgemm_local[v_eps, v_nu, v_co, v_p], data_pack_shared[v_eps, v_nu, v_ci, v_p], p1_shared[v_eps, v_nu, v_ci, v_co])
                                T.writes(bgemm_local[v_eps, v_nu, v_co, v_p])
                                T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                bgemm_local[v_eps, v_nu, v_co, v_p] = bgemm_local[v_eps, v_nu, v_co, v_p] + data_pack_shared[v_eps, v_nu, v_ci, v_p] * p1_shared[v_eps, v_nu, v_ci, v_co]
                    for ax0, ax1, ax2, ax3 in T.grid(T.int64(1), T.int64(2), T.int64(4), T.int64(1)):
                        with T.block("bgemm_local"):
                            v0 = T.axis.spatial(T.int64(4), eps_0_nu_0_co_0_p_0_fused // T.int64(28) * T.int64(2) + eps_1_nu_1_co_1_p_1_fused // T.int64(2) + ax0)
                            v1 = T.axis.spatial(T.int64(4), eps_2_nu_2_co_2_p_2_fused // T.int64(56) * T.int64(2) + ax1)
                            v2 = T.axis.spatial(T.int64(256), eps_0_nu_0_co_0_p_0_fused % T.int64(28) // T.int64(7) * T.int64(64) + eps_1_nu_1_co_1_p_1_fused % T.int64(2) * T.int64(32) + eps_2_nu_2_co_2_p_2_fused % T.int64(56) // T.int64(7) * T.int64(4) + ax2)
                            v3 = T.axis.spatial(T.int64(49), eps_0_nu_0_co_0_p_0_fused % T.int64(7) * T.int64(7) + eps_2_nu_2_co_2_p_2_fused % T.int64(7) + ax3)
                            T.reads(bgemm_local[v0, v1, v2, v3])
                            T.writes(bgemm[v0, v1, v2, v3])
                            bgemm[v0, v1, v2, v3] = bgemm_local[v0, v1, v2, v3]
        for n_co_h_0_w_0_fused_0 in T.thread_binding(T.int64(196), thread="blockIdx.x", annotations={"pragma_auto_unroll_max_step": 16, "pragma_unroll_explicit": 1}):
            for n_co_h_0_w_0_fused_1 in T.thread_binding(T.int64(64), thread="threadIdx.x"):
                for ax0, ax1 in T.grid(T.int64(1), T.int64(1)):
                    for ax2 in T.unroll(T.int64(2)):
                        for ax3 in T.unroll(T.int64(2)):
                            with T.block("inverse_init"):
                                v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                v_vh, v_vw = T.axis.remap("SS", [ax2, ax3])
                                T.reads()
                                T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                inverse_local[v_co, v_p, v_vh, v_vw] = T.float32(0)
                            for ax4 in T.unroll(T.int64(4)):
                                for ax5 in T.unroll(T.int64(4)):
                                    with T.block("inverse_update"):
                                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49) + ax0)
                                        v_p = T.axis.spatial(T.int64(49), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) + ax1)
                                        v_vh, v_vw, v_r_a, v_r_b = T.axis.remap("SSRR", [ax2, ax3, ax4, ax5])
                                        T.reads(inverse_local[v_co, v_p, v_vh, v_vw], bgemm[v_r_a, v_r_b, v_co, v_p])
                                        T.writes(inverse_local[v_co, v_p, v_vh, v_vw])
                                        T.block_attr({"schedule_rule": "conv2d_nchw_winograd_inverse"})
                                        inverse_local[v_co, v_p, v_vh, v_vw] = inverse_local[v_co, v_p, v_vh, v_vw] + bgemm[v_r_a, v_r_b, v_co, v_p] * T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(3) and v_vh % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(2) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_a % T.int64(4) == T.int64(1) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_a % T.int64(4) == T.int64(0) and v_vh % T.int64(2) == T.int64(0), T.float32(1), T.float32(0))))))))) * T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(3) and v_vw % T.int64(2) == T.int64(0), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(1), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(2) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(1), T.float32(-1), T.Select(v_r_b % T.int64(4) == T.int64(1) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(1), T.float32(0), T.Select(v_r_b % T.int64(4) == T.int64(0) and v_vw % T.int64(2) == T.int64(0), T.float32(1), T.float32(0)))))))))
                for h_1, w_1 in T.grid(T.int64(2), T.int64(2)):
                    with T.block("conv2d_winograd"):
                        v_n = T.axis.spatial(T.int64(1), T.int64(0))
                        v_co = T.axis.spatial(T.int64(256), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) // T.int64(49))
                        v_h = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(49) // T.int64(7) * T.int64(2) + h_1)
                        v_w = T.axis.spatial(T.int64(14), (n_co_h_0_w_0_fused_0 * T.int64(64) + n_co_h_0_w_0_fused_1) % T.int64(7) * T.int64(2) + w_1)
                        T.reads(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)], p2[v_n, v_co, v_h, v_w], p3[v_n, v_co, T.int64(0), T.int64(0)])
                        T.writes(T_relu[v_n, v_co, v_h, v_w])
                        T_relu[v_n, v_co, v_h, v_w] = T.max(inverse_local[v_co, v_n * T.int64(49) + v_h // T.int64(2) * T.int64(7) + v_w // T.int64(2), v_h % T.int64(2), v_w % T.int64(2)] + p2[v_n, v_co, v_h, v_w] + p3[v_n, v_co, T.int64(0), T.int64(0)], T.float32(0))
b0 = sch.get_block(name="data_pack", func_name="main")
b1 = sch.get_block(name="bgemm", func_name="main")
b2 = sch.get_block(name="inverse", func_name="main")
b3 = sch.get_block(name="conv2d_winograd", func_name="main")
b4 = sch.get_block(name="T_add", func_name="main")
b5 = sch.get_block(name="T_add_1", func_name="main")
b6 = sch.get_block(name="T_relu", func_name="main")
b7 = sch.get_block(name="root", func_name="main")
b8, b9 = sch.get_producers(block=b2)
sch.compute_inline(block=b9)
b10, = sch.get_consumers(block=b2)
l11, l12, l13, l14 = sch.get_loops(block=b10)
l15, l16 = sch.split(loop=l13, factors=[None, 2], preserve_unit_iters=True)
l17, l18 = sch.split(loop=l14, factors=[None, 2], preserve_unit_iters=True)
sch.reorder(l15, l17, l16, l18)
sch.compute_at(block=b2, loop=l17, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b2, buffer_index=0, storage_scope="local")
l19, l20, l21, l22, l23, l24, l25, l26, l27, l28 = sch.get_loops(block=b2)
sch.unroll(loop=l25)
sch.unroll(loop=l26)
sch.unroll(loop=l27)
sch.unroll(loop=l28)
b29, b30 = sch.get_producers(block=b0)
sch.compute_inline(block=b30)
b31, = sch.get_producers(block=b29)
l32, l33, l34, l35, l36, l37 = sch.get_loops(block=b0)
sch.reorder(l34, l35, l32, l33, l36, l37)
sch.unroll(loop=l32)
sch.unroll(loop=l33)
sch.unroll(loop=l36)
sch.unroll(loop=l37)
l38 = sch.fuse(l34, l35, preserve_unit_iters=True)
v39 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=2)
l40, l41 = sch.split(loop=l38, factors=[None, v39], preserve_unit_iters=True)
sch.bind(loop=l40, thread_axis="blockIdx.x")
sch.bind(loop=l41, thread_axis="threadIdx.x")
b42 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b42, loop=l41, preserve_unit_loops=True, index=-1)
sch.compute_at(block=b29, loop=l41, preserve_unit_loops=True, index=-1)
sch.set_scope(block=b29, buffer_index=0, storage_scope="local")
sch.compute_inline(block=b31)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l43, l44, l45, l46, l47 = sch.get_loops(block=b1)
v48, v49, v50, v51, v52 = sch.sample_perfect_tile(loop=l43, n=5, max_innermost_factor=64, decision=[2, 2, 1, 1, 1])
l53, l54, l55, l56, l57 = sch.split(loop=l43, factors=[v48, v49, v50, v51, v52], preserve_unit_iters=True)
v58, v59, v60, v61, v62 = sch.sample_perfect_tile(loop=l44, n=5, max_innermost_factor=64, decision=[1, 1, 2, 2, 1])
l63, l64, l65, l66, l67 = sch.split(loop=l44, factors=[v58, v59, v60, v61, v62], preserve_unit_iters=True)
v68, v69, v70, v71, v72 = sch.sample_perfect_tile(loop=l45, n=5, max_innermost_factor=64, decision=[4, 2, 8, 2, 2])
l73, l74, l75, l76, l77 = sch.split(loop=l45, factors=[v68, v69, v70, v71, v72], preserve_unit_iters=True)
v78, v79, v80, v81, v82 = sch.sample_perfect_tile(loop=l46, n=5, max_innermost_factor=64, decision=[7, 1, 7, 1, 1])
l83, l84, l85, l86, l87 = sch.split(loop=l46, factors=[v78, v79, v80, v81, v82], preserve_unit_iters=True)
v88, v89, v90 = sch.sample_perfect_tile(loop=l47, n=3, max_innermost_factor=64, decision=[64, 1, 4])
l91, l92, l93 = sch.split(loop=l47, factors=[v88, v89, v90], preserve_unit_iters=True)
sch.reorder(l53, l63, l73, l83, l54, l64, l74, l84, l55, l65, l75, l85, l91, l92, l56, l66, l76, l86, l93, l57, l67, l77, l87)
l94 = sch.fuse(l53, l63, l73, l83, preserve_unit_iters=True)
sch.bind(loop=l94, thread_axis="blockIdx.x")
l95 = sch.fuse(l54, l64, l74, l84, preserve_unit_iters=True)
sch.bind(loop=l95, thread_axis="vthread.x")
l96 = sch.fuse(l55, l65, l75, l85, preserve_unit_iters=True)
sch.bind(loop=l96, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b1, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b97 = sch.cache_write(block=b1, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b97, loop=l96, preserve_unit_loops=True, index=-1)
b98 = sch.cache_read(block=b1, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b98, loop=l91, preserve_unit_loops=True, index=-1)
l99, l100, l101, l102, l103, l104, l105, l106 = sch.get_loops(block=b98)
l107 = sch.fuse(l103, l104, l105, l106, preserve_unit_iters=True)
v108 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=3)
sch.annotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch", ann_val=v108)
b109 = sch.cache_read(block=b1, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b1])
sch.compute_at(block=b109, loop=l91, preserve_unit_loops=True, index=-1)
l110, l111, l112, l113, l114, l115, l116, l117 = sch.get_loops(block=b109)
l118 = sch.fuse(l114, l115, l116, l117, preserve_unit_iters=True)
v119 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=0)
sch.annotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch", ann_val=v119)
sch.reverse_compute_inline(block=b6)
sch.reverse_compute_inline(block=b5)
sch.reverse_compute_inline(block=b4)
v120 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=1)
sch.annotate(block_or_loop=b7, ann_key="meta_schedule.unroll_explicit", ann_val=v120)
l121, l122, l123, l124, l125, l126 = sch.get_loops(block=b3)
l127 = sch.fuse(l121, l122, l123, l124, preserve_unit_iters=True)
v128 = sch.sample_categorical(candidates=[32, 64, 128, 256, 512, 1024], probs=[0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666], decision=1)
l129, l130 = sch.split(loop=l127, factors=[None, v128], preserve_unit_iters=True)
sch.bind(loop=l129, thread_axis="blockIdx.x")
sch.bind(loop=l130, thread_axis="threadIdx.x")
sch.enter_postproc()
sch.unannotate(block_or_loop=b98, ann_key="meta_schedule.cooperative_fetch")
l131, l132, l133, l134, l135 = sch.get_loops(block=b98)
l136, l137, l138 = sch.split(loop=l135, factors=[None, 112, 4], preserve_unit_iters=True)
sch.vectorize(loop=l138)
sch.bind(loop=l137, thread_axis="threadIdx.x")
sch.unannotate(block_or_loop=b109, ann_key="meta_schedule.cooperative_fetch")
l139, l140, l141, l142, l143 = sch.get_loops(block=b109)
l144, l145 = sch.split(loop=l143, factors=[None, 112], preserve_unit_iters=True)
sch.bind(loop=l145, thread_axis="threadIdx.x")
b146 = sch.get_block(name="root", func_name="main")
sch.unannotate(block_or_loop=b146, ann_key="meta_schedule.unroll_explicit")
b147, b148, b149, b150, b151, b152, b153, b154, b155 = sch.get_child_blocks(b146)
l156, l157, l158, l159, l160, l161 = sch.get_loops(block=b147)
l162, l163, l164, l165, l166, l167 = sch.get_loops(block=b148)
sch.annotate(block_or_loop=l162, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l162, ann_key="pragma_unroll_explicit", ann_val=1)
l168, l169, l170, l171, l172, l173 = sch.get_loops(block=b149)
l174, l175, l176, l177, l178, l179, l180 = sch.get_loops(block=b150)
l181, l182, l183, l184, l185, l186 = sch.get_loops(block=b151)
l187, l188, l189, l190, l191, l192, l193, l194, l195, l196, l197, l198, l199, l200 = sch.get_loops(block=b152)
sch.annotate(block_or_loop=l187, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l187, ann_key="pragma_unroll_explicit", ann_val=1)
l201, l202, l203, l204, l205, l206, l207 = sch.get_loops(block=b153)
l208, l209, l210, l211, l212, l213, l214, l215 = sch.get_loops(block=b154)
sch.annotate(block_or_loop=l208, ann_key="pragma_auto_unroll_max_step", ann_val=16)
sch.annotate(block_or_loop=l208, ann_key="pragma_unroll_explicit", ann_val=1)
l216, l217, l218, l219 = sch.get_loops(block=b155)
b220 = sch.get_block(name="data_pack", func_name="main")
l221, l222, l223, l224, l225, l226 = sch.get_loops(block=b220)
b227 = sch.decompose_reduction(block=b220, loop=l225)
b228 = sch.get_block(name="bgemm", func_name="main")
l229, l230, l231, l232, l233, l234, l235, l236, l237, l238, l239, l240, l241, l242 = sch.get_loops(block=b228)
b243 = sch.decompose_reduction(block=b228, loop=l232)
b244 = sch.get_block(name="inverse", func_name="main")
l245, l246, l247, l248, l249, l250, l251, l252 = sch.get_loops(block=b244)
b253 = sch.decompose_reduction(block=b244, loop=l251)
2023-11-11 07:19:15 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 07:19:18 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 07:19:25 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 405 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:19:31 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 800 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:19:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1197 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:19:44 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1597 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:19:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1996 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:19:51 [INFO] [evolutionary_search.cc:723] Sampled 54 candidate(s)
2023-11-11 07:20:11 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 117 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:20:36 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 143 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:21:01 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 150 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:21:25 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 132 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:21:32 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9847  0.9845  0.9832  0.9781  0.9780  0.9777  0.9775  0.9772  0.9769  0.9758  0.9754  0.9710  0.9708  0.9707  0.9690  0.9690
[17 : 32]:	0.9685  0.9684  0.9680  0.9666  0.9666  0.9652  0.9650  0.9649  0.9629  0.9625  0.9620  0.9613  0.9613  0.9607  0.9605  0.9596
[33 : 48]:	0.9596  0.9593  0.9586  0.9583  0.9576  0.9576  0.9572  0.9565  0.9565  0.9565  0.9565  0.9562  0.9561  0.9561  0.9559  0.9552
[49 : 64]:	0.9551  0.9551  0.9551  0.9549  0.9542  0.9538  0.9538  0.9537  0.9533  0.9533  0.9532  0.9528  0.9526  0.9522  0.9522  0.9519
2023-11-11 07:21:32 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 07:21:32 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #705: GFLOPs: 3582.5057. Time: 32.0874 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #706: GFLOPs: 3650.9277. Time: 31.4860 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #707: GFLOPs: 3600.7266. Time: 31.9250 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #708: GFLOPs: 3590.3780. Time: 32.0170 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #709: GFLOPs: 3587.1851. Time: 32.0455 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #710: GFLOPs: 3579.3786. Time: 32.1154 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #711: GFLOPs: 2235.8098. Time: 51.4146 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #712: GFLOPs: 3579.3176. Time: 32.1160 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #713: GFLOPs: 3604.6027. Time: 31.8907 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #714: GFLOPs: 3622.2245. Time: 31.7355 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #715: GFLOPs: 3653.2374. Time: 31.4661 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #716: GFLOPs: 3549.2961. Time: 32.3876 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #717: GFLOPs: 3549.6243. Time: 32.3846 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #718: GFLOPs: 3549.3432. Time: 32.3872 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #719: GFLOPs: 3549.0913. Time: 32.3895 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #720: GFLOPs: 3550.7623. Time: 32.3742 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #721: GFLOPs: 3549.8571. Time: 32.3825 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #722: GFLOPs: 3647.7083. Time: 31.5138 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #723: GFLOPs: 3519.3696. Time: 32.6630 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #724: GFLOPs: 3566.1535. Time: 32.2345 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #725: GFLOPs: 3565.0670. Time: 32.2443 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #726: GFLOPs: 3575.5228. Time: 32.1500 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #727: GFLOPs: 3572.9572. Time: 32.1731 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #728: GFLOPs: 3534.9284. Time: 32.5192 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #729: GFLOPs: 3536.9855. Time: 32.5003 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #730: GFLOPs: 3539.1677. Time: 32.4803 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #731: GFLOPs: 3547.3994. Time: 32.4049 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #732: GFLOPs: 3532.9457. Time: 32.5375 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #733: GFLOPs: 3547.1670. Time: 32.4070 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #734: GFLOPs: 3538.4295. Time: 32.4871 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #735: GFLOPs: 3538.1306. Time: 32.4898 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #736: GFLOPs: 3534.0308. Time: 32.5275 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #737: GFLOPs: 3533.3923. Time: 32.5334 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #738: GFLOPs: 3606.2746. Time: 31.8759 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #739: GFLOPs: 3549.5775. Time: 32.3850 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #740: GFLOPs: 3535.7107. Time: 32.5121 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #741: GFLOPs: 3547.4928. Time: 32.4041 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #742: GFLOPs: 3516.2160. Time: 32.6923 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #743: GFLOPs: 3450.3753. Time: 33.3161 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #744: GFLOPs: 3455.5137. Time: 33.2666 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #745: GFLOPs: 3491.1929. Time: 32.9266 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #746: GFLOPs: 3491.3825. Time: 32.9248 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #747: GFLOPs: 3537.9969. Time: 32.4910 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #748: GFLOPs: 3494.1569. Time: 32.8987 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #749: GFLOPs: 3569.6759. Time: 32.2027 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #750: GFLOPs: 3449.5773. Time: 33.3239 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #751: GFLOPs: 3551.8361. Time: 32.3644 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #752: GFLOPs: 3565.9669. Time: 32.2362 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #753: GFLOPs: 3486.2030. Time: 32.9738 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #754: GFLOPs: 3457.6257. Time: 33.2463 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #755: GFLOPs: 3493.9504. Time: 32.9006 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #756: GFLOPs: 3547.2588. Time: 32.4062 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #757: GFLOPs: 3556.4603. Time: 32.3224 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #758: GFLOPs: 3550.7392. Time: 32.3744 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #759: GFLOPs: 3550.8786. Time: 32.3732 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #760: GFLOPs: 3507.2927. Time: 32.7755 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #761: GFLOPs: 3455.1087. Time: 33.2705 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #762: GFLOPs: 3454.5195. Time: 33.2762 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #763: GFLOPs: 3575.0993. Time: 32.1539 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #764: GFLOPs: 3549.7508. Time: 32.3835 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #765: GFLOPs: 3550.3676. Time: 32.3778 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #766: GFLOPs: 790.4806. Time: 145.4219 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #767: GFLOPs: 196.8368. Time: 584.0028 us. Best GFLOPs: 3672.6734
2023-11-11 07:22:04 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #768: GFLOPs: 768.6173. Time: 149.5585 us. Best GFLOPs: 3672.6734
2023-11-11 07:52:29 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 07:52:32 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 07:52:38 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 397 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:52:45 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 791 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:52:51 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1189 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:52:57 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1591 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:53:04 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1992 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:53:04 [INFO] [evolutionary_search.cc:723] Sampled 58 candidate(s)
2023-11-11 07:53:24 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 128 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:53:48 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 143 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:54:12 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 136 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:54:36 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 148 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 07:54:42 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9832  0.9813  0.9813  0.9806  0.9804  0.9804  0.9799  0.9798  0.9790  0.9781  0.9781  0.9774  0.9774  0.9764  0.9752  0.9751
[17 : 32]:	0.9735  0.9734  0.9734  0.9732  0.9709  0.9705  0.9703  0.9684  0.9684  0.9673  0.9648  0.9639  0.9635  0.9632  0.9628  0.9624
[33 : 48]:	0.9621  0.9609  0.9605  0.9596  0.9595  0.9592  0.9590  0.9589  0.9589  0.9588  0.9579  0.9576  0.9576  0.9573  0.9565  0.9554
[49 : 64]:	0.9553  0.9553  0.9551  0.9551  0.9546  0.9546  0.9546  0.9546  0.9544  0.9542  0.9541  0.9538  0.9536  0.9533  0.9532  0.9529
2023-11-11 07:54:42 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 07:54:42 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #769: GFLOPs: 3593.7107. Time: 31.9873 us. Best GFLOPs: 3672.6734
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #770: GFLOPs: 3586.9493. Time: 32.0476 us. Best GFLOPs: 3672.6734
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #771: GFLOPs: 3620.4777. Time: 31.7508 us. Best GFLOPs: 3672.6734
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #772: GFLOPs: 3608.6185. Time: 31.8552 us. Best GFLOPs: 3672.6734
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #773: GFLOPs: 3623.9889. Time: 31.7201 us. Best GFLOPs: 3672.6734
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #774: GFLOPs: 3577.5474. Time: 32.1318 us. Best GFLOPs: 3672.6734
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #775: GFLOPs: 3546.8642. Time: 32.4098 us. Best GFLOPs: 3672.6734
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #776: GFLOPs: 3598.2929. Time: 31.9466 us. Best GFLOPs: 3672.6734
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #777: GFLOPs: 3510.2927. Time: 32.7475 us. Best GFLOPs: 3672.6734
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #778: GFLOPs: 3668.9299. Time: 31.3315 us. Best GFLOPs: 3672.6734
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #779: GFLOPs: 3661.3933. Time: 31.3960 us. Best GFLOPs: 3672.6734
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #780: GFLOPs: 3689.6552. Time: 31.1555 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #781: GFLOPs: 3688.5131. Time: 31.1652 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #782: GFLOPs: 3631.5896. Time: 31.6537 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #783: GFLOPs: 3668.9542. Time: 31.3313 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #784: GFLOPs: 3600.1087. Time: 31.9305 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #785: GFLOPs: 3631.1261. Time: 31.6577 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #786: GFLOPs: 3554.3034. Time: 32.3420 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #787: GFLOPs: 3563.9063. Time: 32.2548 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #788: GFLOPs: 3600.1059. Time: 31.9305 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #789: GFLOPs: 3591.4624. Time: 32.0074 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #790: GFLOPs: 3522.7253. Time: 32.6319 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #791: GFLOPs: 3631.6493. Time: 31.6532 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #792: GFLOPs: 3603.8452. Time: 31.8974 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #793: GFLOPs: 3603.0870. Time: 31.9041 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #794: GFLOPs: 3523.6583. Time: 32.6233 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #795: GFLOPs: 3615.4472. Time: 31.7950 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #796: GFLOPs: 3531.6692. Time: 32.5493 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #797: GFLOPs: 3556.4562. Time: 32.3224 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #798: GFLOPs: 3551.3198. Time: 32.3692 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #799: GFLOPs: 3547.1653. Time: 32.4071 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #800: GFLOPs: 3556.9047. Time: 32.3183 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #801: GFLOPs: 3565.7752. Time: 32.2379 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #802: GFLOPs: 3573.5188. Time: 32.1681 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #803: GFLOPs: 3532.2259. Time: 32.5441 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #804: GFLOPs: 3540.8986. Time: 32.4644 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #805: GFLOPs: 3493.9713. Time: 32.9004 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #806: GFLOPs: 3566.7859. Time: 32.2288 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #807: GFLOPs: 3553.7070. Time: 32.3474 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #808: GFLOPs: 3571.2883. Time: 32.1882 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #809: GFLOPs: 3581.5131. Time: 32.0963 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #810: GFLOPs: 3476.8507. Time: 33.0625 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #811: GFLOPs: 3540.6007. Time: 32.4672 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #812: GFLOPs: 3552.5977. Time: 32.3575 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #813: GFLOPs: 3550.4917. Time: 32.3767 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #814: GFLOPs: 3553.9927. Time: 32.3448 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #815: GFLOPs: 3495.0029. Time: 32.8907 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #816: GFLOPs: 3516.7882. Time: 32.6870 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #817: GFLOPs: 3523.6028. Time: 32.6238 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #818: GFLOPs: 3537.9679. Time: 32.4913 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #819: GFLOPs: 3501.6665. Time: 32.8281 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #820: GFLOPs: 3449.2925. Time: 33.3266 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #821: GFLOPs: 3632.5277. Time: 31.6455 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #822: GFLOPs: 3621.4709. Time: 31.7421 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #823: GFLOPs: 3505.4360. Time: 32.7928 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #824: GFLOPs: 3528.4242. Time: 32.5792 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #825: GFLOPs: 3533.7121. Time: 32.5304 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #826: GFLOPs: 3598.6027. Time: 31.9438 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #827: GFLOPs: 3483.6647. Time: 32.9978 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #828: GFLOPs: 3545.5977. Time: 32.4214 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #829: GFLOPs: 3539.3617. Time: 32.4785 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #830: GFLOPs: 324.3736. Time: 354.3852 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #831: GFLOPs: 267.4922. Time: 429.7441 us. Best GFLOPs: 3689.6552
2023-11-11 07:55:15 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #832: GFLOPs: 2052.5545. Time: 56.0050 us. Best GFLOPs: 3689.6552
2023-11-11 08:16:42 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 08:16:46 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 08:16:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 395 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:16:59 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 796 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:17:06 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1196 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:17:13 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1597 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:17:19 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1998 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:17:19 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2023-11-11 08:17:39 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 108 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:18:04 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 111 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:18:28 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 129 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:18:52 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 114 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:18:59 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9865  0.9862  0.9860  0.9828  0.9815  0.9814  0.9802  0.9794  0.9786  0.9781  0.9779  0.9778  0.9778  0.9761  0.9751  0.9751
[17 : 32]:	0.9744  0.9726  0.9724  0.9707  0.9703  0.9702  0.9696  0.9696  0.9693  0.9693  0.9693  0.9693  0.9683  0.9681  0.9670  0.9669
[33 : 48]:	0.9658  0.9658  0.9646  0.9645  0.9636  0.9635  0.9632  0.9631  0.9631  0.9617  0.9614  0.9608  0.9607  0.9604  0.9602  0.9602
[49 : 64]:	0.9598  0.9598  0.9598  0.9595  0.9593  0.9592  0.9588  0.9581  0.9578  0.9577  0.9567  0.9564  0.9564  0.9555  0.9550  0.9549
2023-11-11 08:18:59 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 08:18:59 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #833: GFLOPs: 3611.1276. Time: 31.8331 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #834: GFLOPs: 3650.8073. Time: 31.4871 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #835: GFLOPs: 3611.2229. Time: 31.8322 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #836: GFLOPs: 3655.2368. Time: 31.4489 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #837: GFLOPs: 3606.7356. Time: 31.8718 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #838: GFLOPs: 3611.1145. Time: 31.8332 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #839: GFLOPs: 3625.0052. Time: 31.7112 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #840: GFLOPs: 3624.2484. Time: 31.7178 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #841: GFLOPs: 3596.2383. Time: 31.9648 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #842: GFLOPs: 3568.0470. Time: 32.2174 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #843: GFLOPs: 3588.5460. Time: 32.0334 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #844: GFLOPs: 3564.9592. Time: 32.2453 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #845: GFLOPs: 3616.5309. Time: 31.7855 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #846: GFLOPs: 3573.2170. Time: 32.1708 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #847: GFLOPs: 3603.0921. Time: 31.9040 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #848: GFLOPs: 3561.3814. Time: 32.2777 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #849: GFLOPs: 3561.0316. Time: 32.2809 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #850: GFLOPs: 3593.6254. Time: 31.9881 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #851: GFLOPs: 3546.0604. Time: 32.4172 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #852: GFLOPs: 3614.8157. Time: 31.8006 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #853: GFLOPs: 3535.3423. Time: 32.5154 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #854: GFLOPs: 3611.9600. Time: 31.8257 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #855: GFLOPs: 3588.6142. Time: 32.0328 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #856: GFLOPs: 3618.7287. Time: 31.7662 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #857: GFLOPs: 3579.5081. Time: 32.1142 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #858: GFLOPs: 3528.5880. Time: 32.5777 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #859: GFLOPs: 3538.8295. Time: 32.4834 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #860: GFLOPs: 3538.1306. Time: 32.4898 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #861: GFLOPs: 3504.9512. Time: 32.7974 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #862: GFLOPs: 3574.1578. Time: 32.1623 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #863: GFLOPs: 3588.2175. Time: 32.0363 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #864: GFLOPs: 3537.9969. Time: 32.4910 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #865: GFLOPs: 3532.5278. Time: 32.5413 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #866: GFLOPs: 3510.5471. Time: 32.7451 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #867: GFLOPs: 3585.8487. Time: 32.0575 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #868: GFLOPs: 3527.4286. Time: 32.5884 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #869: GFLOPs: 3555.1109. Time: 32.3346 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #870: GFLOPs: 3559.9504. Time: 32.2907 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #871: GFLOPs: 3495.6718. Time: 32.8844 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #872: GFLOPs: 3493.3539. Time: 32.9063 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #873: GFLOPs: 3567.9048. Time: 32.2187 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #874: GFLOPs: 3483.0913. Time: 33.0032 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #875: GFLOPs: 3549.2727. Time: 32.3878 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #876: GFLOPs: 3498.2402. Time: 32.8603 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #877: GFLOPs: 3568.4970. Time: 32.2133 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #878: GFLOPs: 3524.1486. Time: 32.6187 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #879: GFLOPs: 3568.9427. Time: 32.2093 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #880: GFLOPs: 3569.1304. Time: 32.2076 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #881: GFLOPs: 2500.4702. Time: 45.9726 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #882: GFLOPs: 3592.7932. Time: 31.9955 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #883: GFLOPs: 3552.7345. Time: 32.3563 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #884: GFLOPs: 3561.7119. Time: 32.2747 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #885: GFLOPs: 3553.5894. Time: 32.3485 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #886: GFLOPs: 3536.7110. Time: 32.5029 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #887: GFLOPs: 3557.3284. Time: 32.3145 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #888: GFLOPs: 3525.0002. Time: 32.6108 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #889: GFLOPs: 3480.8359. Time: 33.0246 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #890: GFLOPs: 3427.9582. Time: 33.5340 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #891: GFLOPs: 3409.1492. Time: 33.7190 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #892: GFLOPs: 3507.1742. Time: 32.7766 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #893: GFLOPs: 3466.2475. Time: 33.1636 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #894: GFLOPs: 289.5939. Time: 396.9463 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #895: GFLOPs: 32.2344. Time: 3566.1681 us. Best GFLOPs: 3689.6552
2023-11-11 08:19:48 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #896: GFLOPs: 485.1932. Time: 236.9225 us. Best GFLOPs: 3689.6552
2023-11-11 08:49:31 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 08:49:34 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 08:49:40 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 398 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:49:47 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 793 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:49:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1195 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:50:00 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1588 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:50:00 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2023-11-11 08:50:19 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 99 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:50:43 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 147 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:51:07 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 134 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:51:31 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 132 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 08:51:37 [INFO] [evolutionary_search.cc:649] Scores of the best 64 candidates:
[1 : 16]:	0.9864  0.9864  0.9850  0.9831  0.9812  0.9808  0.9808  0.9803  0.9797  0.9790  0.9787  0.9781  0.9761  0.9760  0.9756  0.9756
[17 : 32]:	0.9726  0.9717  0.9708  0.9708  0.9707  0.9705  0.9697  0.9696  0.9682  0.9680  0.9674  0.9671  0.9671  0.9670  0.9654  0.9650
[33 : 48]:	0.9650  0.9649  0.9645  0.9645  0.9638  0.9638  0.9633  0.9631  0.9626  0.9626  0.9626  0.9621  0.9617  0.9610  0.9601  0.9601
[49 : 64]:	0.9600  0.9598  0.9596  0.9596  0.9595  0.9590  0.9579  0.9567  0.9566  0.9564  0.9564  0.9561  0.9556  0.9550  0.9549  0.9546
2023-11-11 08:51:38 [INFO] [evolutionary_search.cc:727] Got 64 candidate(s) with evolutionary search
2023-11-11 08:51:38 [INFO] [evolutionary_search.cc:730] Sending 64 candidates(s) for measurement
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #897: GFLOPs: 3584.9818. Time: 32.0652 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #898: GFLOPs: 3631.4351. Time: 31.6550 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #899: GFLOPs: 3630.5552. Time: 31.6627 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #900: GFLOPs: 3627.4995. Time: 31.6894 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #901: GFLOPs: 3581.2769. Time: 32.0984 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #902: GFLOPs: 3580.0219. Time: 32.1096 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #903: GFLOPs: 3625.4167. Time: 31.7076 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #904: GFLOPs: 3622.3100. Time: 31.7348 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #905: GFLOPs: 3547.9328. Time: 32.4001 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #906: GFLOPs: 3622.8604. Time: 31.7300 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #907: GFLOPs: 3562.9630. Time: 32.2634 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #908: GFLOPs: 3611.3836. Time: 31.8308 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #909: GFLOPs: 3606.3467. Time: 31.8753 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #910: GFLOPs: 3608.7285. Time: 31.8542 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #911: GFLOPs: 3564.9948. Time: 32.2450 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #912: GFLOPs: 3608.2301. Time: 31.8586 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #913: GFLOPs: 3563.0647. Time: 32.2625 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #914: GFLOPs: 3608.6810. Time: 31.8546 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #915: GFLOPs: 3537.8745. Time: 32.4922 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #916: GFLOPs: 3545.3646. Time: 32.4235 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #917: GFLOPs: 3543.5789. Time: 32.4399 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #918: GFLOPs: 3541.7905. Time: 32.4562 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #919: GFLOPs: 3548.9755. Time: 32.3905 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #920: GFLOPs: 3641.7628. Time: 31.5653 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #921: GFLOPs: 3510.4780. Time: 32.7457 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #922: GFLOPs: 3586.1255. Time: 32.0550 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #923: GFLOPs: 3537.5488. Time: 32.4952 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #924: GFLOPs: 3532.8761. Time: 32.5381 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #925: GFLOPs: 3571.3416. Time: 32.1877 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #926: GFLOPs: 3547.5027. Time: 32.4040 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #927: GFLOPs: 3513.4215. Time: 32.7183 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #928: GFLOPs: 3573.4523. Time: 32.1687 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #929: GFLOPs: 3558.8189. Time: 32.3009 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #930: GFLOPs: 3637.1059. Time: 31.6057 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #931: GFLOPs: 3550.3743. Time: 32.3778 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #932: GFLOPs: 3548.8042. Time: 32.3921 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #933: GFLOPs: 3513.7693. Time: 32.7151 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #934: GFLOPs: 3625.7096. Time: 31.7050 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #935: GFLOPs: 3555.6451. Time: 32.3298 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #936: GFLOPs: 3507.7238. Time: 32.7715 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #937: GFLOPs: 3527.5676. Time: 32.5871 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #938: GFLOPs: 3573.3355. Time: 32.1697 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #939: GFLOPs: 3574.1434. Time: 32.1625 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #940: GFLOPs: 3557.2576. Time: 32.3151 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #941: GFLOPs: 3519.5309. Time: 32.6615 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #942: GFLOPs: 3554.2253. Time: 32.3427 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #943: GFLOPs: 3553.4956. Time: 32.3493 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #944: GFLOPs: 3554.1556. Time: 32.3433 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #945: GFLOPs: 3366.4336. Time: 34.1469 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #946: GFLOPs: 3627.4995. Time: 31.6894 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #947: GFLOPs: 3489.0017. Time: 32.9473 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #948: GFLOPs: 3517.3695. Time: 32.6816 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #949: GFLOPs: 3558.9542. Time: 32.2997 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #950: GFLOPs: 3472.4901. Time: 33.1040 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #951: GFLOPs: 3486.0531. Time: 32.9752 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #952: GFLOPs: 3515.5146. Time: 32.6988 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #953: GFLOPs: 3550.2338. Time: 32.3791 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #954: GFLOPs: 3458.2763. Time: 33.2400 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #955: GFLOPs: 3468.5105. Time: 33.1420 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #956: GFLOPs: 3521.6296. Time: 32.6421 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #957: GFLOPs: 3471.7241. Time: 33.1113 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #958: GFLOPs: 74.6037. Time: 1540.8522 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #959: GFLOPs: 19.1459. Time: 6004.0732 us. Best GFLOPs: 3689.6552
2023-11-11 08:52:11 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #960: GFLOPs: 993.7344. Time: 115.6780 us. Best GFLOPs: 3689.6552
2023-11-11 09:18:51 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-11 09:18:55 [INFO] [evolutionary_search.cc:715] Picked top 102 candidate(s) from database
2023-11-11 09:19:02 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 397 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 09:19:08 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 793 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 09:19:15 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1188 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 09:19:21 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 1581 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 09:19:21 [INFO] [evolutionary_search.cc:723] Sampled 59 candidate(s)
2023-11-11 09:19:41 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 112 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 09:20:05 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 111 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 09:20:29 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 124 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 09:20:53 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x56310ec2fda8)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x56310ed65a28)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x56310edaf428)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x56310c01e038)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x56310f841888)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x56310eec5d58)]: 141 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x56310dc91148)]: 0 failure(s)
2023-11-11 09:21:00 [INFO] [evolutionary_search.cc:649] Scores of the best 40 candidates:
[1 : 16]:	0.9901  0.9893  0.9882  0.9873  0.9860  0.9848  0.9839  0.9831  0.9826  0.9819  0.9808  0.9789  0.9785  0.9784  0.9778  0.9778
[17 : 32]:	0.9770  0.9751  0.9750  0.9749  0.9748  0.9730  0.9727  0.9717  0.9716  0.9716  0.9708  0.9707  0.9696  0.9693  0.9690  0.9688
[33 : 40]:	0.9683  0.9667  0.9664  0.9658  0.9647  0.9646  0.9641  0.9637
2023-11-11 09:21:00 [INFO] [evolutionary_search.cc:727] Got 40 candidate(s) with evolutionary search
2023-11-11 09:21:00 [INFO] [evolutionary_search.cc:730] Sending 40 candidates(s) for measurement
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #961: GFLOPs: 3629.2953. Time: 31.6737 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #962: GFLOPs: 3633.8991. Time: 31.6336 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #963: GFLOPs: 3628.4911. Time: 31.6807 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #964: GFLOPs: 3633.3938. Time: 31.6380 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #965: GFLOPs: 3665.6545. Time: 31.3595 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #966: GFLOPs: 3688.6347. Time: 31.1642 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #967: GFLOPs: 3686.8137. Time: 31.1796 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #968: GFLOPs: 3613.8871. Time: 31.8087 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #969: GFLOPs: 3665.2073. Time: 31.3634 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #970: GFLOPs: 3607.2092. Time: 31.8676 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #971: GFLOPs: 3660.0637. Time: 31.4074 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #972: GFLOPs: 3666.2849. Time: 31.3541 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #973: GFLOPs: 3661.8403. Time: 31.3922 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #974: GFLOPs: 3665.4363. Time: 31.3614 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #975: GFLOPs: 3660.8151. Time: 31.4010 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #976: GFLOPs: 3609.9190. Time: 31.8437 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #977: GFLOPs: 3655.2849. Time: 31.4485 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #978: GFLOPs: 3647.1620. Time: 31.5185 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #979: GFLOPs: 3592.3653. Time: 31.9993 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #980: GFLOPs: 3633.5679. Time: 31.6365 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #981: GFLOPs: 3636.8620. Time: 31.6078 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #982: GFLOPs: 3604.4609. Time: 31.8919 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #983: GFLOPs: 3641.7891. Time: 31.5650 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #984: GFLOPs: 3594.1486. Time: 31.9834 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #985: GFLOPs: 3580.2558. Time: 32.1075 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #986: GFLOPs: 3641.1829. Time: 31.5703 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #987: GFLOPs: 3578.6386. Time: 32.1221 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #988: GFLOPs: 3657.0103. Time: 31.4337 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #989: GFLOPs: 3651.3366. Time: 31.4825 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #990: GFLOPs: 3578.9750. Time: 32.1190 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #991: GFLOPs: 3535.3618. Time: 32.5153 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #992: GFLOPs: 3580.0254. Time: 32.1096 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #993: GFLOPs: 3662.1992. Time: 31.3891 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #994: GFLOPs: 3614.6048. Time: 31.8024 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #995: GFLOPs: 3596.6153. Time: 31.9615 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #996: GFLOPs: 3578.3972. Time: 32.1242 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #997: GFLOPs: 3600.3207. Time: 31.9286 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #998: GFLOPs: 3662.5302. Time: 31.3863 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #999: GFLOPs: 107.7419. Time: 1066.9317 us. Best GFLOPs: 3689.6552
2023-11-11 09:21:23 [INFO] [task_scheduler.cc:131] [Task #20: fused_nn_contrib_conv2d_winograd_without_weight_transform_add_add_nn_relu_2] Trial #1000: GFLOPs: 354.6685. Time: 324.1145 us. Best GFLOPs: 3689.6552
