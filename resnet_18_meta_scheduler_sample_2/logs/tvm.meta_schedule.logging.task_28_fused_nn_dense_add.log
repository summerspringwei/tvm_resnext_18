2023-11-10 22:04:32 [INFO] [task_scheduler.cc:160] Initializing Task #28: "fused_nn_dense_add"
2023-11-10 22:04:32 [INFO] [task_scheduler.cc:35] 
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512)), "float32"), p1: T.Buffer((T.int64(1000), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        # with T.block("root"):
        T_matmul_NT = T.alloc_buffer((T.int64(1), T.int64(1000)))
        for i, j, k in T.grid(T.int64(1), T.int64(1000), T.int64(512)):
            with T.block("T_matmul_NT"):
                v_i, v_j, v_k = T.axis.remap("SSR", [i, j, k])
                T.reads(p0[v_i, v_k], p1[v_j, v_k])
                T.writes(T_matmul_NT[v_i, v_j])
                with T.init():
                    T_matmul_NT[v_i, v_j] = T.float32(0)
                T_matmul_NT[v_i, v_j] = T_matmul_NT[v_i, v_j] + p0[v_i, v_k] * p1[v_j, v_k]
        for ax0, ax1 in T.grid(T.int64(1), T.int64(1000)):
            with T.block("T_add"):
                v_ax0, v_ax1 = T.axis.remap("SS", [ax0, ax1])
                T.reads(T_matmul_NT[v_ax0, v_ax1], p2[v_ax0, v_ax1])
                T.writes(T_add[v_ax0, v_ax1])
                T_add[v_ax0, v_ax1] = T_matmul_NT[v_ax0, v_ax1] + p2[v_ax0, v_ax1]
2023-11-10 22:04:32 [INFO] [task_scheduler.cc:164] Total 3 design space(s) generated
2023-11-10 22:04:32 [INFO] [task_scheduler.cc:170] Design space #0:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512)), "float32"), p1: T.Buffer((T.int64(1000), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 1024})
            T_matmul_NT_local = T.alloc_buffer((T.int64(1), T.int64(1000)), scope="local")
            p0_shared = T.alloc_buffer((T.int64(1), T.int64(512)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(1000), T.int64(512)), scope="shared")
            for i_0_j_0_fused in T.thread_binding(T.int64(4), thread="blockIdx.x"):
                for i_1_j_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                    for i_2_j_2_fused in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                        for k_0 in range(T.int64(8)):
                            for ax0_ax1_fused in range(T.int64(64)):
                                with T.block("p0_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(512), k_0 * T.int64(64) + ax0_ax1_fused)
                                    T.reads(p0[v0, v1])
                                    T.writes(p0_shared[v0, v1])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                    p0_shared[v0, v1] = p0[v0, v1]
                            for ax0_ax1_fused in range(T.int64(16000)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(1000), i_0_j_0_fused * T.int64(250) + ax0_ax1_fused // T.int64(64))
                                    v1 = T.axis.spatial(T.int64(512), k_0 * T.int64(64) + ax0_ax1_fused % T.int64(64))
                                    T.reads(p1[v0, v1])
                                    T.writes(p1_shared[v0, v1])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    p1_shared[v0, v1] = p1[v0, v1]
                            for k_1, i_3, j_3, k_2, i_4, j_4 in T.grid(T.int64(1), T.int64(1), T.int64(25), T.int64(64), T.int64(1), T.int64(5)):
                                with T.block("T_matmul_NT"):
                                    v_i = T.axis.spatial(T.int64(1), i_3 + i_4)
                                    v_j = T.axis.spatial(T.int64(1000), i_0_j_0_fused * T.int64(250) + i_1_j_1_fused * T.int64(125) + j_3 * T.int64(5) + j_4)
                                    v_k = T.axis.reduce(T.int64(512), k_0 * T.int64(64) + k_1 * T.int64(64) + k_2)
                                    T.reads(p0_shared[v_i, v_k], p1_shared[v_j, v_k])
                                    T.writes(T_matmul_NT_local[v_i, v_j])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        T_matmul_NT_local[v_i, v_j] = T.float32(0)
                                    T_matmul_NT_local[v_i, v_j] = T_matmul_NT_local[v_i, v_j] + p0_shared[v_i, v_k] * p1_shared[v_j, v_k]
                        for ax0, ax1 in T.grid(T.int64(1), T.int64(125)):
                            with T.block("T_matmul_NT_local"):
                                v0 = T.axis.spatial(T.int64(1), ax0)
                                v1 = T.axis.spatial(T.int64(1000), i_0_j_0_fused * T.int64(250) + i_1_j_1_fused * T.int64(125) + ax1)
                                T.reads(T_matmul_NT_local[v0, v1], p2[v0, v1])
                                T.writes(T_add[v0, v1])
                                T_add[v0, v1] = T_matmul_NT_local[v0, v1] + p2[v0, v1]
b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l3, l4, l5 = sch.get_loops(block=b0)
v6, v7, v8, v9, v10 = sch.sample_perfect_tile(loop=l3, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l11, l12, l13, l14, l15 = sch.split(loop=l3, factors=[v6, v7, v8, v9, v10], preserve_unit_iters=True)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l4, n=5, max_innermost_factor=64, decision=[4, 2, 1, 25, 5])
l21, l22, l23, l24, l25 = sch.split(loop=l4, factors=[v16, v17, v18, v19, v20], preserve_unit_iters=True)
v26, v27, v28 = sch.sample_perfect_tile(loop=l5, n=3, max_innermost_factor=64, decision=[8, 1, 64])
l29, l30, l31 = sch.split(loop=l5, factors=[v26, v27, v28], preserve_unit_iters=True)
sch.reorder(l11, l21, l12, l22, l13, l23, l29, l30, l14, l24, l31, l15, l25)
l32 = sch.fuse(l11, l21, preserve_unit_iters=True)
sch.bind(loop=l32, thread_axis="blockIdx.x")
l33 = sch.fuse(l12, l22, preserve_unit_iters=True)
sch.bind(loop=l33, thread_axis="vthread.x")
l34 = sch.fuse(l13, l23, preserve_unit_iters=True)
sch.bind(loop=l34, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b35 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b35, loop=l34, preserve_unit_loops=True, index=-1)
b36 = sch.cache_read(block=b0, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b0])
sch.compute_at(block=b36, loop=l29, preserve_unit_loops=True, index=-1)
l37, l38, l39, l40, l41, l42 = sch.get_loops(block=b36)
l43 = sch.fuse(l41, l42, preserve_unit_iters=True)
v44 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b36, ann_key="meta_schedule.cooperative_fetch", ann_val=v44)
b45 = sch.cache_read(block=b0, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b0])
sch.compute_at(block=b45, loop=l29, preserve_unit_loops=True, index=-1)
l46, l47, l48, l49, l50, l51 = sch.get_loops(block=b45)
l52 = sch.fuse(l50, l51, preserve_unit_iters=True)
v53 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b45, ann_key="meta_schedule.cooperative_fetch", ann_val=v53)
sch.reverse_compute_inline(block=b1)
v54 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v54)
2023-11-10 22:04:32 [INFO] [task_scheduler.cc:170] Design space #1:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512)), "float32"), p1: T.Buffer((T.int64(1000), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 0})
            T_matmul_NT_local = T.alloc_buffer((T.int64(1), T.int64(1000)), scope="local")
            p0_shared = T.alloc_buffer((T.int64(1), T.int64(512)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(1000), T.int64(512)), scope="shared")
            for i_0_j_0_fused in T.thread_binding(T.int64(4), thread="blockIdx.x"):
                for i_1_j_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                    for i_2_j_2_fused in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                        for k_0_fused in T.serial(T.int64(8), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 2]}):
                            for ax0_ax1_fused in range(T.int64(64)):
                                with T.block("p0_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(512), k_0_fused * T.int64(64) + ax0_ax1_fused)
                                    T.reads(p0[v0, v1])
                                    T.writes(p0_shared[v0, v1])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                    p0_shared[v0, v1] = p0[v0, v1]
                            for ax0_ax1_fused in range(T.int64(16000)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(1000), i_0_j_0_fused * T.int64(250) + ax0_ax1_fused // T.int64(64))
                                    v1 = T.axis.spatial(T.int64(512), k_0_fused * T.int64(64) + ax0_ax1_fused % T.int64(64))
                                    T.reads(p1[v0, v1])
                                    T.writes(p1_shared[v0, v1])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    p1_shared[v0, v1] = p1[v0, v1]
                            for k_1, i_3, j_3, k_2, i_4, j_4 in T.grid(T.int64(1), T.int64(1), T.int64(25), T.int64(64), T.int64(1), T.int64(5)):
                                with T.block("T_matmul_NT"):
                                    v_i = T.axis.spatial(T.int64(1), i_3 + i_4)
                                    v_j = T.axis.spatial(T.int64(1000), i_0_j_0_fused * T.int64(250) + i_1_j_1_fused * T.int64(125) + j_3 * T.int64(5) + j_4)
                                    v_k = T.axis.reduce(T.int64(512), k_0_fused * T.int64(64) + k_1 * T.int64(64) + k_2)
                                    T.reads(p0_shared[v_i, v_k], p1_shared[v_j, v_k])
                                    T.writes(T_matmul_NT_local[v_i, v_j])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        T_matmul_NT_local[v_i, v_j] = T.float32(0)
                                    T_matmul_NT_local[v_i, v_j] = T_matmul_NT_local[v_i, v_j] + p0_shared[v_i, v_k] * p1_shared[v_j, v_k]
                        for ax0, ax1 in T.grid(T.int64(1), T.int64(125)):
                            with T.block("T_matmul_NT_local"):
                                v0 = T.axis.spatial(T.int64(1), ax0)
                                v1 = T.axis.spatial(T.int64(1000), i_0_j_0_fused * T.int64(250) + i_1_j_1_fused * T.int64(125) + ax1)
                                T.reads(T_matmul_NT_local[v0, v1], p2[v0, v1])
                                T.writes(T_add[v0, v1])
                                T_add[v0, v1] = T_matmul_NT_local[v0, v1] + p2[v0, v1]
b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l3, l4, l5 = sch.get_loops(block=b0)
v6, v7, v8, v9, v10 = sch.sample_perfect_tile(loop=l3, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l11, l12, l13, l14, l15 = sch.split(loop=l3, factors=[v6, v7, v8, v9, v10], preserve_unit_iters=True)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l4, n=5, max_innermost_factor=64, decision=[4, 2, 1, 25, 5])
l21, l22, l23, l24, l25 = sch.split(loop=l4, factors=[v16, v17, v18, v19, v20], preserve_unit_iters=True)
v26, v27, v28 = sch.sample_perfect_tile(loop=l5, n=3, max_innermost_factor=64, decision=[8, 1, 64])
l29, l30, l31 = sch.split(loop=l5, factors=[v26, v27, v28], preserve_unit_iters=True)
sch.reorder(l11, l21, l12, l22, l13, l23, l29, l30, l14, l24, l31, l15, l25)
l32 = sch.fuse(l11, l21, preserve_unit_iters=True)
sch.bind(loop=l32, thread_axis="blockIdx.x")
l33 = sch.fuse(l12, l22, preserve_unit_iters=True)
sch.bind(loop=l33, thread_axis="vthread.x")
l34 = sch.fuse(l13, l23, preserve_unit_iters=True)
sch.bind(loop=l34, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b35 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b35, loop=l34, preserve_unit_loops=True, index=-1)
b36 = sch.cache_read(block=b0, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b0])
sch.compute_at(block=b36, loop=l29, preserve_unit_loops=True, index=-1)
l37, l38, l39, l40, l41, l42 = sch.get_loops(block=b36)
l43 = sch.fuse(l41, l42, preserve_unit_iters=True)
v44 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b36, ann_key="meta_schedule.cooperative_fetch", ann_val=v44)
b45 = sch.cache_read(block=b0, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b0])
sch.compute_at(block=b45, loop=l29, preserve_unit_loops=True, index=-1)
l46, l47, l48, l49, l50, l51 = sch.get_loops(block=b45)
l52 = sch.fuse(l50, l51, preserve_unit_iters=True)
v53 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b45, ann_key="meta_schedule.cooperative_fetch", ann_val=v53)
l54 = sch.fuse(l29, preserve_unit_iters=True)
sch.annotate(block_or_loop=l54, ann_key="software_pipeline_stage", ann_val=[0, 0, 2])
sch.annotate(block_or_loop=l54, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l54, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b1)
v55 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=0)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v55)
2023-11-10 22:04:32 [INFO] [task_scheduler.cc:170] Design space #2:
# from tvm.script import ir as I
# from tvm.script import tir as T

@I.ir_module
class Module:
    @T.prim_func
    def main(p0: T.Buffer((T.int64(1), T.int64(512)), "float32"), p1: T.Buffer((T.int64(1000), T.int64(512)), "float32"), p2: T.Buffer((T.int64(1), T.int64(1000)), "float32"), T_add: T.Buffer((T.int64(1), T.int64(1000)), "float32")):
        T.func_attr({"layout_free_buffers": [1], "tir.noalias": T.bool(True)})
        with T.block("root"):
            T.reads()
            T.writes()
            T.block_attr({"meta_schedule.unroll_explicit": 1024})
            T_matmul_NT_local = T.alloc_buffer((T.int64(1), T.int64(1000)), scope="local")
            p0_shared = T.alloc_buffer((T.int64(1), T.int64(512)), scope="shared")
            p1_shared = T.alloc_buffer((T.int64(1000), T.int64(512)), scope="shared")
            for i_0_j_0_fused in T.thread_binding(T.int64(4), thread="blockIdx.x"):
                for i_1_j_1_fused in T.thread_binding(T.int64(2), thread="vthread.x"):
                    for i_2_j_2_fused in T.thread_binding(T.int64(1), thread="threadIdx.x"):
                        for k_0_fused in T.serial(T.int64(8), annotations={"software_pipeline_async_stages": [0], "software_pipeline_order": [0, 1, 2], "software_pipeline_stage": [0, 0, 3]}):
                            for ax0_ax1_fused in range(T.int64(64)):
                                with T.block("p0_shared"):
                                    v0 = T.axis.spatial(T.int64(1), T.int64(0))
                                    v1 = T.axis.spatial(T.int64(512), k_0_fused * T.int64(64) + ax0_ax1_fused)
                                    T.reads(p0[v0, v1])
                                    T.writes(p0_shared[v0, v1])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 2})
                                    p0_shared[v0, v1] = p0[v0, v1]
                            for ax0_ax1_fused in range(T.int64(16000)):
                                with T.block("p1_shared"):
                                    v0 = T.axis.spatial(T.int64(1000), i_0_j_0_fused * T.int64(250) + ax0_ax1_fused // T.int64(64))
                                    v1 = T.axis.spatial(T.int64(512), k_0_fused * T.int64(64) + ax0_ax1_fused % T.int64(64))
                                    T.reads(p1[v0, v1])
                                    T.writes(p1_shared[v0, v1])
                                    T.block_attr({"meta_schedule.cooperative_fetch": 3})
                                    p1_shared[v0, v1] = p1[v0, v1]
                            for k_1, i_3, j_3, k_2, i_4, j_4 in T.grid(T.int64(1), T.int64(1), T.int64(25), T.int64(64), T.int64(1), T.int64(5)):
                                with T.block("T_matmul_NT"):
                                    v_i = T.axis.spatial(T.int64(1), i_3 + i_4)
                                    v_j = T.axis.spatial(T.int64(1000), i_0_j_0_fused * T.int64(250) + i_1_j_1_fused * T.int64(125) + j_3 * T.int64(5) + j_4)
                                    v_k = T.axis.reduce(T.int64(512), k_0_fused * T.int64(64) + k_1 * T.int64(64) + k_2)
                                    T.reads(p0_shared[v_i, v_k], p1_shared[v_j, v_k])
                                    T.writes(T_matmul_NT_local[v_i, v_j])
                                    T.block_attr({"meta_schedule.thread_extent_high_inclusive": 1024, "meta_schedule.thread_extent_low_inclusive": 32, "meta_schedule.tiling_structure": "SSSRRSRS"})
                                    with T.init():
                                        T_matmul_NT_local[v_i, v_j] = T.float32(0)
                                    T_matmul_NT_local[v_i, v_j] = T_matmul_NT_local[v_i, v_j] + p0_shared[v_i, v_k] * p1_shared[v_j, v_k]
                        for ax0, ax1 in T.grid(T.int64(1), T.int64(125)):
                            with T.block("T_matmul_NT_local"):
                                v0 = T.axis.spatial(T.int64(1), ax0)
                                v1 = T.axis.spatial(T.int64(1000), i_0_j_0_fused * T.int64(250) + i_1_j_1_fused * T.int64(125) + ax1)
                                T.reads(T_matmul_NT_local[v0, v1], p2[v0, v1])
                                T.writes(T_add[v0, v1])
                                T_add[v0, v1] = T_matmul_NT_local[v0, v1] + p2[v0, v1]
b0 = sch.get_block(name="T_matmul_NT", func_name="main")
b1 = sch.get_block(name="T_add", func_name="main")
b2 = sch.get_block(name="root", func_name="main")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.tiling_structure", ann_val="SSSRRSRS")
l3, l4, l5 = sch.get_loops(block=b0)
v6, v7, v8, v9, v10 = sch.sample_perfect_tile(loop=l3, n=5, max_innermost_factor=64, decision=[1, 1, 1, 1, 1])
l11, l12, l13, l14, l15 = sch.split(loop=l3, factors=[v6, v7, v8, v9, v10], preserve_unit_iters=True)
v16, v17, v18, v19, v20 = sch.sample_perfect_tile(loop=l4, n=5, max_innermost_factor=64, decision=[4, 2, 1, 25, 5])
l21, l22, l23, l24, l25 = sch.split(loop=l4, factors=[v16, v17, v18, v19, v20], preserve_unit_iters=True)
v26, v27, v28 = sch.sample_perfect_tile(loop=l5, n=3, max_innermost_factor=64, decision=[8, 1, 64])
l29, l30, l31 = sch.split(loop=l5, factors=[v26, v27, v28], preserve_unit_iters=True)
sch.reorder(l11, l21, l12, l22, l13, l23, l29, l30, l14, l24, l31, l15, l25)
l32 = sch.fuse(l11, l21, preserve_unit_iters=True)
sch.bind(loop=l32, thread_axis="blockIdx.x")
l33 = sch.fuse(l12, l22, preserve_unit_iters=True)
sch.bind(loop=l33, thread_axis="vthread.x")
l34 = sch.fuse(l13, l23, preserve_unit_iters=True)
sch.bind(loop=l34, thread_axis="threadIdx.x")
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.thread_extent_low_inclusive", ann_val=32)
sch.annotate(block_or_loop=b0, ann_key="meta_schedule.thread_extent_high_inclusive", ann_val=1024)
b35 = sch.cache_write(block=b0, write_buffer_index=0, storage_scope="local")
sch.reverse_compute_at(block=b35, loop=l34, preserve_unit_loops=True, index=-1)
b36 = sch.cache_read(block=b0, read_buffer_index=0, storage_scope="shared", consumer_blocks=[b0])
sch.compute_at(block=b36, loop=l29, preserve_unit_loops=True, index=-1)
l37, l38, l39, l40, l41, l42 = sch.get_loops(block=b36)
l43 = sch.fuse(l41, l42, preserve_unit_iters=True)
v44 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=1)
sch.annotate(block_or_loop=b36, ann_key="meta_schedule.cooperative_fetch", ann_val=v44)
b45 = sch.cache_read(block=b0, read_buffer_index=1, storage_scope="shared", consumer_blocks=[b0])
sch.compute_at(block=b45, loop=l29, preserve_unit_loops=True, index=-1)
l46, l47, l48, l49, l50, l51 = sch.get_loops(block=b45)
l52 = sch.fuse(l50, l51, preserve_unit_iters=True)
v53 = sch.sample_categorical(candidates=[1, 2, 3, 4], probs=[0.25, 0.25, 0.25, 0.25], decision=2)
sch.annotate(block_or_loop=b45, ann_key="meta_schedule.cooperative_fetch", ann_val=v53)
l54 = sch.fuse(l29, preserve_unit_iters=True)
sch.annotate(block_or_loop=l54, ann_key="software_pipeline_stage", ann_val=[0, 0, 3])
sch.annotate(block_or_loop=l54, ann_key="software_pipeline_order", ann_val=[0, 1, 2])
sch.annotate(block_or_loop=l54, ann_key="software_pipeline_async_stages", ann_val=[0])
sch.reverse_compute_inline(block=b1)
v55 = sch.sample_categorical(candidates=[0, 16, 64, 512, 1024], probs=[0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001, 0.20000000000000001], decision=4)
sch.annotate(block_or_loop=b2, ann_key="meta_schedule.unroll_explicit", ann_val=v55)
2023-11-10 22:31:51 [INFO] [evolutionary_search.cc:713] Generating candidates......
2023-11-10 22:31:51 [INFO] [evolutionary_search.cc:715] Picked top 0 candidate(s) from database
2023-11-10 22:31:52 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55e12b296a88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x55e12be62178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x55e12ba5afe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x55e12810f928)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x55e1276fa478)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x55e12c680dc8)]: 504 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x55e12be793f8)]: 0 failure(s)
2023-11-10 22:31:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55e12b296a88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x55e12be62178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x55e12ba5afe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x55e12810f928)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x55e1276fa478)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x55e12c680dc8)]: 1002 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x55e12be793f8)]: 0 failure(s)
2023-11-10 22:31:53 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55e12b296a88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x55e12be62178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x55e12ba5afe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x55e12810f928)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x55e1276fa478)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x55e12c680dc8)]: 1506 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x55e12be793f8)]: 0 failure(s)
2023-11-10 22:31:54 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55e12b296a88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x55e12be62178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x55e12ba5afe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x55e12810f928)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x55e1276fa478)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x55e12c680dc8)]: 2007 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x55e12be793f8)]: 0 failure(s)
2023-11-10 22:31:55 [INFO] [evolutionary_search.cc:533] Sample-Init-Population summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55e12b296a88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x55e12be62178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x55e12ba5afe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x55e12810f928)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x55e1276fa478)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x55e12c680dc8)]: 2508 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x55e12be793f8)]: 0 failure(s)
2023-11-10 22:31:55 [INFO] [evolutionary_search.cc:723] Sampled 52 candidate(s)
2023-11-10 22:31:57 [INFO] [evolutionary_search.cc:621] Evolve iter #0 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55e12b296a88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x55e12be62178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x55e12ba5afe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x55e12810f928)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x55e1276fa478)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x55e12c680dc8)]: 106 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x55e12be793f8)]: 0 failure(s)
2023-11-10 22:31:58 [INFO] [evolutionary_search.cc:621] Evolve iter #1 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55e12b296a88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x55e12be62178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x55e12ba5afe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x55e12810f928)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x55e1276fa478)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x55e12c680dc8)]: 90 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x55e12be793f8)]: 0 failure(s)
2023-11-10 22:32:00 [INFO] [evolutionary_search.cc:621] Evolve iter #2 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55e12b296a88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x55e12be62178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x55e12ba5afe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x55e12810f928)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x55e1276fa478)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x55e12c680dc8)]: 97 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x55e12be793f8)]: 0 failure(s)
2023-11-10 22:32:02 [INFO] [evolutionary_search.cc:621] Evolve iter #3 done. Summary:
Postproc #0 [meta_schedule.DisallowDynamicLoop(0x55e12b296a88)]: 0 failure(s)
Postproc #1 [meta_schedule.RewriteCooperativeFetch(0x55e12be62178)]: 0 failure(s)
Postproc #2 [meta_schedule.RewriteUnboundBlock(0x55e12ba5afe8)]: 0 failure(s)
Postproc #3 [meta_schedule.RewriteParallelVectorizeUnroll(0x55e12810f928)]: 0 failure(s)
Postproc #4 [meta_schedule.RewriteReductionBlock(0x55e1276fa478)]: 0 failure(s)
Postproc #5 [meta_schedule.VerifyGPUCode(0x55e12c680dc8)]: 104 failure(s)
Postproc #6 [meta_schedule.RewriteTensorize(0x55e12be793f8)]: 0 failure(s)
2023-11-10 22:32:02 [INFO] [evolutionary_search.cc:649] Scores of the best 2 candidates:
[1 : 2]:	0.9997  0.9989
2023-11-10 22:32:02 [INFO] [evolutionary_search.cc:727] Got 2 candidate(s) with evolutionary search
2023-11-10 22:32:02 [INFO] [evolutionary_search.cc:730] Sending 2 candidates(s) for measurement
2023-11-10 22:32:12 [INFO] [task_scheduler.cc:131] [Task #28: fused_nn_dense_add] Trial #1: GFLOPs: 5.4012. Time: 189.7725 us. Best GFLOPs: 5.4012
2023-11-10 22:32:12 [INFO] [task_scheduler.cc:131] [Task #28: fused_nn_dense_add] Trial #2: GFLOPs: 7.5871. Time: 135.0980 us. Best GFLOPs: 7.5871
